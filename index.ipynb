{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recall from the last lab that you had a training accuracy close to 90% and a test set accuracy close to 76%.\n",
    "\n",
    "As with your previous machine learning work, you should be asking a couple of questions:\n",
    "- Is there high bias? yes/no\n",
    "- Is there high variance? yes/no \n",
    "\n",
    "In this lab, you'll use the a train-validate-test partition as well as a validation set to get better insights of how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. However, this time, when you are presented with the `history` dictionary of the model, you will have additional data entries for not only the train and test set but also the validation set.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Construct and run a basic model in Keras\n",
    "* Construct a validation set and explain potential benefits\n",
    "* Apply L1 and L2 regularization\n",
    "* Apply dropout regularization\n",
    "* Observe and comment on the effect of using more data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries\n",
    "\n",
    "As usual, start by importing some of the packages and modules that you intend to use. The first thing you'll be doing is importing the data and taking a random sample, so that should clue you in to what tools to import. If you need more tools down the line, you can always import additional packages later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; import some packages/modules you plan to use\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "As with the previous lab, the data is stored in a file **Bank_complaints.csv**. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here; load and preview the dataset\n",
    "df=pd.read_csv(\"Bank_complaints.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools regarding regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Train - test split\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your models performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "Generate the random sample using seed 123 for consistency of results. Make your new sample have 10,000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(10_000, random_state=123)\n",
    "y = df[\"Product\"]\n",
    "X = df[\"Consumer complaint narrative\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split\n",
    "\n",
    "Below, perform an appropriate train test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Yyour code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model using a validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, you saw that in deep learning, you generally set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test can then be used to define the final model perforance. \n",
    "\n",
    "In this example, take the first 1000 cases out of the training set to create a validation set. You should do this for both `train` and `label_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38756    Checking or savings account\n",
       "5945                    Student loan\n",
       "47149                       Mortgage\n",
       "59200               Credit reporting\n",
       "37277                  Consumer Loan\n",
       "                    ...             \n",
       "27405        Bank account or service\n",
       "49082                       Mortgage\n",
       "16640                    Credit card\n",
       "48246                       Mortgage\n",
       "24699        Bank account or service\n",
       "Name: Product, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just run this block of code \n",
    "\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=123)\n",
    "#X_train_final\n",
    "\n",
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding of the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing and data manipulationg before building the neural network. \n",
    "\n",
    "Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; use one-hot encoding to reformat the complaints into a matrix of vectors.\n",
    "#Only keep the 2000 most common words.\n",
    "\n",
    "tokenizer=Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "X_train_tok = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val = tokenizer.texts_to_matrix(X_val, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; transform the product labels to numerical values\n",
    "#Then transform these integer values into a matrix of binary flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train_final))[:, :, 1]\n",
    "y_val = to_categorical(lb.transform(y_val))[:, :, 1]\n",
    "y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild a fully connected (Dense) layer network with relu activations in Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that you used 2 hidden with 50 units in the first layer and 25 in the second, both with a `relu` activation function. Because you are dealing with a multiclass problem (classifying the complaints into 7 classes), use a softmax classifyer in order to output 7 class probabilities per case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here; build a neural network using Keras as described above.\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu'))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the Model\n",
    "In the compiler, you'll be passing the optimizer, loss function, and metrics. Train the model for 120 epochs in mini-batches of 256 samples. This time, include the argument `validation_data` and assign it `(val, label_val)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Ok, now for the resource intensive part: time to train your model! Note that this is where you also introduce the validation data to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "7500/7500 [==============================] - 1s 116us/step - loss: 1.9529 - accuracy: 0.1587 - val_loss: 1.9456 - val_accuracy: 0.1630\n",
      "Epoch 2/120\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.9241 - accuracy: 0.1917 - val_loss: 1.9246 - val_accuracy: 0.1880\n",
      "Epoch 3/120\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.9007 - accuracy: 0.2199 - val_loss: 1.9045 - val_accuracy: 0.2050\n",
      "Epoch 4/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.8765 - accuracy: 0.2429 - val_loss: 1.8819 - val_accuracy: 0.2210\n",
      "Epoch 5/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8490 - accuracy: 0.2641 - val_loss: 1.8564 - val_accuracy: 0.2330\n",
      "Epoch 6/120\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.8169 - accuracy: 0.2901 - val_loss: 1.8264 - val_accuracy: 0.2500\n",
      "Epoch 7/120\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.7802 - accuracy: 0.3121 - val_loss: 1.7915 - val_accuracy: 0.2790\n",
      "Epoch 8/120\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.7392 - accuracy: 0.3412 - val_loss: 1.7528 - val_accuracy: 0.3130\n",
      "Epoch 9/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.6944 - accuracy: 0.3749 - val_loss: 1.7111 - val_accuracy: 0.3360\n",
      "Epoch 10/120\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.6464 - accuracy: 0.4064 - val_loss: 1.6660 - val_accuracy: 0.3720\n",
      "Epoch 11/120\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.5963 - accuracy: 0.4439 - val_loss: 1.6199 - val_accuracy: 0.3940\n",
      "Epoch 12/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.5453 - accuracy: 0.4695 - val_loss: 1.5729 - val_accuracy: 0.4220\n",
      "Epoch 13/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4943 - accuracy: 0.5001 - val_loss: 1.5274 - val_accuracy: 0.4470\n",
      "Epoch 14/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4442 - accuracy: 0.5268 - val_loss: 1.4836 - val_accuracy: 0.4710\n",
      "Epoch 15/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3959 - accuracy: 0.5488 - val_loss: 1.4401 - val_accuracy: 0.4830\n",
      "Epoch 16/120\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.3487 - accuracy: 0.5731 - val_loss: 1.3989 - val_accuracy: 0.5190\n",
      "Epoch 17/120\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.3036 - accuracy: 0.5957 - val_loss: 1.3616 - val_accuracy: 0.5240\n",
      "Epoch 18/120\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.2609 - accuracy: 0.6059 - val_loss: 1.3232 - val_accuracy: 0.5430\n",
      "Epoch 19/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2200 - accuracy: 0.6227 - val_loss: 1.2897 - val_accuracy: 0.5640\n",
      "Epoch 20/120\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.1813 - accuracy: 0.6361 - val_loss: 1.2559 - val_accuracy: 0.5730\n",
      "Epoch 21/120\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.1443 - accuracy: 0.6487 - val_loss: 1.2253 - val_accuracy: 0.5730\n",
      "Epoch 22/120\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.1098 - accuracy: 0.6551 - val_loss: 1.1972 - val_accuracy: 0.5840\n",
      "Epoch 23/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0774 - accuracy: 0.6629 - val_loss: 1.1698 - val_accuracy: 0.6010\n",
      "Epoch 24/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0461 - accuracy: 0.6739 - val_loss: 1.1454 - val_accuracy: 0.6010\n",
      "Epoch 25/120\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.0171 - accuracy: 0.6795 - val_loss: 1.1214 - val_accuracy: 0.6180\n",
      "Epoch 26/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9899 - accuracy: 0.6891 - val_loss: 1.0991 - val_accuracy: 0.6160\n",
      "Epoch 27/120\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.9639 - accuracy: 0.6955 - val_loss: 1.0770 - val_accuracy: 0.6250\n",
      "Epoch 28/120\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.9393 - accuracy: 0.7035 - val_loss: 1.0589 - val_accuracy: 0.6270\n",
      "Epoch 29/120\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9162 - accuracy: 0.7068 - val_loss: 1.0416 - val_accuracy: 0.6360\n",
      "Epoch 30/120\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8947 - accuracy: 0.7131 - val_loss: 1.0244 - val_accuracy: 0.6400\n",
      "Epoch 31/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8740 - accuracy: 0.7173 - val_loss: 1.0078 - val_accuracy: 0.6370\n",
      "Epoch 32/120\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8547 - accuracy: 0.7203 - val_loss: 0.9926 - val_accuracy: 0.6550\n",
      "Epoch 33/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8367 - accuracy: 0.7280 - val_loss: 0.9802 - val_accuracy: 0.6500\n",
      "Epoch 34/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8200 - accuracy: 0.7329 - val_loss: 0.9663 - val_accuracy: 0.6570\n",
      "Epoch 35/120\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8042 - accuracy: 0.7349 - val_loss: 0.9576 - val_accuracy: 0.6520\n",
      "Epoch 36/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7888 - accuracy: 0.7408 - val_loss: 0.9483 - val_accuracy: 0.6600\n",
      "Epoch 37/120\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.7751 - accuracy: 0.7440 - val_loss: 0.9354 - val_accuracy: 0.6600\n",
      "Epoch 38/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7612 - accuracy: 0.7476 - val_loss: 0.9257 - val_accuracy: 0.6710\n",
      "Epoch 39/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7489 - accuracy: 0.7507 - val_loss: 0.9187 - val_accuracy: 0.6630\n",
      "Epoch 40/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.7367 - accuracy: 0.7505 - val_loss: 0.9068 - val_accuracy: 0.6750\n",
      "Epoch 41/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.7254 - accuracy: 0.7579 - val_loss: 0.9021 - val_accuracy: 0.6810\n",
      "Epoch 42/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7138 - accuracy: 0.7607 - val_loss: 0.8944 - val_accuracy: 0.6750\n",
      "Epoch 43/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7038 - accuracy: 0.7639 - val_loss: 0.8867 - val_accuracy: 0.6730\n",
      "Epoch 44/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.6937 - accuracy: 0.7668 - val_loss: 0.8807 - val_accuracy: 0.6770\n",
      "Epoch 45/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6838 - accuracy: 0.7677 - val_loss: 0.8782 - val_accuracy: 0.6780\n",
      "Epoch 46/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6747 - accuracy: 0.7724 - val_loss: 0.8709 - val_accuracy: 0.6880\n",
      "Epoch 47/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.6657 - accuracy: 0.7757 - val_loss: 0.8660 - val_accuracy: 0.6780\n",
      "Epoch 48/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6575 - accuracy: 0.7773 - val_loss: 0.8574 - val_accuracy: 0.6870\n",
      "Epoch 49/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6492 - accuracy: 0.7783 - val_loss: 0.8537 - val_accuracy: 0.6850\n",
      "Epoch 50/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6418 - accuracy: 0.7819 - val_loss: 0.8478 - val_accuracy: 0.6900\n",
      "Epoch 51/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6337 - accuracy: 0.7855 - val_loss: 0.8472 - val_accuracy: 0.6940\n",
      "Epoch 52/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6266 - accuracy: 0.7843 - val_loss: 0.8420 - val_accuracy: 0.6930\n",
      "Epoch 53/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6194 - accuracy: 0.7881 - val_loss: 0.8404 - val_accuracy: 0.6980\n",
      "Epoch 54/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6124 - accuracy: 0.7897 - val_loss: 0.8328 - val_accuracy: 0.7020\n",
      "Epoch 55/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6063 - accuracy: 0.7925 - val_loss: 0.8307 - val_accuracy: 0.7000\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5996 - accuracy: 0.7944 - val_loss: 0.8302 - val_accuracy: 0.6980\n",
      "Epoch 57/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5931 - accuracy: 0.7955 - val_loss: 0.8271 - val_accuracy: 0.7020\n",
      "Epoch 58/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.5867 - accuracy: 0.7980 - val_loss: 0.8217 - val_accuracy: 0.7020\n",
      "Epoch 59/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5810 - accuracy: 0.7988 - val_loss: 0.8161 - val_accuracy: 0.7120\n",
      "Epoch 60/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.5756 - accuracy: 0.8028 - val_loss: 0.8133 - val_accuracy: 0.7080\n",
      "Epoch 61/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.5694 - accuracy: 0.8047 - val_loss: 0.8130 - val_accuracy: 0.7060\n",
      "Epoch 62/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5644 - accuracy: 0.8043 - val_loss: 0.8112 - val_accuracy: 0.7090\n",
      "Epoch 63/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5591 - accuracy: 0.8085 - val_loss: 0.8055 - val_accuracy: 0.7120\n",
      "Epoch 64/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5532 - accuracy: 0.8096 - val_loss: 0.8034 - val_accuracy: 0.7110\n",
      "Epoch 65/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5481 - accuracy: 0.8108 - val_loss: 0.8049 - val_accuracy: 0.7120\n",
      "Epoch 66/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5429 - accuracy: 0.8132 - val_loss: 0.8038 - val_accuracy: 0.7090\n",
      "Epoch 67/120\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.5384 - accuracy: 0.8107 - val_loss: 0.7996 - val_accuracy: 0.7180\n",
      "Epoch 68/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5331 - accuracy: 0.8152 - val_loss: 0.7971 - val_accuracy: 0.7160\n",
      "Epoch 69/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5285 - accuracy: 0.8175 - val_loss: 0.7956 - val_accuracy: 0.7130\n",
      "Epoch 70/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5242 - accuracy: 0.8168 - val_loss: 0.7929 - val_accuracy: 0.7210\n",
      "Epoch 71/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.5192 - accuracy: 0.8212 - val_loss: 0.7914 - val_accuracy: 0.7250\n",
      "Epoch 72/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5150 - accuracy: 0.8229 - val_loss: 0.7897 - val_accuracy: 0.7220\n",
      "Epoch 73/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5103 - accuracy: 0.8223 - val_loss: 0.7876 - val_accuracy: 0.7220\n",
      "Epoch 74/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.5057 - accuracy: 0.8268 - val_loss: 0.7904 - val_accuracy: 0.7190\n",
      "Epoch 75/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.5021 - accuracy: 0.8245 - val_loss: 0.7858 - val_accuracy: 0.7260\n",
      "Epoch 76/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4977 - accuracy: 0.8268 - val_loss: 0.7822 - val_accuracy: 0.7330\n",
      "Epoch 77/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4930 - accuracy: 0.8295 - val_loss: 0.7784 - val_accuracy: 0.7340\n",
      "Epoch 78/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4893 - accuracy: 0.8311 - val_loss: 0.7786 - val_accuracy: 0.7290\n",
      "Epoch 79/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4851 - accuracy: 0.8340 - val_loss: 0.7771 - val_accuracy: 0.7360\n",
      "Epoch 80/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4814 - accuracy: 0.8345 - val_loss: 0.7782 - val_accuracy: 0.7370\n",
      "Epoch 81/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4773 - accuracy: 0.8381 - val_loss: 0.7767 - val_accuracy: 0.7310\n",
      "Epoch 82/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4737 - accuracy: 0.8371 - val_loss: 0.7783 - val_accuracy: 0.7350\n",
      "Epoch 83/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4695 - accuracy: 0.8405 - val_loss: 0.7747 - val_accuracy: 0.7320\n",
      "Epoch 84/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4664 - accuracy: 0.8420 - val_loss: 0.7728 - val_accuracy: 0.7350\n",
      "Epoch 85/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4623 - accuracy: 0.8408 - val_loss: 0.7735 - val_accuracy: 0.7350\n",
      "Epoch 86/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4583 - accuracy: 0.8455 - val_loss: 0.7704 - val_accuracy: 0.7390\n",
      "Epoch 87/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4547 - accuracy: 0.8465 - val_loss: 0.7700 - val_accuracy: 0.7400\n",
      "Epoch 88/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4513 - accuracy: 0.8463 - val_loss: 0.7717 - val_accuracy: 0.7400\n",
      "Epoch 89/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4475 - accuracy: 0.8495 - val_loss: 0.7683 - val_accuracy: 0.7410\n",
      "Epoch 90/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4442 - accuracy: 0.8485 - val_loss: 0.7720 - val_accuracy: 0.7380\n",
      "Epoch 91/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4407 - accuracy: 0.8513 - val_loss: 0.7712 - val_accuracy: 0.7330\n",
      "Epoch 92/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4369 - accuracy: 0.8539 - val_loss: 0.7652 - val_accuracy: 0.7420\n",
      "Epoch 93/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4339 - accuracy: 0.8543 - val_loss: 0.7657 - val_accuracy: 0.7440\n",
      "Epoch 94/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4304 - accuracy: 0.8551 - val_loss: 0.7680 - val_accuracy: 0.7460\n",
      "Epoch 95/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4269 - accuracy: 0.8580 - val_loss: 0.7687 - val_accuracy: 0.7360\n",
      "Epoch 96/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.4235 - accuracy: 0.8592 - val_loss: 0.7659 - val_accuracy: 0.7420\n",
      "Epoch 97/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.4207 - accuracy: 0.8589 - val_loss: 0.7641 - val_accuracy: 0.7470\n",
      "Epoch 98/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4173 - accuracy: 0.8608 - val_loss: 0.7647 - val_accuracy: 0.7400\n",
      "Epoch 99/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4143 - accuracy: 0.8605 - val_loss: 0.7659 - val_accuracy: 0.7350\n",
      "Epoch 100/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.4111 - accuracy: 0.8625 - val_loss: 0.7645 - val_accuracy: 0.7460\n",
      "Epoch 101/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4078 - accuracy: 0.8649 - val_loss: 0.7666 - val_accuracy: 0.7380\n",
      "Epoch 102/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.4047 - accuracy: 0.8664 - val_loss: 0.7644 - val_accuracy: 0.7410\n",
      "Epoch 103/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.4013 - accuracy: 0.8672 - val_loss: 0.7655 - val_accuracy: 0.7420\n",
      "Epoch 104/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3984 - accuracy: 0.8681 - val_loss: 0.7630 - val_accuracy: 0.7460\n",
      "Epoch 105/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3953 - accuracy: 0.8701 - val_loss: 0.7678 - val_accuracy: 0.7340\n",
      "Epoch 106/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.3926 - accuracy: 0.8693 - val_loss: 0.7609 - val_accuracy: 0.7450\n",
      "Epoch 107/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3892 - accuracy: 0.8724 - val_loss: 0.7627 - val_accuracy: 0.7500\n",
      "Epoch 108/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3865 - accuracy: 0.8724 - val_loss: 0.7668 - val_accuracy: 0.7460\n",
      "Epoch 109/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3834 - accuracy: 0.8749 - val_loss: 0.7643 - val_accuracy: 0.7460\n",
      "Epoch 110/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3806 - accuracy: 0.8759 - val_loss: 0.7628 - val_accuracy: 0.7490\n",
      "Epoch 111/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.3776 - accuracy: 0.8769 - val_loss: 0.7672 - val_accuracy: 0.7380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3752 - accuracy: 0.8787 - val_loss: 0.7646 - val_accuracy: 0.7460\n",
      "Epoch 113/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3721 - accuracy: 0.8785 - val_loss: 0.7647 - val_accuracy: 0.7480\n",
      "Epoch 114/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3692 - accuracy: 0.8805 - val_loss: 0.7667 - val_accuracy: 0.7440\n",
      "Epoch 115/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3666 - accuracy: 0.8804 - val_loss: 0.7627 - val_accuracy: 0.7520\n",
      "Epoch 116/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3639 - accuracy: 0.8819 - val_loss: 0.7648 - val_accuracy: 0.7460\n",
      "Epoch 117/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3608 - accuracy: 0.8829 - val_loss: 0.7682 - val_accuracy: 0.7510\n",
      "Epoch 118/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3586 - accuracy: 0.8848 - val_loss: 0.7670 - val_accuracy: 0.7460\n",
      "Epoch 119/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3556 - accuracy: 0.8881 - val_loss: 0.7645 - val_accuracy: 0.7520\n",
      "Epoch 120/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.3529 - accuracy: 0.8888 - val_loss: 0.7663 - val_accuracy: 0.7480\n"
     ]
    }
   ],
   "source": [
    "#Code provided; note the extra validation parameter passed.\n",
    "model_val = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Performance Results: the `history` dictionary\n",
    "\n",
    "The dictionary `history` contains four entries this time: one per metric that was being monitored during training and during validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_val_dict = model_val.history\n",
    "model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 48us/step\n",
      "Training Loss: 0.35 Training Accuracy: 0.886\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess then evaluate our models performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 0s 48us/step\n",
      "Testing Loss: 0.627 Testing Accuracy: 0.765\n"
     ]
    }
   ],
   "source": [
    "X_test_tok = tokenizer.texts_to_matrix(X_test, mode='binary')\n",
    "y_test_cat = to_categorical(lb.transform(y_test))[:, :, 1]\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element of the list returned by `model.evaluate` is the loss, and the second is the accuracy score. \n",
    "\n",
    "Note that the result you obtained here isn't exactly the same as before. This is because the training set is slightly different! You removed 1000 instances for validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the loss function versus the number of epochs. Be sure to include the training and the validation loss in the same plot. Then, create a second plot comparing training and validation accuracy to the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss vs number of epochs with train and val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy vs number of epochs with train and val set\n",
    "visualize_training_results(model_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice an interesting pattern here: although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss seem to be reaching a limit around the 60th epoch. This means that you're probably **overfitting** the model to the training data when you train for many epochs past this dropoff point of around 40 epochs. Luckily, you learned how to tackle overfitting in the previous lecture! Since it seems clear that you are training too long, include early stopping at the 60th epoch first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Below, observe how to update the model to include an earlier cutoff point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/60\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.9434 - accuracy: 0.1797 - val_loss: 1.9317 - val_accuracy: 0.1970\n",
      "Epoch 2/60\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.9159 - accuracy: 0.2183 - val_loss: 1.9101 - val_accuracy: 0.2250\n",
      "Epoch 3/60\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.8902 - accuracy: 0.2404 - val_loss: 1.8863 - val_accuracy: 0.2500\n",
      "Epoch 4/60\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8613 - accuracy: 0.2699 - val_loss: 1.8583 - val_accuracy: 0.2710\n",
      "Epoch 5/60\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.8277 - accuracy: 0.3040 - val_loss: 1.8265 - val_accuracy: 0.3040\n",
      "Epoch 6/60\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.7890 - accuracy: 0.3461 - val_loss: 1.7916 - val_accuracy: 0.3290\n",
      "Epoch 7/60\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.7452 - accuracy: 0.3767 - val_loss: 1.7510 - val_accuracy: 0.3740\n",
      "Epoch 8/60\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.6973 - accuracy: 0.4160 - val_loss: 1.7069 - val_accuracy: 0.4050\n",
      "Epoch 9/60\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.6464 - accuracy: 0.4533 - val_loss: 1.6607 - val_accuracy: 0.4330\n",
      "Epoch 10/60\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.5929 - accuracy: 0.4823 - val_loss: 1.6138 - val_accuracy: 0.4670\n",
      "Epoch 11/60\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5374 - accuracy: 0.5087 - val_loss: 1.5648 - val_accuracy: 0.4870\n",
      "Epoch 12/60\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.4809 - accuracy: 0.5369 - val_loss: 1.5143 - val_accuracy: 0.5060\n",
      "Epoch 13/60\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.4242 - accuracy: 0.5597 - val_loss: 1.4656 - val_accuracy: 0.5290\n",
      "Epoch 14/60\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.3681 - accuracy: 0.5843 - val_loss: 1.4171 - val_accuracy: 0.5510\n",
      "Epoch 15/60\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.3139 - accuracy: 0.6035 - val_loss: 1.3715 - val_accuracy: 0.5520\n",
      "Epoch 16/60\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2614 - accuracy: 0.6204 - val_loss: 1.3308 - val_accuracy: 0.5670\n",
      "Epoch 17/60\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2122 - accuracy: 0.6415 - val_loss: 1.2840 - val_accuracy: 0.5790\n",
      "Epoch 18/60\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.1649 - accuracy: 0.6579 - val_loss: 1.2443 - val_accuracy: 0.5930\n",
      "Epoch 19/60\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1211 - accuracy: 0.6709 - val_loss: 1.2083 - val_accuracy: 0.6070\n",
      "Epoch 20/60\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0799 - accuracy: 0.6859 - val_loss: 1.1742 - val_accuracy: 0.6190\n",
      "Epoch 21/60\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0420 - accuracy: 0.6967 - val_loss: 1.1451 - val_accuracy: 0.6250\n",
      "Epoch 22/60\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0060 - accuracy: 0.7056 - val_loss: 1.1126 - val_accuracy: 0.6350\n",
      "Epoch 23/60\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9727 - accuracy: 0.7129 - val_loss: 1.0865 - val_accuracy: 0.6420\n",
      "Epoch 24/60\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9416 - accuracy: 0.7212 - val_loss: 1.0631 - val_accuracy: 0.6460\n",
      "Epoch 25/60\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9130 - accuracy: 0.7255 - val_loss: 1.0409 - val_accuracy: 0.6440\n",
      "Epoch 26/60\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.8866 - accuracy: 0.7341 - val_loss: 1.0208 - val_accuracy: 0.6540\n",
      "Epoch 27/60\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8623 - accuracy: 0.7371 - val_loss: 1.0000 - val_accuracy: 0.6480\n",
      "Epoch 28/60\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8395 - accuracy: 0.7428 - val_loss: 0.9849 - val_accuracy: 0.6530\n",
      "Epoch 29/60\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8184 - accuracy: 0.7452 - val_loss: 0.9667 - val_accuracy: 0.6550\n",
      "Epoch 30/60\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7982 - accuracy: 0.7489 - val_loss: 0.9538 - val_accuracy: 0.6570\n",
      "Epoch 31/60\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.7804 - accuracy: 0.7517 - val_loss: 0.9394 - val_accuracy: 0.6610\n",
      "Epoch 32/60\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.7634 - accuracy: 0.7557 - val_loss: 0.9290 - val_accuracy: 0.6620\n",
      "Epoch 33/60\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.7478 - accuracy: 0.7577 - val_loss: 0.9181 - val_accuracy: 0.6620\n",
      "Epoch 34/60\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7335 - accuracy: 0.7601 - val_loss: 0.9061 - val_accuracy: 0.6670\n",
      "Epoch 35/60\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.7197 - accuracy: 0.7627 - val_loss: 0.8975 - val_accuracy: 0.6680\n",
      "Epoch 36/60\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.7070 - accuracy: 0.7659 - val_loss: 0.8919 - val_accuracy: 0.6740\n",
      "Epoch 37/60\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.6952 - accuracy: 0.7688 - val_loss: 0.8825 - val_accuracy: 0.6800\n",
      "Epoch 38/60\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.6844 - accuracy: 0.7695 - val_loss: 0.8733 - val_accuracy: 0.6780\n",
      "Epoch 39/60\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.6736 - accuracy: 0.7724 - val_loss: 0.8678 - val_accuracy: 0.6760\n",
      "Epoch 40/60\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.6640 - accuracy: 0.7745 - val_loss: 0.8634 - val_accuracy: 0.6800\n",
      "Epoch 41/60\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.6546 - accuracy: 0.7764 - val_loss: 0.8567 - val_accuracy: 0.6850\n",
      "Epoch 42/60\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.6454 - accuracy: 0.7809 - val_loss: 0.8514 - val_accuracy: 0.6820\n",
      "Epoch 43/60\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.6379 - accuracy: 0.7817 - val_loss: 0.8469 - val_accuracy: 0.6900\n",
      "Epoch 44/60\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.6293 - accuracy: 0.7832 - val_loss: 0.8414 - val_accuracy: 0.6910\n",
      "Epoch 45/60\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.6215 - accuracy: 0.7873 - val_loss: 0.8418 - val_accuracy: 0.6870\n",
      "Epoch 46/60\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.6144 - accuracy: 0.7885 - val_loss: 0.8359 - val_accuracy: 0.6960\n",
      "Epoch 47/60\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.6074 - accuracy: 0.7911 - val_loss: 0.8308 - val_accuracy: 0.6980\n",
      "Epoch 48/60\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.6003 - accuracy: 0.7935 - val_loss: 0.8289 - val_accuracy: 0.6990\n",
      "Epoch 49/60\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5939 - accuracy: 0.7940 - val_loss: 0.8239 - val_accuracy: 0.6960\n",
      "Epoch 50/60\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5874 - accuracy: 0.7985 - val_loss: 0.8212 - val_accuracy: 0.7010\n",
      "Epoch 51/60\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.5813 - accuracy: 0.8003 - val_loss: 0.8198 - val_accuracy: 0.7000\n",
      "Epoch 52/60\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.5750 - accuracy: 0.8004 - val_loss: 0.8201 - val_accuracy: 0.6950\n",
      "Epoch 53/60\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5698 - accuracy: 0.8036 - val_loss: 0.8167 - val_accuracy: 0.7030\n",
      "Epoch 54/60\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 0.5640 - accuracy: 0.8048 - val_loss: 0.8130 - val_accuracy: 0.7040\n",
      "Epoch 55/60\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.5590 - accuracy: 0.8047 - val_loss: 0.8092 - val_accuracy: 0.7080\n",
      "Epoch 56/60\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.5532 - accuracy: 0.8111 - val_loss: 0.8079 - val_accuracy: 0.7050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/60\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.5484 - accuracy: 0.8089 - val_loss: 0.8062 - val_accuracy: 0.7100\n",
      "Epoch 58/60\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.5432 - accuracy: 0.8123 - val_loss: 0.8049 - val_accuracy: 0.7180\n",
      "Epoch 59/60\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.5385 - accuracy: 0.8147 - val_loss: 0.8028 - val_accuracy: 0.7130\n",
      "Epoch 60/60\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.5344 - accuracy: 0.8167 - val_loss: 0.8014 - val_accuracy: 0.7130\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "final_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=60,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can use the test set to make label predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 56us/step\n",
      "Training Loss: 0.53 Training Accuracy: 0.818\n",
      "1500/1500 [==============================] - 0s 66us/step\n",
      "Testing Loss: 0.654 Testing Accuracy: 0.765\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've significantly reduced the variance, so this is already pretty good! your test set accuracy is slightly worse, but this model will definitely be more robust than the 120 epochs model you originally fit.\n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "7500/7500 [==============================] - 0s 64us/step - loss: 2.6013 - accuracy: 0.1456 - val_loss: 2.5795 - val_accuracy: 0.1980\n",
      "Epoch 2/120\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 2.5639 - accuracy: 0.2217 - val_loss: 2.5538 - val_accuracy: 0.2400\n",
      "Epoch 3/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.5324 - accuracy: 0.2660 - val_loss: 2.5270 - val_accuracy: 0.2550\n",
      "Epoch 4/120\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 2.4979 - accuracy: 0.2889 - val_loss: 2.4954 - val_accuracy: 0.2770\n",
      "Epoch 5/120\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 2.4578 - accuracy: 0.3176 - val_loss: 2.4567 - val_accuracy: 0.3020\n",
      "Epoch 6/120\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 2.4114 - accuracy: 0.3460 - val_loss: 2.4126 - val_accuracy: 0.3290\n",
      "Epoch 7/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.3596 - accuracy: 0.3797 - val_loss: 2.3651 - val_accuracy: 0.3500\n",
      "Epoch 8/120\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 2.3041 - accuracy: 0.4131 - val_loss: 2.3134 - val_accuracy: 0.3800\n",
      "Epoch 9/120\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 2.2455 - accuracy: 0.4439 - val_loss: 2.2581 - val_accuracy: 0.4230\n",
      "Epoch 10/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.1858 - accuracy: 0.4820 - val_loss: 2.2032 - val_accuracy: 0.4500\n",
      "Epoch 11/120\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.1259 - accuracy: 0.5175 - val_loss: 2.1483 - val_accuracy: 0.4830\n",
      "Epoch 12/120\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.0667 - accuracy: 0.5477 - val_loss: 2.0957 - val_accuracy: 0.5130\n",
      "Epoch 13/120\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 2.0091 - accuracy: 0.5795 - val_loss: 2.0462 - val_accuracy: 0.5310\n",
      "Epoch 14/120\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.9539 - accuracy: 0.5985 - val_loss: 1.9971 - val_accuracy: 0.5480\n",
      "Epoch 15/120\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.9008 - accuracy: 0.6181 - val_loss: 1.9505 - val_accuracy: 0.5780\n",
      "Epoch 16/120\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.8499 - accuracy: 0.6376 - val_loss: 1.9077 - val_accuracy: 0.5810\n",
      "Epoch 17/120\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.8021 - accuracy: 0.6531 - val_loss: 1.8667 - val_accuracy: 0.5980\n",
      "Epoch 18/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.7570 - accuracy: 0.6676 - val_loss: 1.8291 - val_accuracy: 0.6090\n",
      "Epoch 19/120\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.7153 - accuracy: 0.6809 - val_loss: 1.7935 - val_accuracy: 0.6140\n",
      "Epoch 20/120\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.6757 - accuracy: 0.6915 - val_loss: 1.7601 - val_accuracy: 0.6250\n",
      "Epoch 21/120\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.6379 - accuracy: 0.70 - 0s 59us/step - loss: 1.6389 - accuracy: 0.6997 - val_loss: 1.7303 - val_accuracy: 0.6310\n",
      "Epoch 22/120\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.6047 - accuracy: 0.7104 - val_loss: 1.7039 - val_accuracy: 0.6350\n",
      "Epoch 23/120\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.5733 - accuracy: 0.7153 - val_loss: 1.6778 - val_accuracy: 0.6380\n",
      "Epoch 24/120\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.5439 - accuracy: 0.7221 - val_loss: 1.6538 - val_accuracy: 0.6460\n",
      "Epoch 25/120\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.5165 - accuracy: 0.7271 - val_loss: 1.6314 - val_accuracy: 0.6440\n",
      "Epoch 26/120\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.4911 - accuracy: 0.7325 - val_loss: 1.6113 - val_accuracy: 0.6490\n",
      "Epoch 27/120\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.4675 - accuracy: 0.7389 - val_loss: 1.5922 - val_accuracy: 0.6530\n",
      "Epoch 28/120\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.4453 - accuracy: 0.7425 - val_loss: 1.5758 - val_accuracy: 0.6540\n",
      "Epoch 29/120\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.4249 - accuracy: 0.7459 - val_loss: 1.5600 - val_accuracy: 0.6670\n",
      "Epoch 30/120\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.4060 - accuracy: 0.7501 - val_loss: 1.5468 - val_accuracy: 0.6670\n",
      "Epoch 31/120\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.3877 - accuracy: 0.7548 - val_loss: 1.5332 - val_accuracy: 0.6730\n",
      "Epoch 32/120\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.3714 - accuracy: 0.7568 - val_loss: 1.5189 - val_accuracy: 0.6760\n",
      "Epoch 33/120\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.3554 - accuracy: 0.7624 - val_loss: 1.5067 - val_accuracy: 0.6740\n",
      "Epoch 34/120\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.3406 - accuracy: 0.7653 - val_loss: 1.4950 - val_accuracy: 0.6790\n",
      "Epoch 35/120\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 1.3259 - accuracy: 0.7661 - val_loss: 1.4876 - val_accuracy: 0.6830\n",
      "Epoch 36/120\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.3131 - accuracy: 0.7703 - val_loss: 1.4765 - val_accuracy: 0.6800\n",
      "Epoch 37/120\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.3000 - accuracy: 0.7739 - val_loss: 1.4710 - val_accuracy: 0.6860\n",
      "Epoch 38/120\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2885 - accuracy: 0.7739 - val_loss: 1.4604 - val_accuracy: 0.6950\n",
      "Epoch 39/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2768 - accuracy: 0.7785 - val_loss: 1.4503 - val_accuracy: 0.6930\n",
      "Epoch 40/120\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.2655 - accuracy: 0.7801 - val_loss: 1.4430 - val_accuracy: 0.6980\n",
      "Epoch 41/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2548 - accuracy: 0.7833 - val_loss: 1.4360 - val_accuracy: 0.6950\n",
      "Epoch 42/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2447 - accuracy: 0.7863 - val_loss: 1.4286 - val_accuracy: 0.7020\n",
      "Epoch 43/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2350 - accuracy: 0.7883 - val_loss: 1.4204 - val_accuracy: 0.7010\n",
      "Epoch 44/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2255 - accuracy: 0.7904 - val_loss: 1.4150 - val_accuracy: 0.7020\n",
      "Epoch 45/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2160 - accuracy: 0.7920 - val_loss: 1.4077 - val_accuracy: 0.7020\n",
      "Epoch 46/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2075 - accuracy: 0.7955 - val_loss: 1.4047 - val_accuracy: 0.7030\n",
      "Epoch 47/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1984 - accuracy: 0.7956 - val_loss: 1.3961 - val_accuracy: 0.7020\n",
      "Epoch 48/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1900 - accuracy: 0.7976 - val_loss: 1.3902 - val_accuracy: 0.7110\n",
      "Epoch 49/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1821 - accuracy: 0.8012 - val_loss: 1.3871 - val_accuracy: 0.7060\n",
      "Epoch 50/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1738 - accuracy: 0.8015 - val_loss: 1.3826 - val_accuracy: 0.7100\n",
      "Epoch 51/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1662 - accuracy: 0.8045 - val_loss: 1.3755 - val_accuracy: 0.7130\n",
      "Epoch 52/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1585 - accuracy: 0.8069 - val_loss: 1.3723 - val_accuracy: 0.7240\n",
      "Epoch 53/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1514 - accuracy: 0.8076 - val_loss: 1.3675 - val_accuracy: 0.7230\n",
      "Epoch 54/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1441 - accuracy: 0.8073 - val_loss: 1.3625 - val_accuracy: 0.7160\n",
      "Epoch 55/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1366 - accuracy: 0.8119 - val_loss: 1.3585 - val_accuracy: 0.7180\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1299 - accuracy: 0.8121 - val_loss: 1.3564 - val_accuracy: 0.7140\n",
      "Epoch 57/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1227 - accuracy: 0.8148 - val_loss: 1.3533 - val_accuracy: 0.7170\n",
      "Epoch 58/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1162 - accuracy: 0.8159 - val_loss: 1.3465 - val_accuracy: 0.7210\n",
      "Epoch 59/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1096 - accuracy: 0.8172 - val_loss: 1.3459 - val_accuracy: 0.7240\n",
      "Epoch 60/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1035 - accuracy: 0.8193 - val_loss: 1.3396 - val_accuracy: 0.7080\n",
      "Epoch 61/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0967 - accuracy: 0.8191 - val_loss: 1.3325 - val_accuracy: 0.7230\n",
      "Epoch 62/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0906 - accuracy: 0.8201 - val_loss: 1.3345 - val_accuracy: 0.7200\n",
      "Epoch 63/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0848 - accuracy: 0.8217 - val_loss: 1.3268 - val_accuracy: 0.7230\n",
      "Epoch 64/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0785 - accuracy: 0.8237 - val_loss: 1.3221 - val_accuracy: 0.7220\n",
      "Epoch 65/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0724 - accuracy: 0.8267 - val_loss: 1.3198 - val_accuracy: 0.7290\n",
      "Epoch 66/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0668 - accuracy: 0.8268 - val_loss: 1.3174 - val_accuracy: 0.7240\n",
      "Epoch 67/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0613 - accuracy: 0.8288 - val_loss: 1.3111 - val_accuracy: 0.7250\n",
      "Epoch 68/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0550 - accuracy: 0.8287 - val_loss: 1.3101 - val_accuracy: 0.7320\n",
      "Epoch 69/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0499 - accuracy: 0.8296 - val_loss: 1.3079 - val_accuracy: 0.7320\n",
      "Epoch 70/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0441 - accuracy: 0.8328 - val_loss: 1.3058 - val_accuracy: 0.7240\n",
      "Epoch 71/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0389 - accuracy: 0.8317 - val_loss: 1.2990 - val_accuracy: 0.7370\n",
      "Epoch 72/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0332 - accuracy: 0.8343 - val_loss: 1.2968 - val_accuracy: 0.7280\n",
      "Epoch 73/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0281 - accuracy: 0.8339 - val_loss: 1.2956 - val_accuracy: 0.7300\n",
      "Epoch 74/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0225 - accuracy: 0.8367 - val_loss: 1.2919 - val_accuracy: 0.7300\n",
      "Epoch 75/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0179 - accuracy: 0.8352 - val_loss: 1.2903 - val_accuracy: 0.7330\n",
      "Epoch 76/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0125 - accuracy: 0.8377 - val_loss: 1.2875 - val_accuracy: 0.7340\n",
      "Epoch 77/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0072 - accuracy: 0.8415 - val_loss: 1.2812 - val_accuracy: 0.7410\n",
      "Epoch 78/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0023 - accuracy: 0.8408 - val_loss: 1.2788 - val_accuracy: 0.7420\n",
      "Epoch 79/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9974 - accuracy: 0.8427 - val_loss: 1.2815 - val_accuracy: 0.7300\n",
      "Epoch 80/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9929 - accuracy: 0.8440 - val_loss: 1.2747 - val_accuracy: 0.7400\n",
      "Epoch 81/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9875 - accuracy: 0.8452 - val_loss: 1.2720 - val_accuracy: 0.7400\n",
      "Epoch 82/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9831 - accuracy: 0.8465 - val_loss: 1.2707 - val_accuracy: 0.7370\n",
      "Epoch 83/120\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.9784 - accuracy: 0.84 - 0s 35us/step - loss: 0.9784 - accuracy: 0.8479 - val_loss: 1.2668 - val_accuracy: 0.7370\n",
      "Epoch 84/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9737 - accuracy: 0.8485 - val_loss: 1.2642 - val_accuracy: 0.7460\n",
      "Epoch 85/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9692 - accuracy: 0.8487 - val_loss: 1.2653 - val_accuracy: 0.7420\n",
      "Epoch 86/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9646 - accuracy: 0.8499 - val_loss: 1.2628 - val_accuracy: 0.7430\n",
      "Epoch 87/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9603 - accuracy: 0.8516 - val_loss: 1.2612 - val_accuracy: 0.7410\n",
      "Epoch 88/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9551 - accuracy: 0.8515 - val_loss: 1.2593 - val_accuracy: 0.7440\n",
      "Epoch 89/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9511 - accuracy: 0.8525 - val_loss: 1.2552 - val_accuracy: 0.7420\n",
      "Epoch 90/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9466 - accuracy: 0.8541 - val_loss: 1.2505 - val_accuracy: 0.7450\n",
      "Epoch 91/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9421 - accuracy: 0.8552 - val_loss: 1.2477 - val_accuracy: 0.7460\n",
      "Epoch 92/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9381 - accuracy: 0.8557 - val_loss: 1.2470 - val_accuracy: 0.7470\n",
      "Epoch 93/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9334 - accuracy: 0.8571 - val_loss: 1.2471 - val_accuracy: 0.7420\n",
      "Epoch 94/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9295 - accuracy: 0.8572 - val_loss: 1.2441 - val_accuracy: 0.7480\n",
      "Epoch 95/120\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9254 - accuracy: 0.8601 - val_loss: 1.2431 - val_accuracy: 0.7450\n",
      "Epoch 96/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9212 - accuracy: 0.8623 - val_loss: 1.2374 - val_accuracy: 0.7550\n",
      "Epoch 97/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9172 - accuracy: 0.8603 - val_loss: 1.2364 - val_accuracy: 0.7480\n",
      "Epoch 98/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9128 - accuracy: 0.8616 - val_loss: 1.2364 - val_accuracy: 0.7420\n",
      "Epoch 99/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9081 - accuracy: 0.8644 - val_loss: 1.2387 - val_accuracy: 0.7450\n",
      "Epoch 100/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9052 - accuracy: 0.8640 - val_loss: 1.2337 - val_accuracy: 0.7430\n",
      "Epoch 101/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9008 - accuracy: 0.8653 - val_loss: 1.2293 - val_accuracy: 0.7500\n",
      "Epoch 102/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8969 - accuracy: 0.8652 - val_loss: 1.2304 - val_accuracy: 0.7440\n",
      "Epoch 103/120\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8929 - accuracy: 0.8668 - val_loss: 1.2291 - val_accuracy: 0.7490\n",
      "Epoch 104/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8891 - accuracy: 0.8687 - val_loss: 1.2254 - val_accuracy: 0.7460\n",
      "Epoch 105/120\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8852 - accuracy: 0.8688 - val_loss: 1.2217 - val_accuracy: 0.7530\n",
      "Epoch 106/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8812 - accuracy: 0.8723 - val_loss: 1.2215 - val_accuracy: 0.7540\n",
      "Epoch 107/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8777 - accuracy: 0.8717 - val_loss: 1.2187 - val_accuracy: 0.7570\n",
      "Epoch 108/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8739 - accuracy: 0.8743 - val_loss: 1.2167 - val_accuracy: 0.7470\n",
      "Epoch 109/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8704 - accuracy: 0.8743 - val_loss: 1.2147 - val_accuracy: 0.7470\n",
      "Epoch 110/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8667 - accuracy: 0.8751 - val_loss: 1.2139 - val_accuracy: 0.7540\n",
      "Epoch 111/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8628 - accuracy: 0.8765 - val_loss: 1.2111 - val_accuracy: 0.7490\n",
      "Epoch 112/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8595 - accuracy: 0.8756 - val_loss: 1.2123 - val_accuracy: 0.7530\n",
      "Epoch 113/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8561 - accuracy: 0.8783 - val_loss: 1.2086 - val_accuracy: 0.7530\n",
      "Epoch 114/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8521 - accuracy: 0.8807 - val_loss: 1.2069 - val_accuracy: 0.7550\n",
      "Epoch 115/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8486 - accuracy: 0.8796 - val_loss: 1.2061 - val_accuracy: 0.7460\n",
      "Epoch 116/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8452 - accuracy: 0.8803 - val_loss: 1.2047 - val_accuracy: 0.7510\n",
      "Epoch 117/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8417 - accuracy: 0.8812 - val_loss: 1.2051 - val_accuracy: 0.7480\n",
      "Epoch 118/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8381 - accuracy: 0.8824 - val_loss: 1.2002 - val_accuracy: 0.7490\n",
      "Epoch 119/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8350 - accuracy: 0.8837 - val_loss: 1.2036 - val_accuracy: 0.7460\n",
      "Epoch 120/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8314 - accuracy: 0.8845 - val_loss: 1.1997 - val_accuracy: 0.7490\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l2(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L2_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2_model_dict = L2_model.history\n",
    "L2_model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training accuracy as well as the validation accuracy for both the L2 and the model without regularization (for 120 epochs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "acc_values = L2_model_dict['accuracy'] \n",
    "val_acc_values = L2_model_dict['val_accuracy']\n",
    "model_acc = model_val_dict['accuracy']\n",
    "model_val_acc = model_val_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, model_acc, label='Training acc')\n",
    "ax.plot(epochs, model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at L1 regularization. Will this work better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 16.0063 - accuracy: 0.1461 - val_loss: 15.5960 - val_accuracy: 0.1580\n",
      "Epoch 2/120\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 15.2477 - accuracy: 0.1595 - val_loss: 14.8569 - val_accuracy: 0.1720\n",
      "Epoch 3/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 14.5152 - accuracy: 0.1812 - val_loss: 14.1405 - val_accuracy: 0.1840\n",
      "Epoch 4/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 13.8059 - accuracy: 0.1993 - val_loss: 13.4455 - val_accuracy: 0.2030\n",
      "Epoch 5/120\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 13.1180 - accuracy: 0.2237 - val_loss: 12.7718 - val_accuracy: 0.2250\n",
      "Epoch 6/120\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 12.4511 - accuracy: 0.2504 - val_loss: 12.1184 - val_accuracy: 0.2420\n",
      "Epoch 7/120\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 11.8043 - accuracy: 0.2863 - val_loss: 11.4845 - val_accuracy: 0.2750\n",
      "Epoch 8/120\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 11.1770 - accuracy: 0.3125 - val_loss: 10.8696 - val_accuracy: 0.3220\n",
      "Epoch 9/120\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 10.5689 - accuracy: 0.3471 - val_loss: 10.2741 - val_accuracy: 0.3480\n",
      "Epoch 10/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 9.9798 - accuracy: 0.3852 - val_loss: 9.6977 - val_accuracy: 0.3860\n",
      "Epoch 11/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 9.4114 - accuracy: 0.4347 - val_loss: 9.1434 - val_accuracy: 0.4160\n",
      "Epoch 12/120\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 8.8643 - accuracy: 0.4691 - val_loss: 8.6099 - val_accuracy: 0.4450\n",
      "Epoch 13/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 8.3383 - accuracy: 0.5011 - val_loss: 8.0973 - val_accuracy: 0.4730\n",
      "Epoch 14/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 7.8332 - accuracy: 0.5289 - val_loss: 7.6053 - val_accuracy: 0.4840\n",
      "Epoch 15/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 7.3493 - accuracy: 0.5521 - val_loss: 7.1363 - val_accuracy: 0.5040\n",
      "Epoch 16/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 6.8873 - accuracy: 0.5733 - val_loss: 6.6872 - val_accuracy: 0.5330\n",
      "Epoch 17/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 6.4469 - accuracy: 0.5936 - val_loss: 6.2613 - val_accuracy: 0.5400\n",
      "Epoch 18/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 6.0285 - accuracy: 0.6072 - val_loss: 5.8573 - val_accuracy: 0.5490\n",
      "Epoch 19/120\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 5.6323 - accuracy: 0.6192 - val_loss: 5.4747 - val_accuracy: 0.5750\n",
      "Epoch 20/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 5.2583 - accuracy: 0.6284 - val_loss: 5.1152 - val_accuracy: 0.5800\n",
      "Epoch 21/120\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 4.9059 - accuracy: 0.6384 - val_loss: 4.7768 - val_accuracy: 0.5830\n",
      "Epoch 22/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 4.5756 - accuracy: 0.6429 - val_loss: 4.4596 - val_accuracy: 0.6110\n",
      "Epoch 23/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 4.2669 - accuracy: 0.6580 - val_loss: 4.1631 - val_accuracy: 0.6180\n",
      "Epoch 24/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 3.9796 - accuracy: 0.6571 - val_loss: 3.8888 - val_accuracy: 0.6230\n",
      "Epoch 25/120\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 3.7141 - accuracy: 0.6603 - val_loss: 3.6379 - val_accuracy: 0.6130\n",
      "Epoch 26/120\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 3.4792 - accuracy: 0.66 - 0s 35us/step - loss: 3.4704 - accuracy: 0.6675 - val_loss: 3.4046 - val_accuracy: 0.6270\n",
      "Epoch 27/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 3.2484 - accuracy: 0.6657 - val_loss: 3.1948 - val_accuracy: 0.6370\n",
      "Epoch 28/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 3.0471 - accuracy: 0.6719 - val_loss: 3.0074 - val_accuracy: 0.6330\n",
      "Epoch 29/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.8672 - accuracy: 0.6733 - val_loss: 2.8385 - val_accuracy: 0.6270\n",
      "Epoch 30/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.7083 - accuracy: 0.6755 - val_loss: 2.6911 - val_accuracy: 0.6400\n",
      "Epoch 31/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.5693 - accuracy: 0.6793 - val_loss: 2.5637 - val_accuracy: 0.6450\n",
      "Epoch 32/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.4506 - accuracy: 0.6816 - val_loss: 2.4560 - val_accuracy: 0.6330\n",
      "Epoch 33/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.3511 - accuracy: 0.6792 - val_loss: 2.3668 - val_accuracy: 0.6420\n",
      "Epoch 34/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.2698 - accuracy: 0.6817 - val_loss: 2.2945 - val_accuracy: 0.6450\n",
      "Epoch 35/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.2056 - accuracy: 0.6837 - val_loss: 2.2405 - val_accuracy: 0.6380\n",
      "Epoch 36/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.1576 - accuracy: 0.6837 - val_loss: 2.1994 - val_accuracy: 0.6400\n",
      "Epoch 37/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.1210 - accuracy: 0.6827 - val_loss: 2.1736 - val_accuracy: 0.6360\n",
      "Epoch 38/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.0908 - accuracy: 0.6844 - val_loss: 2.1401 - val_accuracy: 0.6370\n",
      "Epoch 39/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.0638 - accuracy: 0.6863 - val_loss: 2.1147 - val_accuracy: 0.6410\n",
      "Epoch 40/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.0390 - accuracy: 0.6883 - val_loss: 2.0929 - val_accuracy: 0.6390\n",
      "Epoch 41/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 2.0163 - accuracy: 0.6889 - val_loss: 2.0718 - val_accuracy: 0.6420\n",
      "Epoch 42/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.9948 - accuracy: 0.6905 - val_loss: 2.0522 - val_accuracy: 0.6480\n",
      "Epoch 43/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.9746 - accuracy: 0.6908 - val_loss: 2.0323 - val_accuracy: 0.6530\n",
      "Epoch 44/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.9553 - accuracy: 0.6917 - val_loss: 2.0159 - val_accuracy: 0.6500\n",
      "Epoch 45/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.9372 - accuracy: 0.6921 - val_loss: 1.9978 - val_accuracy: 0.6490\n",
      "Epoch 46/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.9196 - accuracy: 0.6939 - val_loss: 1.9806 - val_accuracy: 0.6520\n",
      "Epoch 47/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.9030 - accuracy: 0.6920 - val_loss: 1.9678 - val_accuracy: 0.6500\n",
      "Epoch 48/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.8870 - accuracy: 0.6940 - val_loss: 1.9537 - val_accuracy: 0.6510\n",
      "Epoch 49/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8716 - accuracy: 0.6935 - val_loss: 1.9370 - val_accuracy: 0.6510\n",
      "Epoch 50/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.8565 - accuracy: 0.6944 - val_loss: 1.9237 - val_accuracy: 0.6540\n",
      "Epoch 51/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8423 - accuracy: 0.6960 - val_loss: 1.9114 - val_accuracy: 0.6600\n",
      "Epoch 52/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.8285 - accuracy: 0.6945 - val_loss: 1.8994 - val_accuracy: 0.6590\n",
      "Epoch 53/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.8153 - accuracy: 0.6960 - val_loss: 1.8850 - val_accuracy: 0.6550\n",
      "Epoch 54/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.8023 - accuracy: 0.6975 - val_loss: 1.8725 - val_accuracy: 0.6520\n",
      "Epoch 55/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7896 - accuracy: 0.6976 - val_loss: 1.8620 - val_accuracy: 0.6610\n",
      "Epoch 56/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7777 - accuracy: 0.6979 - val_loss: 1.8513 - val_accuracy: 0.6590\n",
      "Epoch 57/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7659 - accuracy: 0.6973 - val_loss: 1.8419 - val_accuracy: 0.6600\n",
      "Epoch 58/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.7544 - accuracy: 0.6975 - val_loss: 1.8277 - val_accuracy: 0.6630\n",
      "Epoch 59/120\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.7432 - accuracy: 0.6976 - val_loss: 1.8184 - val_accuracy: 0.6530\n",
      "Epoch 60/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7325 - accuracy: 0.6991 - val_loss: 1.8074 - val_accuracy: 0.6610\n",
      "Epoch 61/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7213 - accuracy: 0.7009 - val_loss: 1.7960 - val_accuracy: 0.6610\n",
      "Epoch 62/120\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.7109 - accuracy: 0.7005 - val_loss: 1.7877 - val_accuracy: 0.6600\n",
      "Epoch 63/120\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.7008 - accuracy: 0.7012 - val_loss: 1.7774 - val_accuracy: 0.6610\n",
      "Epoch 64/120\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.6908 - accuracy: 0.7027 - val_loss: 1.7723 - val_accuracy: 0.6580\n",
      "Epoch 65/120\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.6831 - accuracy: 0.69 - 0s 36us/step - loss: 1.6815 - accuracy: 0.7004 - val_loss: 1.7611 - val_accuracy: 0.6610\n",
      "Epoch 66/120\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.6717 - accuracy: 0.7032 - val_loss: 1.7509 - val_accuracy: 0.6620\n",
      "Epoch 67/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.6620 - accuracy: 0.7032 - val_loss: 1.7452 - val_accuracy: 0.6610\n",
      "Epoch 68/120\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.6530 - accuracy: 0.7032 - val_loss: 1.7326 - val_accuracy: 0.6640\n",
      "Epoch 69/120\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.6442 - accuracy: 0.7037 - val_loss: 1.7286 - val_accuracy: 0.6640\n",
      "Epoch 70/120\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.6354 - accuracy: 0.7025 - val_loss: 1.7172 - val_accuracy: 0.6600\n",
      "Epoch 71/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.6268 - accuracy: 0.7035 - val_loss: 1.7084 - val_accuracy: 0.6630\n",
      "Epoch 72/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.6176 - accuracy: 0.7041 - val_loss: 1.6990 - val_accuracy: 0.6610\n",
      "Epoch 73/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.6091 - accuracy: 0.7043 - val_loss: 1.6941 - val_accuracy: 0.6620\n",
      "Epoch 74/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.6011 - accuracy: 0.7049 - val_loss: 1.6831 - val_accuracy: 0.6610\n",
      "Epoch 75/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5926 - accuracy: 0.7047 - val_loss: 1.6762 - val_accuracy: 0.6650\n",
      "Epoch 76/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5844 - accuracy: 0.7055 - val_loss: 1.6699 - val_accuracy: 0.6620\n",
      "Epoch 77/120\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.5765 - accuracy: 0.7051 - val_loss: 1.6607 - val_accuracy: 0.6640\n",
      "Epoch 78/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.5695 - accuracy: 0.7067 - val_loss: 1.6541 - val_accuracy: 0.6630\n",
      "Epoch 79/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5609 - accuracy: 0.7068 - val_loss: 1.6542 - val_accuracy: 0.6610\n",
      "Epoch 80/120\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.5542 - accuracy: 0.7072 - val_loss: 1.6400 - val_accuracy: 0.6600\n",
      "Epoch 81/120\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.5461 - accuracy: 0.7077 - val_loss: 1.6310 - val_accuracy: 0.6620\n",
      "Epoch 82/120\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.5384 - accuracy: 0.7081 - val_loss: 1.6260 - val_accuracy: 0.6640\n",
      "Epoch 83/120\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.5308 - accuracy: 0.7100 - val_loss: 1.6233 - val_accuracy: 0.6610\n",
      "Epoch 84/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5241 - accuracy: 0.7084 - val_loss: 1.6150 - val_accuracy: 0.6660\n",
      "Epoch 85/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.5169 - accuracy: 0.7101 - val_loss: 1.6022 - val_accuracy: 0.6620\n",
      "Epoch 86/120\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.5097 - accuracy: 0.7101 - val_loss: 1.5972 - val_accuracy: 0.6600\n",
      "Epoch 87/120\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.5027 - accuracy: 0.7101 - val_loss: 1.5915 - val_accuracy: 0.6700\n",
      "Epoch 88/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4955 - accuracy: 0.7104 - val_loss: 1.5857 - val_accuracy: 0.6680\n",
      "Epoch 89/120\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.4892 - accuracy: 0.7104 - val_loss: 1.5788 - val_accuracy: 0.6680\n",
      "Epoch 90/120\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 1.4819 - accuracy: 0.7123 - val_loss: 1.5741 - val_accuracy: 0.6640\n",
      "Epoch 91/120\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.4762 - accuracy: 0.7109 - val_loss: 1.5641 - val_accuracy: 0.6670\n",
      "Epoch 92/120\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.4687 - accuracy: 0.7119 - val_loss: 1.5590 - val_accuracy: 0.6680\n",
      "Epoch 93/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4622 - accuracy: 0.7123 - val_loss: 1.5551 - val_accuracy: 0.6690\n",
      "Epoch 94/120\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.4567 - accuracy: 0.7131 - val_loss: 1.5453 - val_accuracy: 0.6670\n",
      "Epoch 95/120\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.4497 - accuracy: 0.7137 - val_loss: 1.5433 - val_accuracy: 0.6660\n",
      "Epoch 96/120\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.4430 - accuracy: 0.7139 - val_loss: 1.5361 - val_accuracy: 0.6680\n",
      "Epoch 97/120\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.4371 - accuracy: 0.7137 - val_loss: 1.5293 - val_accuracy: 0.6670\n",
      "Epoch 98/120\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.4303 - accuracy: 0.7147 - val_loss: 1.5225 - val_accuracy: 0.6680\n",
      "Epoch 99/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4245 - accuracy: 0.7152 - val_loss: 1.5164 - val_accuracy: 0.6710\n",
      "Epoch 100/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4185 - accuracy: 0.7149 - val_loss: 1.5142 - val_accuracy: 0.6770\n",
      "Epoch 101/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4128 - accuracy: 0.7168 - val_loss: 1.5075 - val_accuracy: 0.6680\n",
      "Epoch 102/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4068 - accuracy: 0.7164 - val_loss: 1.5006 - val_accuracy: 0.6710\n",
      "Epoch 103/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4007 - accuracy: 0.7151 - val_loss: 1.4943 - val_accuracy: 0.6710\n",
      "Epoch 104/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3944 - accuracy: 0.7157 - val_loss: 1.4911 - val_accuracy: 0.6730\n",
      "Epoch 105/120\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.3894 - accuracy: 0.7169 - val_loss: 1.4826 - val_accuracy: 0.6700\n",
      "Epoch 106/120\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.3833 - accuracy: 0.7183 - val_loss: 1.4816 - val_accuracy: 0.6790\n",
      "Epoch 107/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3776 - accuracy: 0.7185 - val_loss: 1.4712 - val_accuracy: 0.6750\n",
      "Epoch 108/120\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.3720 - accuracy: 0.7176 - val_loss: 1.4678 - val_accuracy: 0.6710\n",
      "Epoch 109/120\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3667 - accuracy: 0.7179 - val_loss: 1.4613 - val_accuracy: 0.6780\n",
      "Epoch 110/120\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.3612 - accuracy: 0.7193 - val_loss: 1.4589 - val_accuracy: 0.6750\n",
      "Epoch 111/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.3557 - accuracy: 0.7184 - val_loss: 1.4565 - val_accuracy: 0.6810\n",
      "Epoch 112/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3506 - accuracy: 0.7203 - val_loss: 1.4452 - val_accuracy: 0.6770\n",
      "Epoch 113/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3451 - accuracy: 0.7191 - val_loss: 1.4451 - val_accuracy: 0.6690\n",
      "Epoch 114/120\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.3403 - accuracy: 0.7203 - val_loss: 1.4396 - val_accuracy: 0.6710\n",
      "Epoch 115/120\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.3346 - accuracy: 0.7216 - val_loss: 1.4384 - val_accuracy: 0.6720\n",
      "Epoch 116/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3292 - accuracy: 0.7219 - val_loss: 1.4274 - val_accuracy: 0.6710\n",
      "Epoch 117/120\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3239 - accuracy: 0.7227 - val_loss: 1.4209 - val_accuracy: 0.6760\n",
      "Epoch 118/120\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.3196 - accuracy: 0.7232 - val_loss: 1.4216 - val_accuracy: 0.6760\n",
      "Epoch 119/120\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3143 - accuracy: 0.7227 - val_loss: 1.4131 - val_accuracy: 0.6790\n",
      "Epoch 120/120\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.3093 - accuracy: 0.7225 - val_loss: 1.4080 - val_accuracy: 0.6800\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy doesn't reach rates much higher than 70%. It does seem like you can still improve the model by training much longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 16.0061 - accuracy: 0.1571 - val_loss: 15.5918 - val_accuracy: 0.1540\n",
      "Epoch 2/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 15.2424 - accuracy: 0.1668 - val_loss: 14.8487 - val_accuracy: 0.1630\n",
      "Epoch 3/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 14.5099 - accuracy: 0.1776 - val_loss: 14.1308 - val_accuracy: 0.1770\n",
      "Epoch 4/1000\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 13.8008 - accuracy: 0.1983 - val_loss: 13.4346 - val_accuracy: 0.1940\n",
      "Epoch 5/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 13.1129 - accuracy: 0.2197 - val_loss: 12.7590 - val_accuracy: 0.2100\n",
      "Epoch 6/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 12.4453 - accuracy: 0.2392 - val_loss: 12.1046 - val_accuracy: 0.2270\n",
      "Epoch 7/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 11.7985 - accuracy: 0.2573 - val_loss: 11.4712 - val_accuracy: 0.2490\n",
      "Epoch 8/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 11.1727 - accuracy: 0.2745 - val_loss: 10.8591 - val_accuracy: 0.2620\n",
      "Epoch 9/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 10.5679 - accuracy: 0.2897 - val_loss: 10.2676 - val_accuracy: 0.2710\n",
      "Epoch 10/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 9.9842 - accuracy: 0.2984 - val_loss: 9.6979 - val_accuracy: 0.2680\n",
      "Epoch 11/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 9.4208 - accuracy: 0.3087 - val_loss: 9.1476 - val_accuracy: 0.2840\n",
      "Epoch 12/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 8.8784 - accuracy: 0.3184 - val_loss: 8.6196 - val_accuracy: 0.2870\n",
      "Epoch 13/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 8.3570 - accuracy: 0.3289 - val_loss: 8.1115 - val_accuracy: 0.2890\n",
      "Epoch 14/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 7.8562 - accuracy: 0.3335 - val_loss: 7.6234 - val_accuracy: 0.3070\n",
      "Epoch 15/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 7.3756 - accuracy: 0.3440 - val_loss: 7.1564 - val_accuracy: 0.3120\n",
      "Epoch 16/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 6.9169 - accuracy: 0.3561 - val_loss: 6.7116 - val_accuracy: 0.3310\n",
      "Epoch 17/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 6.4801 - accuracy: 0.3759 - val_loss: 6.2888 - val_accuracy: 0.3410\n",
      "Epoch 18/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 6.0654 - accuracy: 0.3945 - val_loss: 5.8880 - val_accuracy: 0.3440\n",
      "Epoch 19/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 5.6729 - accuracy: 0.4055 - val_loss: 5.5089 - val_accuracy: 0.3770\n",
      "Epoch 20/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 5.3015 - accuracy: 0.4232 - val_loss: 5.1498 - val_accuracy: 0.3800\n",
      "Epoch 21/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 4.9485 - accuracy: 0.4512 - val_loss: 4.8075 - val_accuracy: 0.4070\n",
      "Epoch 22/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 4.6149 - accuracy: 0.4700 - val_loss: 4.4883 - val_accuracy: 0.4390\n",
      "Epoch 23/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 4.3044 - accuracy: 0.4888 - val_loss: 4.1918 - val_accuracy: 0.4360\n",
      "Epoch 24/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 4.0162 - accuracy: 0.5000 - val_loss: 3.9168 - val_accuracy: 0.4560\n",
      "Epoch 25/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 3.7506 - accuracy: 0.5129 - val_loss: 3.6669 - val_accuracy: 0.4550\n",
      "Epoch 26/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 3.5076 - accuracy: 0.5208 - val_loss: 3.4356 - val_accuracy: 0.4810\n",
      "Epoch 27/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 3.2865 - accuracy: 0.5313 - val_loss: 3.2270 - val_accuracy: 0.4880\n",
      "Epoch 28/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 3.0871 - accuracy: 0.5355 - val_loss: 3.0408 - val_accuracy: 0.4870\n",
      "Epoch 29/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.9090 - accuracy: 0.5388 - val_loss: 2.8745 - val_accuracy: 0.4980\n",
      "Epoch 30/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.7514 - accuracy: 0.5483 - val_loss: 2.7282 - val_accuracy: 0.5050\n",
      "Epoch 31/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.6139 - accuracy: 0.5561 - val_loss: 2.6037 - val_accuracy: 0.5050\n",
      "Epoch 32/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.4959 - accuracy: 0.5609 - val_loss: 2.4970 - val_accuracy: 0.5170\n",
      "Epoch 33/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.3980 - accuracy: 0.5635 - val_loss: 2.4091 - val_accuracy: 0.5340\n",
      "Epoch 34/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.3184 - accuracy: 0.5735 - val_loss: 2.3408 - val_accuracy: 0.5290\n",
      "Epoch 35/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.2566 - accuracy: 0.5761 - val_loss: 2.2883 - val_accuracy: 0.5470\n",
      "Epoch 36/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 2.2104 - accuracy: 0.5823 - val_loss: 2.2516 - val_accuracy: 0.5460\n",
      "Epoch 37/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 2.1756 - accuracy: 0.5896 - val_loss: 2.2180 - val_accuracy: 0.5500\n",
      "Epoch 38/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 2.1462 - accuracy: 0.5967 - val_loss: 2.1924 - val_accuracy: 0.5530\n",
      "Epoch 39/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.1203 - accuracy: 0.5981 - val_loss: 2.1691 - val_accuracy: 0.5560\n",
      "Epoch 40/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 2.0961 - accuracy: 0.6048 - val_loss: 2.1468 - val_accuracy: 0.5730\n",
      "Epoch 41/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 2.0736 - accuracy: 0.6115 - val_loss: 2.1263 - val_accuracy: 0.5850\n",
      "Epoch 42/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 2.0519 - accuracy: 0.6227 - val_loss: 2.1049 - val_accuracy: 0.5820\n",
      "Epoch 43/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 2.0306 - accuracy: 0.6269 - val_loss: 2.0865 - val_accuracy: 0.5920\n",
      "Epoch 44/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 2.0107 - accuracy: 0.6337 - val_loss: 2.0692 - val_accuracy: 0.5970\n",
      "Epoch 45/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.9916 - accuracy: 0.6396 - val_loss: 2.0488 - val_accuracy: 0.5970\n",
      "Epoch 46/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.9726 - accuracy: 0.6445 - val_loss: 2.0365 - val_accuracy: 0.5980\n",
      "Epoch 47/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.9550 - accuracy: 0.6460 - val_loss: 2.0150 - val_accuracy: 0.6060\n",
      "Epoch 48/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.9373 - accuracy: 0.6499 - val_loss: 2.0020 - val_accuracy: 0.6030\n",
      "Epoch 49/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.9210 - accuracy: 0.6552 - val_loss: 1.9844 - val_accuracy: 0.6130\n",
      "Epoch 50/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.9039 - accuracy: 0.6597 - val_loss: 1.9703 - val_accuracy: 0.6110\n",
      "Epoch 51/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.8882 - accuracy: 0.6620 - val_loss: 1.9537 - val_accuracy: 0.6180\n",
      "Epoch 52/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.8725 - accuracy: 0.6615 - val_loss: 1.9392 - val_accuracy: 0.6220\n",
      "Epoch 53/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.8579 - accuracy: 0.6663 - val_loss: 1.9262 - val_accuracy: 0.6270\n",
      "Epoch 54/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.8432 - accuracy: 0.6685 - val_loss: 1.9113 - val_accuracy: 0.6290\n",
      "Epoch 55/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.8285 - accuracy: 0.6707 - val_loss: 1.9029 - val_accuracy: 0.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.8146 - accuracy: 0.6719 - val_loss: 1.8883 - val_accuracy: 0.6260\n",
      "Epoch 57/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.8013 - accuracy: 0.6747 - val_loss: 1.8739 - val_accuracy: 0.6340\n",
      "Epoch 58/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.7875 - accuracy: 0.6752 - val_loss: 1.8607 - val_accuracy: 0.6440\n",
      "Epoch 59/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.7747 - accuracy: 0.6761 - val_loss: 1.8489 - val_accuracy: 0.6380\n",
      "Epoch 60/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.7615 - accuracy: 0.6785 - val_loss: 1.8359 - val_accuracy: 0.6460\n",
      "Epoch 61/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7490 - accuracy: 0.6796 - val_loss: 1.8248 - val_accuracy: 0.6470\n",
      "Epoch 62/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.7375 - accuracy: 0.6815 - val_loss: 1.8147 - val_accuracy: 0.6390\n",
      "Epoch 63/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7251 - accuracy: 0.6835 - val_loss: 1.8030 - val_accuracy: 0.6480\n",
      "Epoch 64/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.7133 - accuracy: 0.6839 - val_loss: 1.7937 - val_accuracy: 0.6470\n",
      "Epoch 65/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 1.7024 - accuracy: 0.6851 - val_loss: 1.7820 - val_accuracy: 0.6470\n",
      "Epoch 66/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.6915 - accuracy: 0.6857 - val_loss: 1.7714 - val_accuracy: 0.6470\n",
      "Epoch 67/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.6799 - accuracy: 0.6881 - val_loss: 1.7630 - val_accuracy: 0.6510\n",
      "Epoch 68/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.6698 - accuracy: 0.6883 - val_loss: 1.7527 - val_accuracy: 0.6490\n",
      "Epoch 69/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.6591 - accuracy: 0.6905 - val_loss: 1.7442 - val_accuracy: 0.6510\n",
      "Epoch 70/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.6492 - accuracy: 0.6909 - val_loss: 1.7363 - val_accuracy: 0.6550\n",
      "Epoch 71/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.6391 - accuracy: 0.6913 - val_loss: 1.7268 - val_accuracy: 0.6570\n",
      "Epoch 72/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.6294 - accuracy: 0.6931 - val_loss: 1.7167 - val_accuracy: 0.6520\n",
      "Epoch 73/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.6198 - accuracy: 0.6928 - val_loss: 1.7095 - val_accuracy: 0.6550\n",
      "Epoch 74/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.6111 - accuracy: 0.6941 - val_loss: 1.7049 - val_accuracy: 0.6470\n",
      "Epoch 75/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.6019 - accuracy: 0.6941 - val_loss: 1.6910 - val_accuracy: 0.6580\n",
      "Epoch 76/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.5923 - accuracy: 0.6948 - val_loss: 1.6818 - val_accuracy: 0.6570\n",
      "Epoch 77/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.5838 - accuracy: 0.6947 - val_loss: 1.6736 - val_accuracy: 0.6570\n",
      "Epoch 78/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 1.5756 - accuracy: 0.6949 - val_loss: 1.6652 - val_accuracy: 0.6560\n",
      "Epoch 79/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.5665 - accuracy: 0.6953 - val_loss: 1.6578 - val_accuracy: 0.6550\n",
      "Epoch 80/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.5578 - accuracy: 0.6977 - val_loss: 1.6533 - val_accuracy: 0.6590\n",
      "Epoch 81/1000\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 1.5499 - accuracy: 0.6989 - val_loss: 1.6463 - val_accuracy: 0.6600\n",
      "Epoch 82/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.5421 - accuracy: 0.7001 - val_loss: 1.6340 - val_accuracy: 0.6630\n",
      "Epoch 83/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5338 - accuracy: 0.6984 - val_loss: 1.6291 - val_accuracy: 0.6600\n",
      "Epoch 84/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5260 - accuracy: 0.7004 - val_loss: 1.6192 - val_accuracy: 0.6580\n",
      "Epoch 85/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5194 - accuracy: 0.6996 - val_loss: 1.6115 - val_accuracy: 0.6620\n",
      "Epoch 86/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5112 - accuracy: 0.7001 - val_loss: 1.6057 - val_accuracy: 0.6590\n",
      "Epoch 87/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.5041 - accuracy: 0.7015 - val_loss: 1.5994 - val_accuracy: 0.6640\n",
      "Epoch 88/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4961 - accuracy: 0.7012 - val_loss: 1.5925 - val_accuracy: 0.6610\n",
      "Epoch 89/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4893 - accuracy: 0.7025 - val_loss: 1.5874 - val_accuracy: 0.6610\n",
      "Epoch 90/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.4818 - accuracy: 0.7033 - val_loss: 1.5789 - val_accuracy: 0.6600\n",
      "Epoch 91/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4747 - accuracy: 0.7044 - val_loss: 1.5712 - val_accuracy: 0.6630\n",
      "Epoch 92/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.4680 - accuracy: 0.7036 - val_loss: 1.5658 - val_accuracy: 0.6650\n",
      "Epoch 93/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.4614 - accuracy: 0.7032 - val_loss: 1.5585 - val_accuracy: 0.6610\n",
      "Epoch 94/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.4543 - accuracy: 0.7056 - val_loss: 1.5542 - val_accuracy: 0.6600\n",
      "Epoch 95/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.4481 - accuracy: 0.7049 - val_loss: 1.5467 - val_accuracy: 0.6710\n",
      "Epoch 96/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.4410 - accuracy: 0.7065 - val_loss: 1.5419 - val_accuracy: 0.6630\n",
      "Epoch 97/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.4356 - accuracy: 0.7057 - val_loss: 1.5340 - val_accuracy: 0.6690\n",
      "Epoch 98/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4287 - accuracy: 0.7068 - val_loss: 1.5275 - val_accuracy: 0.6680\n",
      "Epoch 99/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.4218 - accuracy: 0.7068 - val_loss: 1.5262 - val_accuracy: 0.6710\n",
      "Epoch 100/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.4162 - accuracy: 0.7080 - val_loss: 1.5172 - val_accuracy: 0.6710\n",
      "Epoch 101/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.4097 - accuracy: 0.7063 - val_loss: 1.5114 - val_accuracy: 0.6690\n",
      "Epoch 102/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.4039 - accuracy: 0.7080 - val_loss: 1.5068 - val_accuracy: 0.6740\n",
      "Epoch 103/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.3978 - accuracy: 0.7080 - val_loss: 1.5045 - val_accuracy: 0.6770\n",
      "Epoch 104/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3922 - accuracy: 0.7076 - val_loss: 1.4990 - val_accuracy: 0.6760\n",
      "Epoch 105/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.3865 - accuracy: 0.7096 - val_loss: 1.4874 - val_accuracy: 0.6750\n",
      "Epoch 106/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3800 - accuracy: 0.7113 - val_loss: 1.4811 - val_accuracy: 0.6770\n",
      "Epoch 107/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.3751 - accuracy: 0.7093 - val_loss: 1.4778 - val_accuracy: 0.6770\n",
      "Epoch 108/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.3691 - accuracy: 0.7101 - val_loss: 1.4731 - val_accuracy: 0.6710\n",
      "Epoch 109/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.3638 - accuracy: 0.7100 - val_loss: 1.4670 - val_accuracy: 0.6690\n",
      "Epoch 110/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.3580 - accuracy: 0.7097 - val_loss: 1.4616 - val_accuracy: 0.6740\n",
      "Epoch 111/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.3530 - accuracy: 0.7119 - val_loss: 1.4569 - val_accuracy: 0.6720\n",
      "Epoch 112/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.3479 - accuracy: 0.7116 - val_loss: 1.4512 - val_accuracy: 0.6820\n",
      "Epoch 113/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.3429 - accuracy: 0.7121 - val_loss: 1.4507 - val_accuracy: 0.6770\n",
      "Epoch 114/1000\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.3376 - accuracy: 0.7135 - val_loss: 1.4450 - val_accuracy: 0.6690\n",
      "Epoch 115/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.3323 - accuracy: 0.7140 - val_loss: 1.4396 - val_accuracy: 0.6830\n",
      "Epoch 116/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.3270 - accuracy: 0.7147 - val_loss: 1.4354 - val_accuracy: 0.6760\n",
      "Epoch 117/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.3228 - accuracy: 0.7137 - val_loss: 1.4264 - val_accuracy: 0.6810\n",
      "Epoch 118/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.3170 - accuracy: 0.7161 - val_loss: 1.4209 - val_accuracy: 0.6770\n",
      "Epoch 119/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.3126 - accuracy: 0.7143 - val_loss: 1.4211 - val_accuracy: 0.6760\n",
      "Epoch 120/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.3079 - accuracy: 0.7145 - val_loss: 1.4167 - val_accuracy: 0.6760\n",
      "Epoch 121/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.3030 - accuracy: 0.7156 - val_loss: 1.4128 - val_accuracy: 0.6820\n",
      "Epoch 122/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.3021 - accuracy: 0.71 - 0s 35us/step - loss: 1.2980 - accuracy: 0.7173 - val_loss: 1.4040 - val_accuracy: 0.6850\n",
      "Epoch 123/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.2935 - accuracy: 0.7184 - val_loss: 1.4015 - val_accuracy: 0.6740\n",
      "Epoch 124/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.2900 - accuracy: 0.7145 - val_loss: 1.3981 - val_accuracy: 0.6820\n",
      "Epoch 125/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.2855 - accuracy: 0.71 - 0s 36us/step - loss: 1.2848 - accuracy: 0.7167 - val_loss: 1.3908 - val_accuracy: 0.6830\n",
      "Epoch 126/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2799 - accuracy: 0.7177 - val_loss: 1.3865 - val_accuracy: 0.6850\n",
      "Epoch 127/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2757 - accuracy: 0.7160 - val_loss: 1.3883 - val_accuracy: 0.6850\n",
      "Epoch 128/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2719 - accuracy: 0.7191 - val_loss: 1.3898 - val_accuracy: 0.6730\n",
      "Epoch 129/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2671 - accuracy: 0.7191 - val_loss: 1.3788 - val_accuracy: 0.6750\n",
      "Epoch 130/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2632 - accuracy: 0.7189 - val_loss: 1.3705 - val_accuracy: 0.6880\n",
      "Epoch 131/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.2580 - accuracy: 0.7204 - val_loss: 1.3730 - val_accuracy: 0.6860\n",
      "Epoch 132/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2542 - accuracy: 0.7205 - val_loss: 1.3694 - val_accuracy: 0.6830\n",
      "Epoch 133/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2504 - accuracy: 0.7211 - val_loss: 1.3582 - val_accuracy: 0.6850\n",
      "Epoch 134/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.2457 - accuracy: 0.7201 - val_loss: 1.3569 - val_accuracy: 0.6830\n",
      "Epoch 135/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.2422 - accuracy: 0.7211 - val_loss: 1.3500 - val_accuracy: 0.6850\n",
      "Epoch 136/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2381 - accuracy: 0.7221 - val_loss: 1.3484 - val_accuracy: 0.6890\n",
      "Epoch 137/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.2340 - accuracy: 0.7239 - val_loss: 1.3419 - val_accuracy: 0.6910\n",
      "Epoch 138/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2301 - accuracy: 0.7227 - val_loss: 1.3433 - val_accuracy: 0.6840\n",
      "Epoch 139/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2263 - accuracy: 0.7223 - val_loss: 1.3353 - val_accuracy: 0.6880\n",
      "Epoch 140/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2226 - accuracy: 0.7213 - val_loss: 1.3403 - val_accuracy: 0.6830\n",
      "Epoch 141/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2191 - accuracy: 0.7225 - val_loss: 1.3274 - val_accuracy: 0.6830\n",
      "Epoch 142/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.2146 - accuracy: 0.7228 - val_loss: 1.3252 - val_accuracy: 0.6910\n",
      "Epoch 143/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2110 - accuracy: 0.7237 - val_loss: 1.3214 - val_accuracy: 0.6870\n",
      "Epoch 144/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.2080 - accuracy: 0.7240 - val_loss: 1.3193 - val_accuracy: 0.6920\n",
      "Epoch 145/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.2047 - accuracy: 0.7240 - val_loss: 1.3172 - val_accuracy: 0.6940\n",
      "Epoch 146/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.2006 - accuracy: 0.7243 - val_loss: 1.3192 - val_accuracy: 0.6890\n",
      "Epoch 147/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.1974 - accuracy: 0.7259 - val_loss: 1.3081 - val_accuracy: 0.6950\n",
      "Epoch 148/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.1944 - accuracy: 0.7263 - val_loss: 1.3053 - val_accuracy: 0.6920\n",
      "Epoch 149/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.1906 - accuracy: 0.7252 - val_loss: 1.3009 - val_accuracy: 0.6940\n",
      "Epoch 150/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1875 - accuracy: 0.7269 - val_loss: 1.3006 - val_accuracy: 0.6940\n",
      "Epoch 151/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1839 - accuracy: 0.7265 - val_loss: 1.2993 - val_accuracy: 0.6820\n",
      "Epoch 152/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1808 - accuracy: 0.7260 - val_loss: 1.2915 - val_accuracy: 0.6910\n",
      "Epoch 153/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.1776 - accuracy: 0.7271 - val_loss: 1.2893 - val_accuracy: 0.6920\n",
      "Epoch 154/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.1745 - accuracy: 0.7277 - val_loss: 1.2888 - val_accuracy: 0.6940\n",
      "Epoch 155/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.1717 - accuracy: 0.7269 - val_loss: 1.2825 - val_accuracy: 0.6900\n",
      "Epoch 156/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1679 - accuracy: 0.7280 - val_loss: 1.2787 - val_accuracy: 0.6950\n",
      "Epoch 157/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.1655 - accuracy: 0.7279 - val_loss: 1.2796 - val_accuracy: 0.7020\n",
      "Epoch 158/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1625 - accuracy: 0.7291 - val_loss: 1.2929 - val_accuracy: 0.6930\n",
      "Epoch 159/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.1599 - accuracy: 0.7297 - val_loss: 1.2718 - val_accuracy: 0.6980\n",
      "Epoch 160/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.1563 - accuracy: 0.7303 - val_loss: 1.2707 - val_accuracy: 0.6990\n",
      "Epoch 161/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 1.1539 - accuracy: 0.7291 - val_loss: 1.2704 - val_accuracy: 0.6960\n",
      "Epoch 162/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.1502 - accuracy: 0.7311 - val_loss: 1.2683 - val_accuracy: 0.6860\n",
      "Epoch 163/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.1488 - accuracy: 0.7303 - val_loss: 1.2589 - val_accuracy: 0.6930\n",
      "Epoch 164/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.1451 - accuracy: 0.7285 - val_loss: 1.2588 - val_accuracy: 0.6900\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1426 - accuracy: 0.7328 - val_loss: 1.2562 - val_accuracy: 0.6970\n",
      "Epoch 166/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.1398 - accuracy: 0.7305 - val_loss: 1.2574 - val_accuracy: 0.6930\n",
      "Epoch 167/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.1370 - accuracy: 0.7316 - val_loss: 1.2493 - val_accuracy: 0.6930\n",
      "Epoch 168/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1339 - accuracy: 0.7321 - val_loss: 1.2497 - val_accuracy: 0.6970\n",
      "Epoch 169/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1319 - accuracy: 0.7313 - val_loss: 1.2462 - val_accuracy: 0.6920\n",
      "Epoch 170/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1288 - accuracy: 0.7319 - val_loss: 1.2426 - val_accuracy: 0.6890\n",
      "Epoch 171/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1270 - accuracy: 0.7316 - val_loss: 1.2425 - val_accuracy: 0.6900\n",
      "Epoch 172/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1245 - accuracy: 0.7319 - val_loss: 1.2396 - val_accuracy: 0.6950\n",
      "Epoch 173/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1215 - accuracy: 0.7339 - val_loss: 1.2390 - val_accuracy: 0.6950\n",
      "Epoch 174/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.1199 - accuracy: 0.7332 - val_loss: 1.2321 - val_accuracy: 0.6970\n",
      "Epoch 175/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1178 - accuracy: 0.7333 - val_loss: 1.2392 - val_accuracy: 0.6950\n",
      "Epoch 176/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.1154 - accuracy: 0.7329 - val_loss: 1.2302 - val_accuracy: 0.6920\n",
      "Epoch 177/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.1138 - accuracy: 0.7333 - val_loss: 1.2299 - val_accuracy: 0.6890\n",
      "Epoch 178/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 1.1109 - accuracy: 0.7340 - val_loss: 1.2257 - val_accuracy: 0.6990\n",
      "Epoch 179/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.1084 - accuracy: 0.7343 - val_loss: 1.2233 - val_accuracy: 0.6980\n",
      "Epoch 180/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1065 - accuracy: 0.7345 - val_loss: 1.2213 - val_accuracy: 0.6960\n",
      "Epoch 181/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1046 - accuracy: 0.7353 - val_loss: 1.2216 - val_accuracy: 0.6920\n",
      "Epoch 182/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.1023 - accuracy: 0.7343 - val_loss: 1.2354 - val_accuracy: 0.6880\n",
      "Epoch 183/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.1010 - accuracy: 0.7376 - val_loss: 1.2165 - val_accuracy: 0.6970\n",
      "Epoch 184/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.0988 - accuracy: 0.7356 - val_loss: 1.2237 - val_accuracy: 0.6970\n",
      "Epoch 185/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0971 - accuracy: 0.7367 - val_loss: 1.2147 - val_accuracy: 0.6930\n",
      "Epoch 186/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0956 - accuracy: 0.7361 - val_loss: 1.2132 - val_accuracy: 0.6950\n",
      "Epoch 187/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0929 - accuracy: 0.7363 - val_loss: 1.2088 - val_accuracy: 0.6960\n",
      "Epoch 188/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0921 - accuracy: 0.7379 - val_loss: 1.2134 - val_accuracy: 0.6920\n",
      "Epoch 189/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.0899 - accuracy: 0.7384 - val_loss: 1.2059 - val_accuracy: 0.6980\n",
      "Epoch 190/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 1.0873 - accuracy: 0.7392 - val_loss: 1.2099 - val_accuracy: 0.6960\n",
      "Epoch 191/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.0866 - accuracy: 0.7367 - val_loss: 1.2029 - val_accuracy: 0.6990\n",
      "Epoch 192/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0850 - accuracy: 0.7381 - val_loss: 1.2028 - val_accuracy: 0.6990\n",
      "Epoch 193/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 1.0830 - accuracy: 0.73 - 0s 36us/step - loss: 1.0825 - accuracy: 0.7388 - val_loss: 1.2100 - val_accuracy: 0.6980\n",
      "Epoch 194/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.0822 - accuracy: 0.7369 - val_loss: 1.2055 - val_accuracy: 0.6980\n",
      "Epoch 195/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0804 - accuracy: 0.7364 - val_loss: 1.2024 - val_accuracy: 0.6990\n",
      "Epoch 196/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0783 - accuracy: 0.7385 - val_loss: 1.2042 - val_accuracy: 0.6960\n",
      "Epoch 197/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0767 - accuracy: 0.7389 - val_loss: 1.1978 - val_accuracy: 0.7020\n",
      "Epoch 198/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0755 - accuracy: 0.7409 - val_loss: 1.1929 - val_accuracy: 0.7010\n",
      "Epoch 199/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0738 - accuracy: 0.7384 - val_loss: 1.1918 - val_accuracy: 0.6930\n",
      "Epoch 200/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 1.0716 - accuracy: 0.7396 - val_loss: 1.1891 - val_accuracy: 0.6990\n",
      "Epoch 201/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0700 - accuracy: 0.7401 - val_loss: 1.1911 - val_accuracy: 0.7030\n",
      "Epoch 202/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0697 - accuracy: 0.7399 - val_loss: 1.1888 - val_accuracy: 0.6980\n",
      "Epoch 203/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0672 - accuracy: 0.7409 - val_loss: 1.1883 - val_accuracy: 0.6990\n",
      "Epoch 204/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0664 - accuracy: 0.7403 - val_loss: 1.1879 - val_accuracy: 0.7010\n",
      "Epoch 205/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0649 - accuracy: 0.7413 - val_loss: 1.1830 - val_accuracy: 0.7000\n",
      "Epoch 206/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0634 - accuracy: 0.7408 - val_loss: 1.1822 - val_accuracy: 0.7060\n",
      "Epoch 207/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0614 - accuracy: 0.7437 - val_loss: 1.1939 - val_accuracy: 0.6990\n",
      "Epoch 208/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0605 - accuracy: 0.7409 - val_loss: 1.1809 - val_accuracy: 0.7010\n",
      "Epoch 209/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0588 - accuracy: 0.7401 - val_loss: 1.1847 - val_accuracy: 0.7020\n",
      "Epoch 210/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.0576 - accuracy: 0.7429 - val_loss: 1.1786 - val_accuracy: 0.6970\n",
      "Epoch 211/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.0555 - accuracy: 0.7424 - val_loss: 1.1850 - val_accuracy: 0.7020\n",
      "Epoch 212/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0558 - accuracy: 0.7433 - val_loss: 1.1778 - val_accuracy: 0.6980\n",
      "Epoch 213/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0530 - accuracy: 0.7432 - val_loss: 1.1733 - val_accuracy: 0.7010\n",
      "Epoch 214/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 1.0520 - accuracy: 0.7425 - val_loss: 1.1781 - val_accuracy: 0.7010\n",
      "Epoch 215/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0508 - accuracy: 0.7417 - val_loss: 1.1724 - val_accuracy: 0.6990\n",
      "Epoch 216/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0494 - accuracy: 0.7431 - val_loss: 1.1747 - val_accuracy: 0.7000\n",
      "Epoch 217/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0481 - accuracy: 0.7443 - val_loss: 1.1707 - val_accuracy: 0.7000\n",
      "Epoch 218/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0464 - accuracy: 0.7423 - val_loss: 1.1698 - val_accuracy: 0.7000\n",
      "Epoch 219/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0450 - accuracy: 0.7428 - val_loss: 1.1776 - val_accuracy: 0.7010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0439 - accuracy: 0.7437 - val_loss: 1.1669 - val_accuracy: 0.7070\n",
      "Epoch 221/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0428 - accuracy: 0.7437 - val_loss: 1.1838 - val_accuracy: 0.6920\n",
      "Epoch 222/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0427 - accuracy: 0.7421 - val_loss: 1.1657 - val_accuracy: 0.7020\n",
      "Epoch 223/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0402 - accuracy: 0.7437 - val_loss: 1.1617 - val_accuracy: 0.7040\n",
      "Epoch 224/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 1.0392 - accuracy: 0.7424 - val_loss: 1.1646 - val_accuracy: 0.7050\n",
      "Epoch 225/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0387 - accuracy: 0.7456 - val_loss: 1.1608 - val_accuracy: 0.7060\n",
      "Epoch 226/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0370 - accuracy: 0.7447 - val_loss: 1.1617 - val_accuracy: 0.7050\n",
      "Epoch 227/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 1.0359 - accuracy: 0.7425 - val_loss: 1.1576 - val_accuracy: 0.7080\n",
      "Epoch 228/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 1.0347 - accuracy: 0.7439 - val_loss: 1.1587 - val_accuracy: 0.7020\n",
      "Epoch 229/1000\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.0336 - accuracy: 0.7460 - val_loss: 1.1647 - val_accuracy: 0.7040\n",
      "Epoch 230/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0320 - accuracy: 0.7460 - val_loss: 1.1581 - val_accuracy: 0.7050\n",
      "Epoch 231/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0311 - accuracy: 0.7459 - val_loss: 1.1556 - val_accuracy: 0.7020\n",
      "Epoch 232/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.0292 - accuracy: 0.7465 - val_loss: 1.1611 - val_accuracy: 0.7020\n",
      "Epoch 233/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.0288 - accuracy: 0.7441 - val_loss: 1.1600 - val_accuracy: 0.7060\n",
      "Epoch 234/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.0275 - accuracy: 0.7451 - val_loss: 1.1639 - val_accuracy: 0.7010\n",
      "Epoch 235/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.0271 - accuracy: 0.7447 - val_loss: 1.1841 - val_accuracy: 0.6870\n",
      "Epoch 236/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 1.0261 - accuracy: 0.7456 - val_loss: 1.1495 - val_accuracy: 0.7090\n",
      "Epoch 237/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 1.0248 - accuracy: 0.7463 - val_loss: 1.1515 - val_accuracy: 0.7100\n",
      "Epoch 238/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0232 - accuracy: 0.7471 - val_loss: 1.1505 - val_accuracy: 0.7040\n",
      "Epoch 239/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 1.0216 - accuracy: 0.7479 - val_loss: 1.1605 - val_accuracy: 0.7070\n",
      "Epoch 240/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0213 - accuracy: 0.7477 - val_loss: 1.1462 - val_accuracy: 0.7110\n",
      "Epoch 241/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0196 - accuracy: 0.7495 - val_loss: 1.1459 - val_accuracy: 0.7110\n",
      "Epoch 242/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0190 - accuracy: 0.7459 - val_loss: 1.1504 - val_accuracy: 0.7090\n",
      "Epoch 243/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0176 - accuracy: 0.7479 - val_loss: 1.1505 - val_accuracy: 0.7020\n",
      "Epoch 244/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0177 - accuracy: 0.7463 - val_loss: 1.1487 - val_accuracy: 0.7100\n",
      "Epoch 245/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0155 - accuracy: 0.7481 - val_loss: 1.1480 - val_accuracy: 0.7060\n",
      "Epoch 246/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0152 - accuracy: 0.7487 - val_loss: 1.1426 - val_accuracy: 0.7060\n",
      "Epoch 247/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0141 - accuracy: 0.7489 - val_loss: 1.1411 - val_accuracy: 0.7080\n",
      "Epoch 248/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0139 - accuracy: 0.7476 - val_loss: 1.1412 - val_accuracy: 0.7120\n",
      "Epoch 249/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0112 - accuracy: 0.7484 - val_loss: 1.1435 - val_accuracy: 0.7080\n",
      "Epoch 250/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0111 - accuracy: 0.7500 - val_loss: 1.1425 - val_accuracy: 0.7060\n",
      "Epoch 251/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0098 - accuracy: 0.7495 - val_loss: 1.1428 - val_accuracy: 0.7070\n",
      "Epoch 252/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0087 - accuracy: 0.7496 - val_loss: 1.1472 - val_accuracy: 0.7030\n",
      "Epoch 253/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 1.0082 - accuracy: 0.7488 - val_loss: 1.1356 - val_accuracy: 0.7130\n",
      "Epoch 254/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0070 - accuracy: 0.7491 - val_loss: 1.1524 - val_accuracy: 0.6970\n",
      "Epoch 255/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.0060 - accuracy: 0.7487 - val_loss: 1.1345 - val_accuracy: 0.7070\n",
      "Epoch 256/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.0048 - accuracy: 0.7497 - val_loss: 1.1370 - val_accuracy: 0.7050\n",
      "Epoch 257/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 1.0037 - accuracy: 0.7501 - val_loss: 1.1352 - val_accuracy: 0.7080\n",
      "Epoch 258/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 1.0035 - accuracy: 0.7488 - val_loss: 1.1362 - val_accuracy: 0.7110\n",
      "Epoch 259/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 1.0021 - accuracy: 0.7488 - val_loss: 1.1408 - val_accuracy: 0.7110\n",
      "Epoch 260/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.0014 - accuracy: 0.7513 - val_loss: 1.1325 - val_accuracy: 0.7090\n",
      "Epoch 261/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.9996 - accuracy: 0.7520 - val_loss: 1.1298 - val_accuracy: 0.7130\n",
      "Epoch 262/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9998 - accuracy: 0.7517 - val_loss: 1.1365 - val_accuracy: 0.7080\n",
      "Epoch 263/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.9987 - accuracy: 0.7499 - val_loss: 1.1373 - val_accuracy: 0.7080\n",
      "Epoch 264/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9971 - accuracy: 0.7527 - val_loss: 1.1327 - val_accuracy: 0.7090\n",
      "Epoch 265/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.9963 - accuracy: 0.7489 - val_loss: 1.1405 - val_accuracy: 0.7060\n",
      "Epoch 266/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9958 - accuracy: 0.7517 - val_loss: 1.1457 - val_accuracy: 0.7100\n",
      "Epoch 267/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9957 - accuracy: 0.7525 - val_loss: 1.1317 - val_accuracy: 0.7140\n",
      "Epoch 268/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9954 - accuracy: 0.7515 - val_loss: 1.1342 - val_accuracy: 0.7070\n",
      "Epoch 269/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9932 - accuracy: 0.7501 - val_loss: 1.1245 - val_accuracy: 0.7160\n",
      "Epoch 270/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.9920 - accuracy: 0.7519 - val_loss: 1.1242 - val_accuracy: 0.7120\n",
      "Epoch 271/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9919 - accuracy: 0.7524 - val_loss: 1.1373 - val_accuracy: 0.7090\n",
      "Epoch 272/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9904 - accuracy: 0.7540 - val_loss: 1.1311 - val_accuracy: 0.7100\n",
      "Epoch 273/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.9892 - accuracy: 0.7509 - val_loss: 1.1211 - val_accuracy: 0.7120\n",
      "Epoch 274/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9884 - accuracy: 0.7529 - val_loss: 1.1224 - val_accuracy: 0.7160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9875 - accuracy: 0.7552 - val_loss: 1.1236 - val_accuracy: 0.7140\n",
      "Epoch 276/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9865 - accuracy: 0.7541 - val_loss: 1.1258 - val_accuracy: 0.7160\n",
      "Epoch 277/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.9857 - accuracy: 0.7532 - val_loss: 1.1191 - val_accuracy: 0.7150\n",
      "Epoch 278/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9847 - accuracy: 0.7533 - val_loss: 1.1213 - val_accuracy: 0.7140\n",
      "Epoch 279/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9848 - accuracy: 0.7551 - val_loss: 1.1171 - val_accuracy: 0.7120\n",
      "Epoch 280/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9841 - accuracy: 0.7523 - val_loss: 1.1197 - val_accuracy: 0.7120\n",
      "Epoch 281/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9822 - accuracy: 0.7535 - val_loss: 1.1160 - val_accuracy: 0.7160\n",
      "Epoch 282/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9816 - accuracy: 0.7535 - val_loss: 1.1264 - val_accuracy: 0.7100\n",
      "Epoch 283/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9811 - accuracy: 0.7533 - val_loss: 1.1200 - val_accuracy: 0.7120\n",
      "Epoch 284/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9793 - accuracy: 0.7567 - val_loss: 1.1141 - val_accuracy: 0.7150\n",
      "Epoch 285/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9789 - accuracy: 0.7547 - val_loss: 1.1175 - val_accuracy: 0.7170\n",
      "Epoch 286/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9779 - accuracy: 0.7565 - val_loss: 1.1145 - val_accuracy: 0.7160\n",
      "Epoch 287/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.9781 - accuracy: 0.7540 - val_loss: 1.1150 - val_accuracy: 0.7160\n",
      "Epoch 288/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9766 - accuracy: 0.7553 - val_loss: 1.1133 - val_accuracy: 0.7120\n",
      "Epoch 289/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9752 - accuracy: 0.7552 - val_loss: 1.1118 - val_accuracy: 0.7140\n",
      "Epoch 290/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9749 - accuracy: 0.7576 - val_loss: 1.1128 - val_accuracy: 0.7180\n",
      "Epoch 291/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9740 - accuracy: 0.7544 - val_loss: 1.1111 - val_accuracy: 0.7160\n",
      "Epoch 292/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.9737 - accuracy: 0.7559 - val_loss: 1.1077 - val_accuracy: 0.7230\n",
      "Epoch 293/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9733 - accuracy: 0.7553 - val_loss: 1.1138 - val_accuracy: 0.7200\n",
      "Epoch 294/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9725 - accuracy: 0.7564 - val_loss: 1.1143 - val_accuracy: 0.7180\n",
      "Epoch 295/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9705 - accuracy: 0.7553 - val_loss: 1.1190 - val_accuracy: 0.7180\n",
      "Epoch 296/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9708 - accuracy: 0.7555 - val_loss: 1.1088 - val_accuracy: 0.7120\n",
      "Epoch 297/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9694 - accuracy: 0.7575 - val_loss: 1.1067 - val_accuracy: 0.7180\n",
      "Epoch 298/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9685 - accuracy: 0.7560 - val_loss: 1.1133 - val_accuracy: 0.7140\n",
      "Epoch 299/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.9676 - accuracy: 0.7563 - val_loss: 1.1210 - val_accuracy: 0.7110\n",
      "Epoch 300/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9692 - accuracy: 0.7565 - val_loss: 1.1047 - val_accuracy: 0.7130\n",
      "Epoch 301/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9663 - accuracy: 0.7580 - val_loss: 1.1072 - val_accuracy: 0.7140\n",
      "Epoch 302/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.9654 - accuracy: 0.7580 - val_loss: 1.1054 - val_accuracy: 0.7210\n",
      "Epoch 303/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9656 - accuracy: 0.7577 - val_loss: 1.1107 - val_accuracy: 0.7160\n",
      "Epoch 304/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9648 - accuracy: 0.7593 - val_loss: 1.1079 - val_accuracy: 0.7160\n",
      "Epoch 305/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.9628 - accuracy: 0.7573 - val_loss: 1.1093 - val_accuracy: 0.7180\n",
      "Epoch 306/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9632 - accuracy: 0.7572 - val_loss: 1.1189 - val_accuracy: 0.7160\n",
      "Epoch 307/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.9629 - accuracy: 0.7580 - val_loss: 1.1028 - val_accuracy: 0.7210\n",
      "Epoch 308/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9619 - accuracy: 0.7585 - val_loss: 1.1091 - val_accuracy: 0.7180\n",
      "Epoch 309/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9605 - accuracy: 0.7585 - val_loss: 1.1124 - val_accuracy: 0.7190\n",
      "Epoch 310/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9603 - accuracy: 0.7573 - val_loss: 1.1118 - val_accuracy: 0.7110\n",
      "Epoch 311/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9604 - accuracy: 0.7585 - val_loss: 1.1162 - val_accuracy: 0.7160\n",
      "Epoch 312/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9600 - accuracy: 0.7561 - val_loss: 1.1095 - val_accuracy: 0.7160\n",
      "Epoch 313/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9586 - accuracy: 0.7591 - val_loss: 1.0997 - val_accuracy: 0.7190\n",
      "Epoch 314/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9575 - accuracy: 0.7600 - val_loss: 1.0998 - val_accuracy: 0.7180\n",
      "Epoch 315/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9570 - accuracy: 0.7579 - val_loss: 1.1127 - val_accuracy: 0.7160\n",
      "Epoch 316/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9568 - accuracy: 0.7589 - val_loss: 1.0970 - val_accuracy: 0.7200\n",
      "Epoch 317/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9562 - accuracy: 0.7589 - val_loss: 1.1002 - val_accuracy: 0.7230\n",
      "Epoch 318/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9553 - accuracy: 0.7601 - val_loss: 1.1012 - val_accuracy: 0.7220\n",
      "Epoch 319/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9543 - accuracy: 0.7595 - val_loss: 1.0989 - val_accuracy: 0.7190\n",
      "Epoch 320/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.9538 - accuracy: 0.7601 - val_loss: 1.0943 - val_accuracy: 0.7180\n",
      "Epoch 321/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9533 - accuracy: 0.7599 - val_loss: 1.0942 - val_accuracy: 0.7220\n",
      "Epoch 322/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.9528 - accuracy: 0.7604 - val_loss: 1.0954 - val_accuracy: 0.7160\n",
      "Epoch 323/1000\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.9510 - accuracy: 0.7631 - val_loss: 1.1119 - val_accuracy: 0.7200\n",
      "Epoch 324/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9511 - accuracy: 0.7600 - val_loss: 1.1014 - val_accuracy: 0.7220\n",
      "Epoch 325/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9513 - accuracy: 0.7585 - val_loss: 1.0992 - val_accuracy: 0.7220\n",
      "Epoch 326/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9492 - accuracy: 0.7605 - val_loss: 1.1013 - val_accuracy: 0.7230\n",
      "Epoch 327/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9503 - accuracy: 0.7591 - val_loss: 1.0935 - val_accuracy: 0.7190\n",
      "Epoch 328/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.9479 - accuracy: 0.7624 - val_loss: 1.0985 - val_accuracy: 0.7180\n",
      "Epoch 329/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9471 - accuracy: 0.7624 - val_loss: 1.0923 - val_accuracy: 0.7180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9477 - accuracy: 0.7599 - val_loss: 1.0913 - val_accuracy: 0.7200\n",
      "Epoch 331/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.9476 - accuracy: 0.7608 - val_loss: 1.0954 - val_accuracy: 0.7180\n",
      "Epoch 332/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9457 - accuracy: 0.7620 - val_loss: 1.0946 - val_accuracy: 0.7220\n",
      "Epoch 333/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.9460 - accuracy: 0.7604 - val_loss: 1.0944 - val_accuracy: 0.7260\n",
      "Epoch 334/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.9449 - accuracy: 0.7623 - val_loss: 1.0882 - val_accuracy: 0.7200\n",
      "Epoch 335/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9449 - accuracy: 0.7593 - val_loss: 1.0933 - val_accuracy: 0.7170\n",
      "Epoch 336/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9434 - accuracy: 0.7621 - val_loss: 1.0891 - val_accuracy: 0.7230\n",
      "Epoch 337/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9428 - accuracy: 0.7625 - val_loss: 1.0998 - val_accuracy: 0.7180\n",
      "Epoch 338/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9427 - accuracy: 0.7612 - val_loss: 1.1202 - val_accuracy: 0.7080\n",
      "Epoch 339/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9430 - accuracy: 0.7617 - val_loss: 1.1089 - val_accuracy: 0.7170\n",
      "Epoch 340/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9427 - accuracy: 0.7609 - val_loss: 1.0920 - val_accuracy: 0.7210\n",
      "Epoch 341/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9416 - accuracy: 0.7627 - val_loss: 1.0997 - val_accuracy: 0.7190\n",
      "Epoch 342/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9408 - accuracy: 0.7639 - val_loss: 1.0905 - val_accuracy: 0.7210\n",
      "Epoch 343/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9407 - accuracy: 0.7621 - val_loss: 1.0983 - val_accuracy: 0.7170\n",
      "Epoch 344/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.9386 - accuracy: 0.7613 - val_loss: 1.0870 - val_accuracy: 0.7250\n",
      "Epoch 345/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9389 - accuracy: 0.7635 - val_loss: 1.0864 - val_accuracy: 0.7210\n",
      "Epoch 346/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9376 - accuracy: 0.7631 - val_loss: 1.0987 - val_accuracy: 0.7240\n",
      "Epoch 347/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9385 - accuracy: 0.7640 - val_loss: 1.0856 - val_accuracy: 0.7220\n",
      "Epoch 348/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9378 - accuracy: 0.7609 - val_loss: 1.0831 - val_accuracy: 0.7220\n",
      "Epoch 349/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9367 - accuracy: 0.7635 - val_loss: 1.0830 - val_accuracy: 0.7200\n",
      "Epoch 350/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9352 - accuracy: 0.7636 - val_loss: 1.0901 - val_accuracy: 0.7200\n",
      "Epoch 351/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9349 - accuracy: 0.7649 - val_loss: 1.0815 - val_accuracy: 0.7250\n",
      "Epoch 352/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.9355 - accuracy: 0.7623 - val_loss: 1.0909 - val_accuracy: 0.7190\n",
      "Epoch 353/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9347 - accuracy: 0.7653 - val_loss: 1.0895 - val_accuracy: 0.7210\n",
      "Epoch 354/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9336 - accuracy: 0.7635 - val_loss: 1.0982 - val_accuracy: 0.7190\n",
      "Epoch 355/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9335 - accuracy: 0.7655 - val_loss: 1.0851 - val_accuracy: 0.7230\n",
      "Epoch 356/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9332 - accuracy: 0.7628 - val_loss: 1.0849 - val_accuracy: 0.7230\n",
      "Epoch 357/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9327 - accuracy: 0.7648 - val_loss: 1.0896 - val_accuracy: 0.7230\n",
      "Epoch 358/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9337 - accuracy: 0.7645 - val_loss: 1.0832 - val_accuracy: 0.7210\n",
      "Epoch 359/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9304 - accuracy: 0.7640 - val_loss: 1.0940 - val_accuracy: 0.7190\n",
      "Epoch 360/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9308 - accuracy: 0.7633 - val_loss: 1.1033 - val_accuracy: 0.7090\n",
      "Epoch 361/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9310 - accuracy: 0.7653 - val_loss: 1.0825 - val_accuracy: 0.7240\n",
      "Epoch 362/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9293 - accuracy: 0.7657 - val_loss: 1.0842 - val_accuracy: 0.7220\n",
      "Epoch 363/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.9287 - accuracy: 0.7653 - val_loss: 1.0802 - val_accuracy: 0.7220\n",
      "Epoch 364/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9289 - accuracy: 0.7655 - val_loss: 1.0857 - val_accuracy: 0.7210\n",
      "Epoch 365/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9291 - accuracy: 0.7647 - val_loss: 1.0823 - val_accuracy: 0.7220\n",
      "Epoch 366/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9268 - accuracy: 0.7635 - val_loss: 1.0802 - val_accuracy: 0.7250\n",
      "Epoch 367/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9268 - accuracy: 0.7669 - val_loss: 1.1074 - val_accuracy: 0.7140\n",
      "Epoch 368/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9263 - accuracy: 0.7663 - val_loss: 1.0797 - val_accuracy: 0.7240\n",
      "Epoch 369/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9255 - accuracy: 0.7676 - val_loss: 1.0778 - val_accuracy: 0.7230\n",
      "Epoch 370/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9253 - accuracy: 0.7657 - val_loss: 1.0800 - val_accuracy: 0.7220\n",
      "Epoch 371/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9247 - accuracy: 0.7631 - val_loss: 1.0877 - val_accuracy: 0.7150\n",
      "Epoch 372/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.9244 - accuracy: 0.7645 - val_loss: 1.0780 - val_accuracy: 0.7280\n",
      "Epoch 373/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9243 - accuracy: 0.7651 - val_loss: 1.0756 - val_accuracy: 0.7290\n",
      "Epoch 374/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9240 - accuracy: 0.7661 - val_loss: 1.0760 - val_accuracy: 0.7270\n",
      "Epoch 375/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9230 - accuracy: 0.7679 - val_loss: 1.0835 - val_accuracy: 0.7200\n",
      "Epoch 376/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9226 - accuracy: 0.7675 - val_loss: 1.0756 - val_accuracy: 0.7270\n",
      "Epoch 377/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9225 - accuracy: 0.7684 - val_loss: 1.0797 - val_accuracy: 0.7240\n",
      "Epoch 378/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9223 - accuracy: 0.7657 - val_loss: 1.0752 - val_accuracy: 0.7330\n",
      "Epoch 379/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9220 - accuracy: 0.7673 - val_loss: 1.0720 - val_accuracy: 0.7290\n",
      "Epoch 380/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9206 - accuracy: 0.7679 - val_loss: 1.0747 - val_accuracy: 0.7280\n",
      "Epoch 381/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9201 - accuracy: 0.7664 - val_loss: 1.0760 - val_accuracy: 0.7270\n",
      "Epoch 382/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9217 - accuracy: 0.7669 - val_loss: 1.0778 - val_accuracy: 0.7270\n",
      "Epoch 383/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.9188 - accuracy: 0.7691 - val_loss: 1.0794 - val_accuracy: 0.7240\n",
      "Epoch 384/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.9191 - accuracy: 0.7675 - val_loss: 1.0885 - val_accuracy: 0.7230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9198 - accuracy: 0.7672 - val_loss: 1.1090 - val_accuracy: 0.7070\n",
      "Epoch 386/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9204 - accuracy: 0.7659 - val_loss: 1.0763 - val_accuracy: 0.7250\n",
      "Epoch 387/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9185 - accuracy: 0.7665 - val_loss: 1.1073 - val_accuracy: 0.7100\n",
      "Epoch 388/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9193 - accuracy: 0.7657 - val_loss: 1.0762 - val_accuracy: 0.7250\n",
      "Epoch 389/1000\n",
      "7500/7500 [==============================] - 0s 33us/step - loss: 0.9184 - accuracy: 0.7668 - val_loss: 1.0803 - val_accuracy: 0.7220\n",
      "Epoch 390/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9162 - accuracy: 0.7679 - val_loss: 1.0848 - val_accuracy: 0.7180\n",
      "Epoch 391/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9163 - accuracy: 0.7695 - val_loss: 1.0770 - val_accuracy: 0.7310\n",
      "Epoch 392/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9165 - accuracy: 0.7669 - val_loss: 1.0693 - val_accuracy: 0.7320\n",
      "Epoch 393/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.9168 - accuracy: 0.7655 - val_loss: 1.0692 - val_accuracy: 0.7320\n",
      "Epoch 394/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9151 - accuracy: 0.7677 - val_loss: 1.0749 - val_accuracy: 0.7260\n",
      "Epoch 395/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9139 - accuracy: 0.7705 - val_loss: 1.0775 - val_accuracy: 0.7280\n",
      "Epoch 396/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9141 - accuracy: 0.7677 - val_loss: 1.0779 - val_accuracy: 0.7230\n",
      "Epoch 397/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9145 - accuracy: 0.7691 - val_loss: 1.1059 - val_accuracy: 0.7090\n",
      "Epoch 398/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9140 - accuracy: 0.7693 - val_loss: 1.0750 - val_accuracy: 0.7230\n",
      "Epoch 399/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9131 - accuracy: 0.7692 - val_loss: 1.0753 - val_accuracy: 0.7290\n",
      "Epoch 400/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9149 - accuracy: 0.7665 - val_loss: 1.0709 - val_accuracy: 0.7270\n",
      "Epoch 401/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.9132 - accuracy: 0.7681 - val_loss: 1.0832 - val_accuracy: 0.7240\n",
      "Epoch 402/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9123 - accuracy: 0.7693 - val_loss: 1.0768 - val_accuracy: 0.7260\n",
      "Epoch 403/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9115 - accuracy: 0.7697 - val_loss: 1.0687 - val_accuracy: 0.7310\n",
      "Epoch 404/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9108 - accuracy: 0.7692 - val_loss: 1.1014 - val_accuracy: 0.7130\n",
      "Epoch 405/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9107 - accuracy: 0.7716 - val_loss: 1.0737 - val_accuracy: 0.7300\n",
      "Epoch 406/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9104 - accuracy: 0.7684 - val_loss: 1.0913 - val_accuracy: 0.7230\n",
      "Epoch 407/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9103 - accuracy: 0.7709 - val_loss: 1.0820 - val_accuracy: 0.7210\n",
      "Epoch 408/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9082 - accuracy: 0.7688 - val_loss: 1.0780 - val_accuracy: 0.7270\n",
      "Epoch 409/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.9087 - accuracy: 0.7692 - val_loss: 1.0704 - val_accuracy: 0.7270\n",
      "Epoch 410/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.9074 - accuracy: 0.7707 - val_loss: 1.0791 - val_accuracy: 0.7210\n",
      "Epoch 411/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9064 - accuracy: 0.7689 - val_loss: 1.0651 - val_accuracy: 0.7320\n",
      "Epoch 412/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9068 - accuracy: 0.7699 - val_loss: 1.0661 - val_accuracy: 0.7350\n",
      "Epoch 413/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.9067 - accuracy: 0.7691 - val_loss: 1.0862 - val_accuracy: 0.7150\n",
      "Epoch 414/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9077 - accuracy: 0.7700 - val_loss: 1.0738 - val_accuracy: 0.7220\n",
      "Epoch 415/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9069 - accuracy: 0.7695 - val_loss: 1.0683 - val_accuracy: 0.7320\n",
      "Epoch 416/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.9057 - accuracy: 0.7708 - val_loss: 1.0730 - val_accuracy: 0.7220\n",
      "Epoch 417/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.9052 - accuracy: 0.7719 - val_loss: 1.0675 - val_accuracy: 0.7290\n",
      "Epoch 418/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9070 - accuracy: 0.7712 - val_loss: 1.0653 - val_accuracy: 0.7330\n",
      "Epoch 419/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9046 - accuracy: 0.7672 - val_loss: 1.0722 - val_accuracy: 0.7310\n",
      "Epoch 420/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9029 - accuracy: 0.7711 - val_loss: 1.0652 - val_accuracy: 0.7340\n",
      "Epoch 421/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9035 - accuracy: 0.7705 - val_loss: 1.0711 - val_accuracy: 0.7270\n",
      "Epoch 422/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.9041 - accuracy: 0.7696 - val_loss: 1.0671 - val_accuracy: 0.7270\n",
      "Epoch 423/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 0.9026 - accuracy: 0.7699 - val_loss: 1.0790 - val_accuracy: 0.7250\n",
      "Epoch 424/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.9027 - accuracy: 0.7692 - val_loss: 1.0829 - val_accuracy: 0.7220\n",
      "Epoch 425/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9029 - accuracy: 0.7723 - val_loss: 1.0867 - val_accuracy: 0.7150\n",
      "Epoch 426/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.9021 - accuracy: 0.7719 - val_loss: 1.0801 - val_accuracy: 0.7230\n",
      "Epoch 427/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.9007 - accuracy: 0.7733 - val_loss: 1.0764 - val_accuracy: 0.7240\n",
      "Epoch 428/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.9035 - accuracy: 0.7712 - val_loss: 1.0658 - val_accuracy: 0.7280\n",
      "Epoch 429/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.9003 - accuracy: 0.7728 - val_loss: 1.0789 - val_accuracy: 0.7180\n",
      "Epoch 430/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.9008 - accuracy: 0.7736 - val_loss: 1.0718 - val_accuracy: 0.7270\n",
      "Epoch 431/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.9004 - accuracy: 0.7693 - val_loss: 1.0662 - val_accuracy: 0.7300\n",
      "Epoch 432/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8993 - accuracy: 0.7729 - val_loss: 1.0658 - val_accuracy: 0.7300\n",
      "Epoch 433/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8982 - accuracy: 0.7735 - val_loss: 1.0622 - val_accuracy: 0.7330\n",
      "Epoch 434/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8992 - accuracy: 0.7735 - val_loss: 1.0662 - val_accuracy: 0.7300\n",
      "Epoch 435/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.8995 - accuracy: 0.7721 - val_loss: 1.0704 - val_accuracy: 0.7260\n",
      "Epoch 436/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8977 - accuracy: 0.7739 - val_loss: 1.0622 - val_accuracy: 0.7360\n",
      "Epoch 437/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8968 - accuracy: 0.7711 - val_loss: 1.0646 - val_accuracy: 0.7340\n",
      "Epoch 438/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8984 - accuracy: 0.7725 - val_loss: 1.0694 - val_accuracy: 0.7240\n",
      "Epoch 439/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.8965 - accuracy: 0.7747 - val_loss: 1.0723 - val_accuracy: 0.7250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.8962 - accuracy: 0.7732 - val_loss: 1.0658 - val_accuracy: 0.7310\n",
      "Epoch 441/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8945 - accuracy: 0.7756 - val_loss: 1.0657 - val_accuracy: 0.7230\n",
      "Epoch 442/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8973 - accuracy: 0.7715 - val_loss: 1.0648 - val_accuracy: 0.7290\n",
      "Epoch 443/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8973 - accuracy: 0.7733 - val_loss: 1.0659 - val_accuracy: 0.7290\n",
      "Epoch 444/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8957 - accuracy: 0.7712 - val_loss: 1.0757 - val_accuracy: 0.7260\n",
      "Epoch 445/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.8940 - accuracy: 0.7739 - val_loss: 1.0742 - val_accuracy: 0.7210\n",
      "Epoch 446/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8954 - accuracy: 0.7719 - val_loss: 1.0723 - val_accuracy: 0.7320\n",
      "Epoch 447/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8955 - accuracy: 0.7741 - val_loss: 1.0721 - val_accuracy: 0.7270\n",
      "Epoch 448/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8929 - accuracy: 0.7740 - val_loss: 1.0632 - val_accuracy: 0.7310\n",
      "Epoch 449/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.8948 - accuracy: 0.7737 - val_loss: 1.0668 - val_accuracy: 0.7280\n",
      "Epoch 450/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.8931 - accuracy: 0.7728 - val_loss: 1.0863 - val_accuracy: 0.7170\n",
      "Epoch 451/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.8933 - accuracy: 0.7731 - val_loss: 1.0686 - val_accuracy: 0.7270\n",
      "Epoch 452/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.8907 - accuracy: 0.7760 - val_loss: 1.0567 - val_accuracy: 0.7340\n",
      "Epoch 453/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8911 - accuracy: 0.7747 - val_loss: 1.0665 - val_accuracy: 0.7240\n",
      "Epoch 454/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.8905 - accuracy: 0.7749 - val_loss: 1.0591 - val_accuracy: 0.7320\n",
      "Epoch 455/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.8918 - accuracy: 0.7743 - val_loss: 1.0645 - val_accuracy: 0.7280\n",
      "Epoch 456/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8909 - accuracy: 0.7747 - val_loss: 1.0878 - val_accuracy: 0.7140\n",
      "Epoch 457/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.8895 - accuracy: 0.7741 - val_loss: 1.0683 - val_accuracy: 0.7220\n",
      "Epoch 458/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.8899 - accuracy: 0.7735 - val_loss: 1.0675 - val_accuracy: 0.7260\n",
      "Epoch 459/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8917 - accuracy: 0.7749 - val_loss: 1.0608 - val_accuracy: 0.7310\n",
      "Epoch 460/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8876 - accuracy: 0.7731 - val_loss: 1.0626 - val_accuracy: 0.7270\n",
      "Epoch 461/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8905 - accuracy: 0.7737 - val_loss: 1.0582 - val_accuracy: 0.7320\n",
      "Epoch 462/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8887 - accuracy: 0.7744 - val_loss: 1.0607 - val_accuracy: 0.7310\n",
      "Epoch 463/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8899 - accuracy: 0.7729 - val_loss: 1.0586 - val_accuracy: 0.7370\n",
      "Epoch 464/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8876 - accuracy: 0.7740 - val_loss: 1.0715 - val_accuracy: 0.7260\n",
      "Epoch 465/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8866 - accuracy: 0.7740 - val_loss: 1.0520 - val_accuracy: 0.7360\n",
      "Epoch 466/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8861 - accuracy: 0.7740 - val_loss: 1.0697 - val_accuracy: 0.7280\n",
      "Epoch 467/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8867 - accuracy: 0.7740 - val_loss: 1.0568 - val_accuracy: 0.7360\n",
      "Epoch 468/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8844 - accuracy: 0.7761 - val_loss: 1.0548 - val_accuracy: 0.7360\n",
      "Epoch 469/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8858 - accuracy: 0.7749 - val_loss: 1.0614 - val_accuracy: 0.7290\n",
      "Epoch 470/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.8860 - accuracy: 0.7716 - val_loss: 1.0696 - val_accuracy: 0.7230\n",
      "Epoch 471/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.8853 - accuracy: 0.7777 - val_loss: 1.0616 - val_accuracy: 0.7260\n",
      "Epoch 472/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8858 - accuracy: 0.7747 - val_loss: 1.0565 - val_accuracy: 0.7370\n",
      "Epoch 473/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8859 - accuracy: 0.7765 - val_loss: 1.0730 - val_accuracy: 0.7220\n",
      "Epoch 474/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8840 - accuracy: 0.7761 - val_loss: 1.0660 - val_accuracy: 0.7300\n",
      "Epoch 475/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8853 - accuracy: 0.7757 - val_loss: 1.0675 - val_accuracy: 0.7290\n",
      "Epoch 476/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8851 - accuracy: 0.7763 - val_loss: 1.0613 - val_accuracy: 0.7290\n",
      "Epoch 477/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8826 - accuracy: 0.7769 - val_loss: 1.0894 - val_accuracy: 0.7180\n",
      "Epoch 478/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8849 - accuracy: 0.7739 - val_loss: 1.0660 - val_accuracy: 0.7240\n",
      "Epoch 479/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8831 - accuracy: 0.7756 - val_loss: 1.0577 - val_accuracy: 0.7300\n",
      "Epoch 480/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8813 - accuracy: 0.7769 - val_loss: 1.0548 - val_accuracy: 0.7310\n",
      "Epoch 481/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8827 - accuracy: 0.7765 - val_loss: 1.0765 - val_accuracy: 0.7280\n",
      "Epoch 482/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8856 - accuracy: 0.7747 - val_loss: 1.0726 - val_accuracy: 0.7260\n",
      "Epoch 483/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8818 - accuracy: 0.7768 - val_loss: 1.0550 - val_accuracy: 0.7310\n",
      "Epoch 484/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8810 - accuracy: 0.7780 - val_loss: 1.0598 - val_accuracy: 0.7300\n",
      "Epoch 485/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8813 - accuracy: 0.7755 - val_loss: 1.0711 - val_accuracy: 0.7250\n",
      "Epoch 486/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8813 - accuracy: 0.7716 - val_loss: 1.0535 - val_accuracy: 0.7310\n",
      "Epoch 487/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8814 - accuracy: 0.7768 - val_loss: 1.0646 - val_accuracy: 0.7250\n",
      "Epoch 488/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8797 - accuracy: 0.7767 - val_loss: 1.0500 - val_accuracy: 0.7400\n",
      "Epoch 489/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8795 - accuracy: 0.7784 - val_loss: 1.0533 - val_accuracy: 0.7310\n",
      "Epoch 490/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8826 - accuracy: 0.7744 - val_loss: 1.0861 - val_accuracy: 0.7170\n",
      "Epoch 491/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8799 - accuracy: 0.7768 - val_loss: 1.0648 - val_accuracy: 0.7240\n",
      "Epoch 492/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8792 - accuracy: 0.7773 - val_loss: 1.0543 - val_accuracy: 0.7290\n",
      "Epoch 493/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8779 - accuracy: 0.7743 - val_loss: 1.0593 - val_accuracy: 0.7320\n",
      "Epoch 494/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8774 - accuracy: 0.7795 - val_loss: 1.0649 - val_accuracy: 0.7290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8785 - accuracy: 0.7789 - val_loss: 1.0540 - val_accuracy: 0.7340\n",
      "Epoch 496/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8776 - accuracy: 0.7784 - val_loss: 1.0515 - val_accuracy: 0.7400\n",
      "Epoch 497/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8782 - accuracy: 0.7787 - val_loss: 1.0533 - val_accuracy: 0.7370\n",
      "Epoch 498/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8766 - accuracy: 0.7771 - val_loss: 1.0522 - val_accuracy: 0.7360\n",
      "Epoch 499/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8743 - accuracy: 0.7791 - val_loss: 1.0549 - val_accuracy: 0.7360\n",
      "Epoch 500/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8773 - accuracy: 0.7765 - val_loss: 1.0562 - val_accuracy: 0.7290\n",
      "Epoch 501/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8770 - accuracy: 0.7773 - val_loss: 1.0495 - val_accuracy: 0.7370\n",
      "Epoch 502/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8774 - accuracy: 0.7765 - val_loss: 1.0602 - val_accuracy: 0.7300\n",
      "Epoch 503/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8760 - accuracy: 0.7771 - val_loss: 1.0514 - val_accuracy: 0.7340\n",
      "Epoch 504/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8749 - accuracy: 0.7773 - val_loss: 1.0533 - val_accuracy: 0.7350\n",
      "Epoch 505/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8752 - accuracy: 0.7779 - val_loss: 1.0596 - val_accuracy: 0.7300\n",
      "Epoch 506/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8751 - accuracy: 0.7784 - val_loss: 1.1032 - val_accuracy: 0.6980\n",
      "Epoch 507/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8773 - accuracy: 0.7765 - val_loss: 1.0496 - val_accuracy: 0.7370\n",
      "Epoch 508/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8749 - accuracy: 0.7780 - val_loss: 1.0831 - val_accuracy: 0.7140\n",
      "Epoch 509/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8745 - accuracy: 0.7780 - val_loss: 1.0544 - val_accuracy: 0.7330\n",
      "Epoch 510/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8778 - accuracy: 0.7791 - val_loss: 1.0561 - val_accuracy: 0.7350\n",
      "Epoch 511/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8730 - accuracy: 0.7795 - val_loss: 1.0599 - val_accuracy: 0.7280\n",
      "Epoch 512/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8721 - accuracy: 0.7799 - val_loss: 1.0596 - val_accuracy: 0.7270\n",
      "Epoch 513/1000\n",
      "7500/7500 [==============================] - 0s 58us/step - loss: 0.8742 - accuracy: 0.7781 - val_loss: 1.0583 - val_accuracy: 0.7270\n",
      "Epoch 514/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8722 - accuracy: 0.7781 - val_loss: 1.0514 - val_accuracy: 0.7380\n",
      "Epoch 515/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8742 - accuracy: 0.7781 - val_loss: 1.0592 - val_accuracy: 0.7250\n",
      "Epoch 516/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8712 - accuracy: 0.7765 - val_loss: 1.1040 - val_accuracy: 0.7030\n",
      "Epoch 517/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8738 - accuracy: 0.7781 - val_loss: 1.0578 - val_accuracy: 0.7300\n",
      "Epoch 518/1000\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 0.8694 - accuracy: 0.7797 - val_loss: 1.0547 - val_accuracy: 0.7330\n",
      "Epoch 519/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8697 - accuracy: 0.7796 - val_loss: 1.0501 - val_accuracy: 0.7360\n",
      "Epoch 520/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8684 - accuracy: 0.7820 - val_loss: 1.0655 - val_accuracy: 0.7270\n",
      "Epoch 521/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8712 - accuracy: 0.7795 - val_loss: 1.0668 - val_accuracy: 0.7210\n",
      "Epoch 522/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8699 - accuracy: 0.7801 - val_loss: 1.0636 - val_accuracy: 0.7250\n",
      "Epoch 523/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8717 - accuracy: 0.7795 - val_loss: 1.0448 - val_accuracy: 0.7390\n",
      "Epoch 524/1000\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 0.8700 - accuracy: 0.7803 - val_loss: 1.0524 - val_accuracy: 0.7370\n",
      "Epoch 525/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.8699 - accuracy: 0.7785 - val_loss: 1.0524 - val_accuracy: 0.7320\n",
      "Epoch 526/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8668 - accuracy: 0.7787 - val_loss: 1.0456 - val_accuracy: 0.7390\n",
      "Epoch 527/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8674 - accuracy: 0.7819 - val_loss: 1.0692 - val_accuracy: 0.7250\n",
      "Epoch 528/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8692 - accuracy: 0.7824 - val_loss: 1.0448 - val_accuracy: 0.7410\n",
      "Epoch 529/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8666 - accuracy: 0.7788 - val_loss: 1.0588 - val_accuracy: 0.7300\n",
      "Epoch 530/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8677 - accuracy: 0.7784 - val_loss: 1.0734 - val_accuracy: 0.7270\n",
      "Epoch 531/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8674 - accuracy: 0.7797 - val_loss: 1.0493 - val_accuracy: 0.7300\n",
      "Epoch 532/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8661 - accuracy: 0.7783 - val_loss: 1.0592 - val_accuracy: 0.7240\n",
      "Epoch 533/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8680 - accuracy: 0.7809 - val_loss: 1.0529 - val_accuracy: 0.7340\n",
      "Epoch 534/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8670 - accuracy: 0.7796 - val_loss: 1.0656 - val_accuracy: 0.7220\n",
      "Epoch 535/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8662 - accuracy: 0.7795 - val_loss: 1.0496 - val_accuracy: 0.7320\n",
      "Epoch 536/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8673 - accuracy: 0.7793 - val_loss: 1.0626 - val_accuracy: 0.7240\n",
      "Epoch 537/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8656 - accuracy: 0.7820 - val_loss: 1.0460 - val_accuracy: 0.7360\n",
      "Epoch 538/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8638 - accuracy: 0.7788 - val_loss: 1.0591 - val_accuracy: 0.7290\n",
      "Epoch 539/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8638 - accuracy: 0.7809 - val_loss: 1.0492 - val_accuracy: 0.7320\n",
      "Epoch 540/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8638 - accuracy: 0.7819 - val_loss: 1.0721 - val_accuracy: 0.7170\n",
      "Epoch 541/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8639 - accuracy: 0.7800 - val_loss: 1.0502 - val_accuracy: 0.7330\n",
      "Epoch 542/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8652 - accuracy: 0.7800 - val_loss: 1.0487 - val_accuracy: 0.7380\n",
      "Epoch 543/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8620 - accuracy: 0.7816 - val_loss: 1.0915 - val_accuracy: 0.7120\n",
      "Epoch 544/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8652 - accuracy: 0.7805 - val_loss: 1.0674 - val_accuracy: 0.7220\n",
      "Epoch 545/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8624 - accuracy: 0.7819 - val_loss: 1.0473 - val_accuracy: 0.7360\n",
      "Epoch 546/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8649 - accuracy: 0.7824 - val_loss: 1.0833 - val_accuracy: 0.7110\n",
      "Epoch 547/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8632 - accuracy: 0.7805 - val_loss: 1.0554 - val_accuracy: 0.7300\n",
      "Epoch 548/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8624 - accuracy: 0.7813 - val_loss: 1.0522 - val_accuracy: 0.7300\n",
      "Epoch 549/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8621 - accuracy: 0.7825 - val_loss: 1.0407 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 550/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8638 - accuracy: 0.7808 - val_loss: 1.0400 - val_accuracy: 0.7410\n",
      "Epoch 551/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8647 - accuracy: 0.7775 - val_loss: 1.0415 - val_accuracy: 0.7340\n",
      "Epoch 552/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8622 - accuracy: 0.7813 - val_loss: 1.0619 - val_accuracy: 0.7280\n",
      "Epoch 553/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8623 - accuracy: 0.7815 - val_loss: 1.0525 - val_accuracy: 0.7310\n",
      "Epoch 554/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8602 - accuracy: 0.7825 - val_loss: 1.0393 - val_accuracy: 0.7410\n",
      "Epoch 555/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8629 - accuracy: 0.7808 - val_loss: 1.0527 - val_accuracy: 0.7300\n",
      "Epoch 556/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8599 - accuracy: 0.7816 - val_loss: 1.0493 - val_accuracy: 0.7380\n",
      "Epoch 557/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8604 - accuracy: 0.7836 - val_loss: 1.0580 - val_accuracy: 0.7290\n",
      "Epoch 558/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8625 - accuracy: 0.7804 - val_loss: 1.0410 - val_accuracy: 0.7400\n",
      "Epoch 559/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8607 - accuracy: 0.7816 - val_loss: 1.0732 - val_accuracy: 0.7180\n",
      "Epoch 560/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8597 - accuracy: 0.7821 - val_loss: 1.0473 - val_accuracy: 0.7370\n",
      "Epoch 561/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8573 - accuracy: 0.7845 - val_loss: 1.0627 - val_accuracy: 0.7270\n",
      "Epoch 562/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8608 - accuracy: 0.7796 - val_loss: 1.1408 - val_accuracy: 0.6850\n",
      "Epoch 563/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8633 - accuracy: 0.7804 - val_loss: 1.0505 - val_accuracy: 0.7370\n",
      "Epoch 564/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8569 - accuracy: 0.7813 - val_loss: 1.0506 - val_accuracy: 0.7340\n",
      "Epoch 565/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8581 - accuracy: 0.7800 - val_loss: 1.0491 - val_accuracy: 0.7310\n",
      "Epoch 566/1000\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.8589 - accuracy: 0.7837 - val_loss: 1.0716 - val_accuracy: 0.7120\n",
      "Epoch 567/1000\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.8616 - accuracy: 0.7805 - val_loss: 1.1192 - val_accuracy: 0.7030\n",
      "Epoch 568/1000\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.8597 - accuracy: 0.7816 - val_loss: 1.0435 - val_accuracy: 0.7380\n",
      "Epoch 569/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8589 - accuracy: 0.7825 - val_loss: 1.0409 - val_accuracy: 0.7360\n",
      "Epoch 570/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8606 - accuracy: 0.7812 - val_loss: 1.0522 - val_accuracy: 0.7300\n",
      "Epoch 571/1000\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.8552 - accuracy: 0.7831 - val_loss: 1.0445 - val_accuracy: 0.7360\n",
      "Epoch 572/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8567 - accuracy: 0.7839 - val_loss: 1.1157 - val_accuracy: 0.6970\n",
      "Epoch 573/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8604 - accuracy: 0.7804 - val_loss: 1.0368 - val_accuracy: 0.7430\n",
      "Epoch 574/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.8516 - accuracy: 0.78 - 0s 51us/step - loss: 0.8541 - accuracy: 0.7851 - val_loss: 1.0601 - val_accuracy: 0.7270\n",
      "Epoch 575/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8557 - accuracy: 0.7835 - val_loss: 1.0515 - val_accuracy: 0.7300\n",
      "Epoch 576/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8566 - accuracy: 0.7849 - val_loss: 1.0420 - val_accuracy: 0.7340\n",
      "Epoch 577/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.8536 - accuracy: 0.7841 - val_loss: 1.0426 - val_accuracy: 0.7390\n",
      "Epoch 578/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.8599 - accuracy: 0.7819 - val_loss: 1.0565 - val_accuracy: 0.7300\n",
      "Epoch 579/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.8593 - accuracy: 0.78 - 0s 44us/step - loss: 0.8552 - accuracy: 0.7832 - val_loss: 1.0452 - val_accuracy: 0.7350\n",
      "Epoch 580/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8536 - accuracy: 0.7841 - val_loss: 1.0394 - val_accuracy: 0.7350\n",
      "Epoch 581/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8559 - accuracy: 0.7823 - val_loss: 1.0356 - val_accuracy: 0.7420\n",
      "Epoch 582/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8552 - accuracy: 0.7811 - val_loss: 1.1069 - val_accuracy: 0.7040\n",
      "Epoch 583/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8547 - accuracy: 0.7843 - val_loss: 1.0501 - val_accuracy: 0.7310\n",
      "Epoch 584/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8545 - accuracy: 0.7829 - val_loss: 1.0436 - val_accuracy: 0.7390\n",
      "Epoch 585/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8535 - accuracy: 0.7833 - val_loss: 1.0604 - val_accuracy: 0.7220\n",
      "Epoch 586/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8527 - accuracy: 0.7857 - val_loss: 1.0622 - val_accuracy: 0.7310\n",
      "Epoch 587/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8533 - accuracy: 0.7868 - val_loss: 1.0778 - val_accuracy: 0.7100\n",
      "Epoch 588/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8534 - accuracy: 0.7827 - val_loss: 1.0647 - val_accuracy: 0.7220\n",
      "Epoch 589/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8525 - accuracy: 0.7848 - val_loss: 1.0537 - val_accuracy: 0.7310\n",
      "Epoch 590/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8540 - accuracy: 0.7844 - val_loss: 1.0439 - val_accuracy: 0.7370\n",
      "Epoch 591/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8532 - accuracy: 0.7827 - val_loss: 1.0358 - val_accuracy: 0.7440\n",
      "Epoch 592/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8525 - accuracy: 0.7849 - val_loss: 1.0453 - val_accuracy: 0.7330\n",
      "Epoch 593/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8516 - accuracy: 0.7849 - val_loss: 1.0732 - val_accuracy: 0.7100\n",
      "Epoch 594/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8535 - accuracy: 0.7828 - val_loss: 1.0398 - val_accuracy: 0.7420\n",
      "Epoch 595/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8519 - accuracy: 0.7833 - val_loss: 1.0621 - val_accuracy: 0.7240\n",
      "Epoch 596/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8518 - accuracy: 0.7821 - val_loss: 1.0481 - val_accuracy: 0.7330\n",
      "Epoch 597/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8521 - accuracy: 0.7856 - val_loss: 1.0326 - val_accuracy: 0.7440\n",
      "Epoch 598/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8519 - accuracy: 0.7831 - val_loss: 1.0409 - val_accuracy: 0.7430\n",
      "Epoch 599/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8479 - accuracy: 0.7840 - val_loss: 1.0366 - val_accuracy: 0.7420\n",
      "Epoch 600/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8490 - accuracy: 0.7832 - val_loss: 1.0369 - val_accuracy: 0.7400\n",
      "Epoch 601/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8491 - accuracy: 0.7853 - val_loss: 1.0578 - val_accuracy: 0.7270\n",
      "Epoch 602/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8525 - accuracy: 0.7831 - val_loss: 1.0450 - val_accuracy: 0.7360\n",
      "Epoch 603/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8506 - accuracy: 0.7832 - val_loss: 1.0724 - val_accuracy: 0.7230\n",
      "Epoch 604/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8504 - accuracy: 0.7837 - val_loss: 1.0575 - val_accuracy: 0.7250\n",
      "Epoch 605/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.8476 - accuracy: 0.7864 - val_loss: 1.0465 - val_accuracy: 0.7320\n",
      "Epoch 606/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8479 - accuracy: 0.7880 - val_loss: 1.0810 - val_accuracy: 0.7090\n",
      "Epoch 607/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8493 - accuracy: 0.7845 - val_loss: 1.0587 - val_accuracy: 0.7330\n",
      "Epoch 608/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8486 - accuracy: 0.7847 - val_loss: 1.0457 - val_accuracy: 0.7350\n",
      "Epoch 609/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8489 - accuracy: 0.7857 - val_loss: 1.0614 - val_accuracy: 0.7250\n",
      "Epoch 610/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8471 - accuracy: 0.7857 - val_loss: 1.0481 - val_accuracy: 0.7360\n",
      "Epoch 611/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.8471 - accuracy: 0.7863 - val_loss: 1.0419 - val_accuracy: 0.7350\n",
      "Epoch 612/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.8473 - accuracy: 0.7884 - val_loss: 1.0416 - val_accuracy: 0.7340\n",
      "Epoch 613/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8467 - accuracy: 0.7853 - val_loss: 1.0426 - val_accuracy: 0.7340\n",
      "Epoch 614/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8480 - accuracy: 0.7861 - val_loss: 1.0347 - val_accuracy: 0.7410\n",
      "Epoch 615/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8459 - accuracy: 0.7848 - val_loss: 1.0330 - val_accuracy: 0.7380\n",
      "Epoch 616/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8449 - accuracy: 0.7861 - val_loss: 1.0344 - val_accuracy: 0.7380\n",
      "Epoch 617/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8482 - accuracy: 0.7856 - val_loss: 1.0371 - val_accuracy: 0.7370\n",
      "Epoch 618/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8455 - accuracy: 0.7873 - val_loss: 1.0391 - val_accuracy: 0.7410\n",
      "Epoch 619/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8449 - accuracy: 0.7863 - val_loss: 1.0466 - val_accuracy: 0.7270\n",
      "Epoch 620/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8456 - accuracy: 0.7852 - val_loss: 1.0312 - val_accuracy: 0.7380\n",
      "Epoch 621/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8464 - accuracy: 0.7865 - val_loss: 1.0358 - val_accuracy: 0.7320\n",
      "Epoch 622/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8440 - accuracy: 0.7848 - val_loss: 1.0405 - val_accuracy: 0.7360\n",
      "Epoch 623/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8445 - accuracy: 0.7844 - val_loss: 1.0780 - val_accuracy: 0.7120\n",
      "Epoch 624/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8470 - accuracy: 0.7837 - val_loss: 1.0400 - val_accuracy: 0.7370\n",
      "Epoch 625/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8443 - accuracy: 0.7848 - val_loss: 1.0412 - val_accuracy: 0.7330\n",
      "Epoch 626/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8496 - accuracy: 0.7829 - val_loss: 1.0519 - val_accuracy: 0.7290\n",
      "Epoch 627/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8457 - accuracy: 0.7864 - val_loss: 1.0364 - val_accuracy: 0.7410\n",
      "Epoch 628/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8472 - accuracy: 0.7859 - val_loss: 1.0468 - val_accuracy: 0.7380\n",
      "Epoch 629/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8423 - accuracy: 0.7879 - val_loss: 1.0656 - val_accuracy: 0.7230\n",
      "Epoch 630/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8429 - accuracy: 0.7905 - val_loss: 1.0412 - val_accuracy: 0.7400\n",
      "Epoch 631/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8496 - accuracy: 0.7831 - val_loss: 1.0686 - val_accuracy: 0.7170\n",
      "Epoch 632/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8437 - accuracy: 0.7888 - val_loss: 1.0325 - val_accuracy: 0.7360\n",
      "Epoch 633/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8412 - accuracy: 0.7869 - val_loss: 1.0457 - val_accuracy: 0.7260\n",
      "Epoch 634/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8435 - accuracy: 0.7877 - val_loss: 1.0282 - val_accuracy: 0.7480\n",
      "Epoch 635/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8416 - accuracy: 0.7864 - val_loss: 1.0555 - val_accuracy: 0.7330\n",
      "Epoch 636/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8435 - accuracy: 0.7859 - val_loss: 1.0306 - val_accuracy: 0.7420\n",
      "Epoch 637/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8433 - accuracy: 0.7873 - val_loss: 1.0491 - val_accuracy: 0.7270\n",
      "Epoch 638/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8448 - accuracy: 0.7861 - val_loss: 1.0586 - val_accuracy: 0.7270\n",
      "Epoch 639/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8447 - accuracy: 0.7865 - val_loss: 1.0375 - val_accuracy: 0.7430\n",
      "Epoch 640/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8405 - accuracy: 0.7888 - val_loss: 1.0342 - val_accuracy: 0.7460\n",
      "Epoch 641/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8474 - accuracy: 0.7841 - val_loss: 1.0426 - val_accuracy: 0.7400\n",
      "Epoch 642/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8427 - accuracy: 0.7857 - val_loss: 1.0340 - val_accuracy: 0.7370\n",
      "Epoch 643/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8433 - accuracy: 0.7856 - val_loss: 1.0389 - val_accuracy: 0.7330\n",
      "Epoch 644/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8411 - accuracy: 0.7884 - val_loss: 1.0325 - val_accuracy: 0.7420\n",
      "Epoch 645/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8410 - accuracy: 0.7875 - val_loss: 1.0407 - val_accuracy: 0.7390\n",
      "Epoch 646/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8448 - accuracy: 0.7843 - val_loss: 1.0372 - val_accuracy: 0.7400\n",
      "Epoch 647/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8421 - accuracy: 0.7872 - val_loss: 1.0390 - val_accuracy: 0.7440\n",
      "Epoch 648/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8387 - accuracy: 0.7888 - val_loss: 1.0338 - val_accuracy: 0.7330\n",
      "Epoch 649/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8394 - accuracy: 0.7851 - val_loss: 1.0449 - val_accuracy: 0.7390\n",
      "Epoch 650/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8386 - accuracy: 0.7873 - val_loss: 1.0482 - val_accuracy: 0.7320\n",
      "Epoch 651/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8429 - accuracy: 0.7869 - val_loss: 1.0366 - val_accuracy: 0.7340\n",
      "Epoch 652/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8377 - accuracy: 0.7893 - val_loss: 1.0400 - val_accuracy: 0.7370\n",
      "Epoch 653/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8388 - accuracy: 0.7889 - val_loss: 1.1303 - val_accuracy: 0.6970\n",
      "Epoch 654/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8425 - accuracy: 0.7877 - val_loss: 1.0324 - val_accuracy: 0.7380\n",
      "Epoch 655/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8385 - accuracy: 0.7891 - val_loss: 1.0286 - val_accuracy: 0.7480\n",
      "Epoch 656/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8424 - accuracy: 0.7836 - val_loss: 1.0394 - val_accuracy: 0.7370\n",
      "Epoch 657/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8389 - accuracy: 0.7889 - val_loss: 1.0293 - val_accuracy: 0.7440\n",
      "Epoch 658/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8392 - accuracy: 0.7877 - val_loss: 1.0345 - val_accuracy: 0.7400\n",
      "Epoch 659/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8400 - accuracy: 0.7857 - val_loss: 1.0466 - val_accuracy: 0.7330\n",
      "Epoch 660/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8396 - accuracy: 0.7888 - val_loss: 1.0513 - val_accuracy: 0.7300\n",
      "Epoch 661/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8464 - accuracy: 0.7864 - val_loss: 1.0455 - val_accuracy: 0.7300\n",
      "Epoch 662/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8367 - accuracy: 0.7888 - val_loss: 1.1030 - val_accuracy: 0.7050\n",
      "Epoch 663/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8379 - accuracy: 0.7885 - val_loss: 1.0293 - val_accuracy: 0.7370\n",
      "Epoch 664/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8425 - accuracy: 0.7879 - val_loss: 1.0456 - val_accuracy: 0.7290\n",
      "Epoch 665/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8375 - accuracy: 0.7872 - val_loss: 1.0366 - val_accuracy: 0.7400\n",
      "Epoch 666/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8364 - accuracy: 0.7895 - val_loss: 1.0717 - val_accuracy: 0.7170\n",
      "Epoch 667/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8356 - accuracy: 0.7891 - val_loss: 1.0332 - val_accuracy: 0.7340\n",
      "Epoch 668/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8377 - accuracy: 0.7887 - val_loss: 1.0444 - val_accuracy: 0.7370\n",
      "Epoch 669/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8377 - accuracy: 0.7875 - val_loss: 1.0538 - val_accuracy: 0.7230\n",
      "Epoch 670/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8410 - accuracy: 0.7885 - val_loss: 1.0300 - val_accuracy: 0.7420\n",
      "Epoch 671/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8367 - accuracy: 0.7893 - val_loss: 1.0457 - val_accuracy: 0.7350\n",
      "Epoch 672/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8367 - accuracy: 0.7876 - val_loss: 1.0477 - val_accuracy: 0.7290\n",
      "Epoch 673/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8379 - accuracy: 0.7860 - val_loss: 1.0391 - val_accuracy: 0.7380\n",
      "Epoch 674/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8352 - accuracy: 0.7904 - val_loss: 1.0354 - val_accuracy: 0.7350\n",
      "Epoch 675/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8351 - accuracy: 0.7873 - val_loss: 1.0425 - val_accuracy: 0.7380\n",
      "Epoch 676/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8419 - accuracy: 0.7857 - val_loss: 1.0461 - val_accuracy: 0.7330\n",
      "Epoch 677/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8422 - accuracy: 0.7856 - val_loss: 1.0814 - val_accuracy: 0.7140\n",
      "Epoch 678/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8365 - accuracy: 0.7889 - val_loss: 1.1092 - val_accuracy: 0.7060\n",
      "Epoch 679/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8438 - accuracy: 0.7860 - val_loss: 1.0379 - val_accuracy: 0.7380\n",
      "Epoch 680/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8343 - accuracy: 0.7888 - val_loss: 1.0414 - val_accuracy: 0.7340\n",
      "Epoch 681/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8389 - accuracy: 0.7871 - val_loss: 1.0545 - val_accuracy: 0.7200\n",
      "Epoch 682/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8373 - accuracy: 0.7891 - val_loss: 1.0453 - val_accuracy: 0.7410\n",
      "Epoch 683/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8364 - accuracy: 0.7901 - val_loss: 1.0313 - val_accuracy: 0.7400\n",
      "Epoch 684/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8343 - accuracy: 0.7880 - val_loss: 1.0406 - val_accuracy: 0.7390\n",
      "Epoch 685/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8324 - accuracy: 0.7891 - val_loss: 1.0308 - val_accuracy: 0.7390\n",
      "Epoch 686/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8319 - accuracy: 0.7912 - val_loss: 1.0530 - val_accuracy: 0.7290\n",
      "Epoch 687/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8338 - accuracy: 0.7901 - val_loss: 1.0353 - val_accuracy: 0.7370\n",
      "Epoch 688/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8331 - accuracy: 0.7901 - val_loss: 1.0447 - val_accuracy: 0.7300\n",
      "Epoch 689/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8339 - accuracy: 0.7896 - val_loss: 1.0413 - val_accuracy: 0.7400\n",
      "Epoch 690/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8419 - accuracy: 0.7893 - val_loss: 1.0439 - val_accuracy: 0.7370\n",
      "Epoch 691/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8361 - accuracy: 0.7892 - val_loss: 1.0508 - val_accuracy: 0.7350\n",
      "Epoch 692/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8362 - accuracy: 0.7880 - val_loss: 1.0699 - val_accuracy: 0.7150\n",
      "Epoch 693/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8339 - accuracy: 0.7912 - val_loss: 1.0312 - val_accuracy: 0.7450\n",
      "Epoch 694/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8305 - accuracy: 0.7932 - val_loss: 1.0641 - val_accuracy: 0.7170\n",
      "Epoch 695/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8361 - accuracy: 0.7889 - val_loss: 1.1220 - val_accuracy: 0.6950\n",
      "Epoch 696/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8346 - accuracy: 0.7891 - val_loss: 1.0333 - val_accuracy: 0.7340\n",
      "Epoch 697/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8362 - accuracy: 0.7884 - val_loss: 1.0386 - val_accuracy: 0.7360\n",
      "Epoch 698/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8324 - accuracy: 0.7905 - val_loss: 1.0583 - val_accuracy: 0.7230\n",
      "Epoch 699/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.8321 - accuracy: 0.7905 - val_loss: 1.0366 - val_accuracy: 0.7420\n",
      "Epoch 700/1000\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.8365 - accuracy: 0.7880 - val_loss: 1.0405 - val_accuracy: 0.7370\n",
      "Epoch 701/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8316 - accuracy: 0.7899 - val_loss: 1.0394 - val_accuracy: 0.7370\n",
      "Epoch 702/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8317 - accuracy: 0.7917 - val_loss: 1.0299 - val_accuracy: 0.7420\n",
      "Epoch 703/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8295 - accuracy: 0.7940 - val_loss: 1.0795 - val_accuracy: 0.7170\n",
      "Epoch 704/1000\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 0.8345 - accuracy: 0.7899 - val_loss: 1.0666 - val_accuracy: 0.7170\n",
      "Epoch 705/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8379 - accuracy: 0.7876 - val_loss: 1.0304 - val_accuracy: 0.7410\n",
      "Epoch 706/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8317 - accuracy: 0.7927 - val_loss: 1.0341 - val_accuracy: 0.7380\n",
      "Epoch 707/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8300 - accuracy: 0.7904 - val_loss: 1.0291 - val_accuracy: 0.7390\n",
      "Epoch 708/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8314 - accuracy: 0.7884 - val_loss: 1.0253 - val_accuracy: 0.7490\n",
      "Epoch 709/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8313 - accuracy: 0.7921 - val_loss: 1.0421 - val_accuracy: 0.7420\n",
      "Epoch 710/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8401 - accuracy: 0.7835 - val_loss: 1.0707 - val_accuracy: 0.7200\n",
      "Epoch 711/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8350 - accuracy: 0.7863 - val_loss: 1.0412 - val_accuracy: 0.7380\n",
      "Epoch 712/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8313 - accuracy: 0.7884 - val_loss: 1.0970 - val_accuracy: 0.7100\n",
      "Epoch 713/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8363 - accuracy: 0.7883 - val_loss: 1.0897 - val_accuracy: 0.7070\n",
      "Epoch 714/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8334 - accuracy: 0.7908 - val_loss: 1.0271 - val_accuracy: 0.7430\n",
      "Epoch 715/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8286 - accuracy: 0.7925 - val_loss: 1.0500 - val_accuracy: 0.7340\n",
      "Epoch 716/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8293 - accuracy: 0.7913 - val_loss: 1.0479 - val_accuracy: 0.7320\n",
      "Epoch 717/1000\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.8378 - accuracy: 0.7904 - val_loss: 1.0554 - val_accuracy: 0.7260\n",
      "Epoch 718/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8322 - accuracy: 0.7889 - val_loss: 1.0298 - val_accuracy: 0.7380\n",
      "Epoch 719/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8321 - accuracy: 0.7905 - val_loss: 1.0569 - val_accuracy: 0.7290\n",
      "Epoch 720/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8398 - accuracy: 0.7845 - val_loss: 1.0359 - val_accuracy: 0.7360\n",
      "Epoch 721/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8350 - accuracy: 0.7879 - val_loss: 1.0731 - val_accuracy: 0.7190\n",
      "Epoch 722/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8300 - accuracy: 0.7913 - val_loss: 1.0646 - val_accuracy: 0.7170\n",
      "Epoch 723/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8272 - accuracy: 0.7944 - val_loss: 1.0266 - val_accuracy: 0.7410\n",
      "Epoch 724/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8275 - accuracy: 0.7912 - val_loss: 1.0806 - val_accuracy: 0.7060\n",
      "Epoch 725/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8314 - accuracy: 0.7915 - val_loss: 1.0449 - val_accuracy: 0.7300\n",
      "Epoch 726/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8325 - accuracy: 0.7899 - val_loss: 1.0308 - val_accuracy: 0.7430\n",
      "Epoch 727/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8250 - accuracy: 0.7908 - val_loss: 1.0256 - val_accuracy: 0.7460\n",
      "Epoch 728/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8258 - accuracy: 0.7908 - val_loss: 1.0287 - val_accuracy: 0.7420\n",
      "Epoch 729/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8272 - accuracy: 0.7921 - val_loss: 1.0271 - val_accuracy: 0.7400\n",
      "Epoch 730/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8293 - accuracy: 0.7912 - val_loss: 1.0391 - val_accuracy: 0.7380\n",
      "Epoch 731/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8286 - accuracy: 0.7904 - val_loss: 1.0711 - val_accuracy: 0.7240\n",
      "Epoch 732/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8323 - accuracy: 0.7903 - val_loss: 1.0253 - val_accuracy: 0.7400\n",
      "Epoch 733/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8269 - accuracy: 0.7936 - val_loss: 1.1041 - val_accuracy: 0.6950\n",
      "Epoch 734/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8383 - accuracy: 0.7869 - val_loss: 1.0486 - val_accuracy: 0.7290\n",
      "Epoch 735/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8370 - accuracy: 0.7848 - val_loss: 1.1110 - val_accuracy: 0.7060\n",
      "Epoch 736/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8339 - accuracy: 0.7876 - val_loss: 1.0514 - val_accuracy: 0.7280\n",
      "Epoch 737/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8257 - accuracy: 0.7945 - val_loss: 1.0298 - val_accuracy: 0.7330\n",
      "Epoch 738/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8310 - accuracy: 0.7899 - val_loss: 1.0381 - val_accuracy: 0.7400\n",
      "Epoch 739/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8327 - accuracy: 0.7912 - val_loss: 1.0415 - val_accuracy: 0.7380\n",
      "Epoch 740/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8278 - accuracy: 0.7909 - val_loss: 1.0727 - val_accuracy: 0.7220\n",
      "Epoch 741/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8277 - accuracy: 0.7936 - val_loss: 1.0276 - val_accuracy: 0.7460\n",
      "Epoch 742/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8325 - accuracy: 0.7896 - val_loss: 1.0592 - val_accuracy: 0.7320\n",
      "Epoch 743/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8295 - accuracy: 0.7899 - val_loss: 1.0289 - val_accuracy: 0.7430\n",
      "Epoch 744/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8269 - accuracy: 0.7912 - val_loss: 1.1089 - val_accuracy: 0.7000\n",
      "Epoch 745/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8307 - accuracy: 0.7877 - val_loss: 1.0826 - val_accuracy: 0.7130\n",
      "Epoch 746/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8308 - accuracy: 0.7884 - val_loss: 1.0265 - val_accuracy: 0.7450\n",
      "Epoch 747/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8279 - accuracy: 0.7923 - val_loss: 1.0452 - val_accuracy: 0.7290\n",
      "Epoch 748/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8351 - accuracy: 0.7896 - val_loss: 1.0465 - val_accuracy: 0.7320\n",
      "Epoch 749/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8314 - accuracy: 0.7889 - val_loss: 1.0271 - val_accuracy: 0.7430\n",
      "Epoch 750/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8244 - accuracy: 0.7917 - val_loss: 1.0657 - val_accuracy: 0.7240\n",
      "Epoch 751/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8257 - accuracy: 0.7932 - val_loss: 1.0413 - val_accuracy: 0.7400\n",
      "Epoch 752/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8270 - accuracy: 0.7872 - val_loss: 1.0554 - val_accuracy: 0.7300\n",
      "Epoch 753/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8226 - accuracy: 0.7959 - val_loss: 1.0341 - val_accuracy: 0.7350\n",
      "Epoch 754/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8249 - accuracy: 0.7904 - val_loss: 1.0876 - val_accuracy: 0.7090\n",
      "Epoch 755/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8447 - accuracy: 0.7835 - val_loss: 1.0281 - val_accuracy: 0.7360\n",
      "Epoch 756/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8254 - accuracy: 0.7916 - val_loss: 1.0312 - val_accuracy: 0.7400\n",
      "Epoch 757/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8230 - accuracy: 0.7923 - val_loss: 1.0316 - val_accuracy: 0.7330\n",
      "Epoch 758/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8230 - accuracy: 0.7941 - val_loss: 1.0368 - val_accuracy: 0.7320\n",
      "Epoch 759/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8337 - accuracy: 0.7885 - val_loss: 1.0416 - val_accuracy: 0.7340\n",
      "Epoch 760/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8230 - accuracy: 0.7933 - val_loss: 1.0295 - val_accuracy: 0.7430\n",
      "Epoch 761/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8266 - accuracy: 0.7900 - val_loss: 1.0572 - val_accuracy: 0.7240\n",
      "Epoch 762/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8240 - accuracy: 0.7919 - val_loss: 1.0407 - val_accuracy: 0.7330\n",
      "Epoch 763/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8252 - accuracy: 0.7917 - val_loss: 1.0681 - val_accuracy: 0.7230\n",
      "Epoch 764/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8349 - accuracy: 0.7881 - val_loss: 1.0393 - val_accuracy: 0.7300\n",
      "Epoch 765/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8228 - accuracy: 0.7940 - val_loss: 1.0710 - val_accuracy: 0.7220\n",
      "Epoch 766/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8257 - accuracy: 0.7933 - val_loss: 1.0409 - val_accuracy: 0.7330\n",
      "Epoch 767/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8283 - accuracy: 0.7891 - val_loss: 1.0316 - val_accuracy: 0.7430\n",
      "Epoch 768/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8237 - accuracy: 0.7945 - val_loss: 1.0904 - val_accuracy: 0.7070\n",
      "Epoch 769/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8240 - accuracy: 0.7913 - val_loss: 1.0465 - val_accuracy: 0.7350\n",
      "Epoch 770/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8239 - accuracy: 0.7907 - val_loss: 1.0618 - val_accuracy: 0.7250\n",
      "Epoch 771/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8252 - accuracy: 0.7889 - val_loss: 1.0477 - val_accuracy: 0.7290\n",
      "Epoch 772/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8304 - accuracy: 0.7888 - val_loss: 1.0300 - val_accuracy: 0.7360\n",
      "Epoch 773/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8283 - accuracy: 0.7897 - val_loss: 1.0461 - val_accuracy: 0.7340\n",
      "Epoch 774/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8203 - accuracy: 0.7937 - val_loss: 1.0236 - val_accuracy: 0.7410\n",
      "Epoch 775/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8181 - accuracy: 0.7971 - val_loss: 1.0379 - val_accuracy: 0.7340\n",
      "Epoch 776/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8221 - accuracy: 0.7948 - val_loss: 1.0407 - val_accuracy: 0.7310\n",
      "Epoch 777/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8251 - accuracy: 0.7911 - val_loss: 1.0230 - val_accuracy: 0.7410\n",
      "Epoch 778/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8186 - accuracy: 0.7955 - val_loss: 1.0438 - val_accuracy: 0.7380\n",
      "Epoch 779/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8306 - accuracy: 0.7856 - val_loss: 1.0347 - val_accuracy: 0.7370\n",
      "Epoch 780/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8207 - accuracy: 0.7933 - val_loss: 1.0189 - val_accuracy: 0.7440\n",
      "Epoch 781/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8238 - accuracy: 0.7913 - val_loss: 1.1003 - val_accuracy: 0.7070\n",
      "Epoch 782/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8355 - accuracy: 0.7853 - val_loss: 1.0638 - val_accuracy: 0.7260\n",
      "Epoch 783/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8262 - accuracy: 0.7915 - val_loss: 1.0326 - val_accuracy: 0.7410\n",
      "Epoch 784/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8187 - accuracy: 0.7957 - val_loss: 1.0266 - val_accuracy: 0.7470\n",
      "Epoch 785/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8247 - accuracy: 0.7907 - val_loss: 1.0265 - val_accuracy: 0.7310\n",
      "Epoch 786/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8273 - accuracy: 0.7893 - val_loss: 1.0299 - val_accuracy: 0.7380\n",
      "Epoch 787/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8246 - accuracy: 0.7892 - val_loss: 1.0331 - val_accuracy: 0.7400\n",
      "Epoch 788/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8216 - accuracy: 0.7933 - val_loss: 1.0668 - val_accuracy: 0.7310\n",
      "Epoch 789/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8222 - accuracy: 0.7935 - val_loss: 1.0280 - val_accuracy: 0.7410\n",
      "Epoch 790/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8215 - accuracy: 0.7920 - val_loss: 1.0946 - val_accuracy: 0.7120\n",
      "Epoch 791/1000\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8295 - accuracy: 0.7899 - val_loss: 1.0277 - val_accuracy: 0.7420\n",
      "Epoch 792/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8171 - accuracy: 0.7985 - val_loss: 1.0892 - val_accuracy: 0.7160\n",
      "Epoch 793/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8243 - accuracy: 0.7959 - val_loss: 1.0252 - val_accuracy: 0.7460\n",
      "Epoch 794/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8251 - accuracy: 0.7907 - val_loss: 1.0261 - val_accuracy: 0.7420\n",
      "Epoch 795/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8220 - accuracy: 0.7963 - val_loss: 1.0427 - val_accuracy: 0.7330\n",
      "Epoch 796/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8217 - accuracy: 0.7940 - val_loss: 1.0299 - val_accuracy: 0.7400\n",
      "Epoch 797/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8227 - accuracy: 0.7920 - val_loss: 1.0428 - val_accuracy: 0.7300\n",
      "Epoch 798/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.8209 - accuracy: 0.79 - 0s 35us/step - loss: 0.8214 - accuracy: 0.7921 - val_loss: 1.0316 - val_accuracy: 0.7370\n",
      "Epoch 799/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8154 - accuracy: 0.7951 - val_loss: 1.0651 - val_accuracy: 0.7240\n",
      "Epoch 800/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8386 - accuracy: 0.7861 - val_loss: 1.0343 - val_accuracy: 0.7380\n",
      "Epoch 801/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8181 - accuracy: 0.7951 - val_loss: 1.0697 - val_accuracy: 0.7220\n",
      "Epoch 802/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8180 - accuracy: 0.7929 - val_loss: 1.0514 - val_accuracy: 0.7340\n",
      "Epoch 803/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8261 - accuracy: 0.7912 - val_loss: 1.0356 - val_accuracy: 0.7290\n",
      "Epoch 804/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8247 - accuracy: 0.7925 - val_loss: 1.0607 - val_accuracy: 0.7170\n",
      "Epoch 805/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8276 - accuracy: 0.7919 - val_loss: 1.0765 - val_accuracy: 0.7130\n",
      "Epoch 806/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8305 - accuracy: 0.7885 - val_loss: 1.0260 - val_accuracy: 0.7430\n",
      "Epoch 807/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8192 - accuracy: 0.7959 - val_loss: 1.0462 - val_accuracy: 0.7330\n",
      "Epoch 808/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8164 - accuracy: 0.7937 - val_loss: 1.0258 - val_accuracy: 0.7360\n",
      "Epoch 809/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8219 - accuracy: 0.7961 - val_loss: 1.0449 - val_accuracy: 0.7390\n",
      "Epoch 810/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8266 - accuracy: 0.7940 - val_loss: 1.0335 - val_accuracy: 0.7430\n",
      "Epoch 811/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8210 - accuracy: 0.7940 - val_loss: 1.0902 - val_accuracy: 0.7120\n",
      "Epoch 812/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8290 - accuracy: 0.7911 - val_loss: 1.1080 - val_accuracy: 0.6940\n",
      "Epoch 813/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8231 - accuracy: 0.7948 - val_loss: 1.0233 - val_accuracy: 0.7420\n",
      "Epoch 814/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8184 - accuracy: 0.7933 - val_loss: 1.0524 - val_accuracy: 0.7310\n",
      "Epoch 815/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8262 - accuracy: 0.7887 - val_loss: 1.0601 - val_accuracy: 0.7250\n",
      "Epoch 816/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8200 - accuracy: 0.7969 - val_loss: 1.0409 - val_accuracy: 0.7370\n",
      "Epoch 817/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8248 - accuracy: 0.7919 - val_loss: 1.0227 - val_accuracy: 0.7420\n",
      "Epoch 818/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8117 - accuracy: 0.7967 - val_loss: 1.0294 - val_accuracy: 0.7410\n",
      "Epoch 819/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8143 - accuracy: 0.7964 - val_loss: 1.0468 - val_accuracy: 0.7340\n",
      "Epoch 820/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8187 - accuracy: 0.7940 - val_loss: 1.1606 - val_accuracy: 0.6840\n",
      "Epoch 821/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8215 - accuracy: 0.7935 - val_loss: 1.1178 - val_accuracy: 0.7000\n",
      "Epoch 822/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8227 - accuracy: 0.7928 - val_loss: 1.0378 - val_accuracy: 0.7380\n",
      "Epoch 823/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8149 - accuracy: 0.7980 - val_loss: 1.0827 - val_accuracy: 0.7160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 824/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8285 - accuracy: 0.7901 - val_loss: 1.0435 - val_accuracy: 0.7330\n",
      "Epoch 825/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8228 - accuracy: 0.7913 - val_loss: 1.0245 - val_accuracy: 0.7440\n",
      "Epoch 826/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8165 - accuracy: 0.7947 - val_loss: 1.0473 - val_accuracy: 0.7300\n",
      "Epoch 827/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8119 - accuracy: 0.7968 - val_loss: 1.0565 - val_accuracy: 0.7240\n",
      "Epoch 828/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8132 - accuracy: 0.7964 - val_loss: 1.0344 - val_accuracy: 0.7400\n",
      "Epoch 829/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8147 - accuracy: 0.7953 - val_loss: 1.0499 - val_accuracy: 0.7370\n",
      "Epoch 830/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8190 - accuracy: 0.7943 - val_loss: 1.0364 - val_accuracy: 0.7400\n",
      "Epoch 831/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8225 - accuracy: 0.7921 - val_loss: 1.0661 - val_accuracy: 0.7260\n",
      "Epoch 832/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8220 - accuracy: 0.7909 - val_loss: 1.0364 - val_accuracy: 0.7300\n",
      "Epoch 833/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8167 - accuracy: 0.7939 - val_loss: 1.0356 - val_accuracy: 0.7370\n",
      "Epoch 834/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8149 - accuracy: 0.7985 - val_loss: 1.0606 - val_accuracy: 0.7210\n",
      "Epoch 835/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8187 - accuracy: 0.7935 - val_loss: 1.0379 - val_accuracy: 0.7360\n",
      "Epoch 836/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8151 - accuracy: 0.7964 - val_loss: 1.0318 - val_accuracy: 0.7440\n",
      "Epoch 837/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8177 - accuracy: 0.7943 - val_loss: 1.0277 - val_accuracy: 0.7420\n",
      "Epoch 838/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8129 - accuracy: 0.7945 - val_loss: 1.0564 - val_accuracy: 0.7280\n",
      "Epoch 839/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8232 - accuracy: 0.7872 - val_loss: 1.0360 - val_accuracy: 0.7390\n",
      "Epoch 840/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8117 - accuracy: 0.7948 - val_loss: 1.0631 - val_accuracy: 0.7240\n",
      "Epoch 841/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8179 - accuracy: 0.7965 - val_loss: 1.0221 - val_accuracy: 0.7430\n",
      "Epoch 842/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8142 - accuracy: 0.7948 - val_loss: 1.0701 - val_accuracy: 0.7320\n",
      "Epoch 843/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8120 - accuracy: 0.7961 - val_loss: 1.0373 - val_accuracy: 0.7350\n",
      "Epoch 844/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8119 - accuracy: 0.7968 - val_loss: 1.0298 - val_accuracy: 0.7430\n",
      "Epoch 845/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8163 - accuracy: 0.7948 - val_loss: 1.0341 - val_accuracy: 0.7350\n",
      "Epoch 846/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8206 - accuracy: 0.7939 - val_loss: 1.0351 - val_accuracy: 0.7400\n",
      "Epoch 847/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8117 - accuracy: 0.7935 - val_loss: 1.1361 - val_accuracy: 0.6900\n",
      "Epoch 848/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8223 - accuracy: 0.7927 - val_loss: 1.0837 - val_accuracy: 0.7170\n",
      "Epoch 849/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8188 - accuracy: 0.7983 - val_loss: 1.0400 - val_accuracy: 0.7330\n",
      "Epoch 850/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8159 - accuracy: 0.7951 - val_loss: 1.0774 - val_accuracy: 0.7240\n",
      "Epoch 851/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8170 - accuracy: 0.7960 - val_loss: 1.0313 - val_accuracy: 0.7420\n",
      "Epoch 852/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8137 - accuracy: 0.7960 - val_loss: 1.0255 - val_accuracy: 0.7380\n",
      "Epoch 853/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8087 - accuracy: 0.7983 - val_loss: 1.0908 - val_accuracy: 0.7130\n",
      "Epoch 854/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8236 - accuracy: 0.7919 - val_loss: 1.0395 - val_accuracy: 0.7390\n",
      "Epoch 855/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8140 - accuracy: 0.7989 - val_loss: 1.0446 - val_accuracy: 0.7300\n",
      "Epoch 856/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8220 - accuracy: 0.7881 - val_loss: 1.0906 - val_accuracy: 0.7170\n",
      "Epoch 857/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8230 - accuracy: 0.7932 - val_loss: 1.0644 - val_accuracy: 0.7270\n",
      "Epoch 858/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8148 - accuracy: 0.7952 - val_loss: 1.0690 - val_accuracy: 0.7240\n",
      "Epoch 859/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8224 - accuracy: 0.7893 - val_loss: 1.1052 - val_accuracy: 0.7150\n",
      "Epoch 860/1000\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.8236 - accuracy: 0.7903 - val_loss: 1.0757 - val_accuracy: 0.7220\n",
      "Epoch 861/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.8142 - accuracy: 0.7948 - val_loss: 1.0305 - val_accuracy: 0.7400\n",
      "Epoch 862/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8116 - accuracy: 0.7969 - val_loss: 1.0322 - val_accuracy: 0.7400\n",
      "Epoch 863/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8214 - accuracy: 0.7915 - val_loss: 1.0502 - val_accuracy: 0.7340\n",
      "Epoch 864/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8096 - accuracy: 0.7979 - val_loss: 1.0653 - val_accuracy: 0.7170\n",
      "Epoch 865/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8203 - accuracy: 0.7927 - val_loss: 1.0186 - val_accuracy: 0.7410\n",
      "Epoch 866/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8164 - accuracy: 0.7964 - val_loss: 1.0461 - val_accuracy: 0.7340\n",
      "Epoch 867/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8207 - accuracy: 0.7940 - val_loss: 1.0285 - val_accuracy: 0.7430\n",
      "Epoch 868/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8112 - accuracy: 0.7989 - val_loss: 1.0646 - val_accuracy: 0.7240\n",
      "Epoch 869/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8175 - accuracy: 0.7937 - val_loss: 1.0218 - val_accuracy: 0.7470\n",
      "Epoch 870/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8107 - accuracy: 0.7992 - val_loss: 1.0806 - val_accuracy: 0.7230\n",
      "Epoch 871/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8158 - accuracy: 0.7953 - val_loss: 1.0492 - val_accuracy: 0.7250\n",
      "Epoch 872/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8211 - accuracy: 0.7924 - val_loss: 1.0307 - val_accuracy: 0.7420\n",
      "Epoch 873/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8105 - accuracy: 0.7977 - val_loss: 1.1540 - val_accuracy: 0.6940\n",
      "Epoch 874/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8236 - accuracy: 0.7923 - val_loss: 1.0894 - val_accuracy: 0.7110\n",
      "Epoch 875/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8211 - accuracy: 0.7935 - val_loss: 1.0467 - val_accuracy: 0.7320\n",
      "Epoch 876/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8197 - accuracy: 0.7884 - val_loss: 1.0303 - val_accuracy: 0.7360\n",
      "Epoch 877/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8120 - accuracy: 0.7955 - val_loss: 1.0271 - val_accuracy: 0.7390\n",
      "Epoch 878/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8196 - accuracy: 0.7924 - val_loss: 1.0331 - val_accuracy: 0.7370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 879/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8189 - accuracy: 0.7940 - val_loss: 1.0947 - val_accuracy: 0.7070\n",
      "Epoch 880/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8144 - accuracy: 0.7964 - val_loss: 1.0473 - val_accuracy: 0.7310\n",
      "Epoch 881/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8078 - accuracy: 0.8001 - val_loss: 1.0369 - val_accuracy: 0.7420\n",
      "Epoch 882/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8096 - accuracy: 0.7951 - val_loss: 1.0433 - val_accuracy: 0.7390\n",
      "Epoch 883/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8133 - accuracy: 0.7964 - val_loss: 1.0230 - val_accuracy: 0.7410\n",
      "Epoch 884/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8151 - accuracy: 0.7969 - val_loss: 1.0511 - val_accuracy: 0.7340\n",
      "Epoch 885/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8110 - accuracy: 0.7996 - val_loss: 1.0352 - val_accuracy: 0.7330\n",
      "Epoch 886/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8090 - accuracy: 0.7985 - val_loss: 1.0296 - val_accuracy: 0.7400\n",
      "Epoch 887/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8054 - accuracy: 0.7999 - val_loss: 1.0389 - val_accuracy: 0.7300\n",
      "Epoch 888/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8081 - accuracy: 0.7941 - val_loss: 1.0251 - val_accuracy: 0.7370\n",
      "Epoch 889/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8138 - accuracy: 0.7944 - val_loss: 1.0463 - val_accuracy: 0.7320\n",
      "Epoch 890/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8237 - accuracy: 0.7897 - val_loss: 1.0364 - val_accuracy: 0.7380\n",
      "Epoch 891/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8193 - accuracy: 0.7921 - val_loss: 1.0209 - val_accuracy: 0.7420\n",
      "Epoch 892/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8128 - accuracy: 0.7969 - val_loss: 1.1080 - val_accuracy: 0.7060\n",
      "Epoch 893/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8093 - accuracy: 0.7976 - val_loss: 1.0270 - val_accuracy: 0.7380\n",
      "Epoch 894/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8174 - accuracy: 0.7927 - val_loss: 1.0248 - val_accuracy: 0.7440\n",
      "Epoch 895/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8178 - accuracy: 0.7952 - val_loss: 1.2531 - val_accuracy: 0.6630\n",
      "Epoch 896/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8285 - accuracy: 0.7920 - val_loss: 1.0693 - val_accuracy: 0.7220\n",
      "Epoch 897/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8159 - accuracy: 0.7953 - val_loss: 1.0895 - val_accuracy: 0.7040\n",
      "Epoch 898/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.8195 - accuracy: 0.7927 - val_loss: 1.0445 - val_accuracy: 0.7320\n",
      "Epoch 899/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8206 - accuracy: 0.7951 - val_loss: 1.0378 - val_accuracy: 0.7360\n",
      "Epoch 900/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8166 - accuracy: 0.7957 - val_loss: 1.0315 - val_accuracy: 0.7440\n",
      "Epoch 901/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.8103 - accuracy: 0.7987 - val_loss: 1.0381 - val_accuracy: 0.7400\n",
      "Epoch 902/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8082 - accuracy: 0.7965 - val_loss: 1.1039 - val_accuracy: 0.7170\n",
      "Epoch 903/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8176 - accuracy: 0.7987 - val_loss: 1.0478 - val_accuracy: 0.7310\n",
      "Epoch 904/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8079 - accuracy: 0.7993 - val_loss: 1.0323 - val_accuracy: 0.7390\n",
      "Epoch 905/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8050 - accuracy: 0.8000 - val_loss: 1.0361 - val_accuracy: 0.7350\n",
      "Epoch 906/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8058 - accuracy: 0.8016 - val_loss: 1.0796 - val_accuracy: 0.7180\n",
      "Epoch 907/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8264 - accuracy: 0.7865 - val_loss: 1.0712 - val_accuracy: 0.7200\n",
      "Epoch 908/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.8045 - accuracy: 0.7980 - val_loss: 1.0485 - val_accuracy: 0.7330\n",
      "Epoch 909/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8111 - accuracy: 0.7968 - val_loss: 1.0580 - val_accuracy: 0.7280\n",
      "Epoch 910/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.8364 - accuracy: 0.7868 - val_loss: 1.0816 - val_accuracy: 0.7100\n",
      "Epoch 911/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.8433 - accuracy: 0.7831 - val_loss: 1.0606 - val_accuracy: 0.7220\n",
      "Epoch 912/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8128 - accuracy: 0.7980 - val_loss: 1.1159 - val_accuracy: 0.7030\n",
      "Epoch 913/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8120 - accuracy: 0.7952 - val_loss: 1.0552 - val_accuracy: 0.7320\n",
      "Epoch 914/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8067 - accuracy: 0.7975 - val_loss: 1.0388 - val_accuracy: 0.7310\n",
      "Epoch 915/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8266 - accuracy: 0.7927 - val_loss: 1.0279 - val_accuracy: 0.7430\n",
      "Epoch 916/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.8109 - accuracy: 0.7955 - val_loss: 1.0327 - val_accuracy: 0.7410\n",
      "Epoch 917/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8040 - accuracy: 0.8013 - val_loss: 1.0716 - val_accuracy: 0.7270\n",
      "Epoch 918/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8060 - accuracy: 0.7959 - val_loss: 1.0425 - val_accuracy: 0.7380\n",
      "Epoch 919/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8050 - accuracy: 0.7993 - val_loss: 1.0219 - val_accuracy: 0.7390\n",
      "Epoch 920/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8136 - accuracy: 0.7941 - val_loss: 1.0470 - val_accuracy: 0.7320\n",
      "Epoch 921/1000\n",
      "7500/7500 [==============================] - 0s 45us/step - loss: 0.8320 - accuracy: 0.7831 - val_loss: 1.0448 - val_accuracy: 0.7310\n",
      "Epoch 922/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.8022 - accuracy: 0.8027 - val_loss: 1.0444 - val_accuracy: 0.7360\n",
      "Epoch 923/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8037 - accuracy: 0.8005 - val_loss: 1.0756 - val_accuracy: 0.7130\n",
      "Epoch 924/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8195 - accuracy: 0.7955 - val_loss: 1.0687 - val_accuracy: 0.7200\n",
      "Epoch 925/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8187 - accuracy: 0.7952 - val_loss: 1.0583 - val_accuracy: 0.7300\n",
      "Epoch 926/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8096 - accuracy: 0.8000 - val_loss: 1.0787 - val_accuracy: 0.7200\n",
      "Epoch 927/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8138 - accuracy: 0.7936 - val_loss: 1.0556 - val_accuracy: 0.7220\n",
      "Epoch 928/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8057 - accuracy: 0.8016 - val_loss: 1.0379 - val_accuracy: 0.7360\n",
      "Epoch 929/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8073 - accuracy: 0.7961 - val_loss: 1.0283 - val_accuracy: 0.7380\n",
      "Epoch 930/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8041 - accuracy: 0.8001 - val_loss: 1.0470 - val_accuracy: 0.7300\n",
      "Epoch 931/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8058 - accuracy: 0.8008 - val_loss: 1.1325 - val_accuracy: 0.6940\n",
      "Epoch 932/1000\n",
      "7500/7500 [==============================] - 0s 47us/step - loss: 0.8286 - accuracy: 0.7868 - val_loss: 1.0299 - val_accuracy: 0.7300\n",
      "Epoch 933/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8045 - accuracy: 0.7984 - val_loss: 1.0690 - val_accuracy: 0.7220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 934/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8033 - accuracy: 0.8029 - val_loss: 1.0239 - val_accuracy: 0.7360\n",
      "Epoch 935/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8011 - accuracy: 0.8037 - val_loss: 1.0386 - val_accuracy: 0.7310\n",
      "Epoch 936/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8164 - accuracy: 0.7949 - val_loss: 1.0277 - val_accuracy: 0.7410\n",
      "Epoch 937/1000\n",
      "7500/7500 [==============================] - 0s 46us/step - loss: 0.8078 - accuracy: 0.7957 - val_loss: 1.0257 - val_accuracy: 0.7420\n",
      "Epoch 938/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8155 - accuracy: 0.7949 - val_loss: 1.0326 - val_accuracy: 0.7400\n",
      "Epoch 939/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8087 - accuracy: 0.7977 - val_loss: 1.1220 - val_accuracy: 0.6990\n",
      "Epoch 940/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8244 - accuracy: 0.7847 - val_loss: 1.1569 - val_accuracy: 0.7000\n",
      "Epoch 941/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8129 - accuracy: 0.7931 - val_loss: 1.0647 - val_accuracy: 0.7170\n",
      "Epoch 942/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8118 - accuracy: 0.7959 - val_loss: 1.0798 - val_accuracy: 0.7130\n",
      "Epoch 943/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.8068 - accuracy: 0.7968 - val_loss: 1.0608 - val_accuracy: 0.7210\n",
      "Epoch 944/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8109 - accuracy: 0.7972 - val_loss: 1.0426 - val_accuracy: 0.7290\n",
      "Epoch 945/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8113 - accuracy: 0.7993 - val_loss: 1.0797 - val_accuracy: 0.7250\n",
      "Epoch 946/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8148 - accuracy: 0.7988 - val_loss: 1.0636 - val_accuracy: 0.7270\n",
      "Epoch 947/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8054 - accuracy: 0.8032 - val_loss: 1.0321 - val_accuracy: 0.7400\n",
      "Epoch 948/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8169 - accuracy: 0.7948 - val_loss: 1.0947 - val_accuracy: 0.7110\n",
      "Epoch 949/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8041 - accuracy: 0.8003 - val_loss: 1.0462 - val_accuracy: 0.7370\n",
      "Epoch 950/1000\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.7963 - accuracy: 0.80 - 0s 37us/step - loss: 0.7990 - accuracy: 0.8027 - val_loss: 1.0830 - val_accuracy: 0.7220\n",
      "Epoch 951/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8304 - accuracy: 0.7908 - val_loss: 1.0514 - val_accuracy: 0.7280\n",
      "Epoch 952/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8082 - accuracy: 0.7991 - val_loss: 1.0568 - val_accuracy: 0.7280\n",
      "Epoch 953/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8035 - accuracy: 0.8000 - val_loss: 1.0417 - val_accuracy: 0.7430\n",
      "Epoch 954/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.7984 - accuracy: 0.8041 - val_loss: 1.0213 - val_accuracy: 0.7420\n",
      "Epoch 955/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8268 - accuracy: 0.7880 - val_loss: 1.0999 - val_accuracy: 0.7180\n",
      "Epoch 956/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8006 - accuracy: 0.8011 - val_loss: 1.0309 - val_accuracy: 0.7430\n",
      "Epoch 957/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8018 - accuracy: 0.8016 - val_loss: 1.0361 - val_accuracy: 0.7340\n",
      "Epoch 958/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7987 - accuracy: 0.8043 - val_loss: 1.0297 - val_accuracy: 0.7370\n",
      "Epoch 959/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8291 - accuracy: 0.7864 - val_loss: 1.0381 - val_accuracy: 0.7300\n",
      "Epoch 960/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8253 - accuracy: 0.7901 - val_loss: 1.0290 - val_accuracy: 0.7380\n",
      "Epoch 961/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8072 - accuracy: 0.7999 - val_loss: 1.0440 - val_accuracy: 0.7380\n",
      "Epoch 962/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.7972 - accuracy: 0.8015 - val_loss: 1.0264 - val_accuracy: 0.7380\n",
      "Epoch 963/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7978 - accuracy: 0.8039 - val_loss: 1.1539 - val_accuracy: 0.7030\n",
      "Epoch 964/1000\n",
      "7500/7500 [==============================] - 0s 39us/step - loss: 0.8127 - accuracy: 0.7996 - val_loss: 1.0223 - val_accuracy: 0.7450\n",
      "Epoch 965/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.7981 - accuracy: 0.8044 - val_loss: 1.1134 - val_accuracy: 0.7100\n",
      "Epoch 966/1000\n",
      "7500/7500 [==============================] - 0s 65us/step - loss: 0.8161 - accuracy: 0.7949 - val_loss: 1.0258 - val_accuracy: 0.7370\n",
      "Epoch 967/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.7990 - accuracy: 0.8043 - val_loss: 1.0243 - val_accuracy: 0.7440\n",
      "Epoch 968/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7993 - accuracy: 0.8015 - val_loss: 1.1031 - val_accuracy: 0.7170\n",
      "Epoch 969/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.8125 - accuracy: 0.7960 - val_loss: 1.0532 - val_accuracy: 0.7320\n",
      "Epoch 970/1000\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.8064 - accuracy: 0.7977 - val_loss: 1.0171 - val_accuracy: 0.7490\n",
      "Epoch 971/1000\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8020 - accuracy: 0.8031 - val_loss: 1.0309 - val_accuracy: 0.7390\n",
      "Epoch 972/1000\n",
      "7500/7500 [==============================] - 0s 44us/step - loss: 0.8038 - accuracy: 0.7989 - val_loss: 1.0748 - val_accuracy: 0.7260\n",
      "Epoch 973/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8050 - accuracy: 0.8001 - val_loss: 1.0993 - val_accuracy: 0.7100\n",
      "Epoch 974/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.8036 - accuracy: 0.8001 - val_loss: 1.0772 - val_accuracy: 0.7190\n",
      "Epoch 975/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8277 - accuracy: 0.7888 - val_loss: 1.0948 - val_accuracy: 0.7230\n",
      "Epoch 976/1000\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.8054 - accuracy: 0.8013 - val_loss: 1.0203 - val_accuracy: 0.7470\n",
      "Epoch 977/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7976 - accuracy: 0.8012 - val_loss: 1.0314 - val_accuracy: 0.7430\n",
      "Epoch 978/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7929 - accuracy: 0.8052 - val_loss: 1.0439 - val_accuracy: 0.7340\n",
      "Epoch 979/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8009 - accuracy: 0.8003 - val_loss: 1.0233 - val_accuracy: 0.7360\n",
      "Epoch 980/1000\n",
      "7500/7500 [==============================] - 0s 43us/step - loss: 0.7998 - accuracy: 0.8029 - val_loss: 1.0509 - val_accuracy: 0.7310\n",
      "Epoch 981/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.7993 - accuracy: 0.8036 - val_loss: 1.0609 - val_accuracy: 0.7220\n",
      "Epoch 982/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8010 - accuracy: 0.8012 - val_loss: 1.0433 - val_accuracy: 0.7270\n",
      "Epoch 983/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8211 - accuracy: 0.7911 - val_loss: 1.0836 - val_accuracy: 0.7110\n",
      "Epoch 984/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8002 - accuracy: 0.8017 - val_loss: 1.1341 - val_accuracy: 0.7050\n",
      "Epoch 985/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.8033 - accuracy: 0.8000 - val_loss: 1.0919 - val_accuracy: 0.7060\n",
      "Epoch 986/1000\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8128 - accuracy: 0.7939 - val_loss: 1.0920 - val_accuracy: 0.7110\n",
      "Epoch 987/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8033 - accuracy: 0.8047 - val_loss: 1.0246 - val_accuracy: 0.7370\n",
      "Epoch 988/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8134 - accuracy: 0.7932 - val_loss: 1.7471 - val_accuracy: 0.5230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8870 - accuracy: 0.7761 - val_loss: 1.0743 - val_accuracy: 0.7220\n",
      "Epoch 990/1000\n",
      "7500/7500 [==============================] - 0s 40us/step - loss: 0.8083 - accuracy: 0.7975 - val_loss: 1.0560 - val_accuracy: 0.7290\n",
      "Epoch 991/1000\n",
      "7500/7500 [==============================] - 0s 37us/step - loss: 0.7992 - accuracy: 0.8020 - val_loss: 1.0292 - val_accuracy: 0.7400\n",
      "Epoch 992/1000\n",
      "7500/7500 [==============================] - 0s 34us/step - loss: 0.7989 - accuracy: 0.7991 - val_loss: 1.0351 - val_accuracy: 0.7260\n",
      "Epoch 993/1000\n",
      "7500/7500 [==============================] - 0s 42us/step - loss: 0.7930 - accuracy: 0.8043 - val_loss: 1.0510 - val_accuracy: 0.7310\n",
      "Epoch 994/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.7973 - accuracy: 0.8036 - val_loss: 1.0434 - val_accuracy: 0.7330\n",
      "Epoch 995/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8219 - accuracy: 0.7959 - val_loss: 1.0238 - val_accuracy: 0.7400\n",
      "Epoch 996/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.8007 - accuracy: 0.8016 - val_loss: 1.0284 - val_accuracy: 0.7320\n",
      "Epoch 997/1000\n",
      "7500/7500 [==============================] - 0s 36us/step - loss: 0.7945 - accuracy: 0.8060 - val_loss: 1.0309 - val_accuracy: 0.7430\n",
      "Epoch 998/1000\n",
      "7500/7500 [==============================] - 0s 38us/step - loss: 0.7980 - accuracy: 0.8032 - val_loss: 1.0781 - val_accuracy: 0.7200\n",
      "Epoch 999/1000\n",
      "7500/7500 [==============================] - 0s 41us/step - loss: 0.8043 - accuracy: 0.7973 - val_loss: 1.0354 - val_accuracy: 0.7380\n",
      "Epoch 1000/1000\n",
      "7500/7500 [==============================] - 0s 35us/step - loss: 0.8329 - accuracy: 0.7911 - val_loss: 1.0329 - val_accuracy: 0.7380\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.005), input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "L1_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=1000,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model.history\n",
    "\n",
    "acc_values = L1_model_dict['accuracy'] \n",
    "val_acc_values = L1_model_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 49us/step\n",
      "Training Loss: 0.793 Training Accuracy: 0.807\n",
      "1500/1500 [==============================] - 0s 52us/step\n",
      "Testing Loss: 0.923 Testing Accuracy: 0.762\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about the best result you've achieved so far, but you were training for quite a while! Next, experiment with dropout regularization to see if it offers any advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "7500/7500 [==============================] - 1s 104us/step - loss: 1.9819 - accuracy: 0.1491 - val_loss: 1.9450 - val_accuracy: 0.1430\n",
      "Epoch 2/200\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 1.9581 - accuracy: 0.1579 - val_loss: 1.9367 - val_accuracy: 0.1650\n",
      "Epoch 3/200\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 1.9488 - accuracy: 0.1687 - val_loss: 1.9308 - val_accuracy: 0.1890\n",
      "Epoch 4/200\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.9376 - accuracy: 0.1796 - val_loss: 1.9259 - val_accuracy: 0.2060\n",
      "Epoch 5/200\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.9297 - accuracy: 0.1899 - val_loss: 1.9205 - val_accuracy: 0.2140\n",
      "Epoch 6/200\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.9247 - accuracy: 0.1957 - val_loss: 1.9146 - val_accuracy: 0.2220\n",
      "Epoch 7/200\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 1.9182 - accuracy: 0.2015 - val_loss: 1.9073 - val_accuracy: 0.2320\n",
      "Epoch 8/200\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.9097 - accuracy: 0.2104 - val_loss: 1.9002 - val_accuracy: 0.2460\n",
      "Epoch 9/200\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 1.9033 - accuracy: 0.2195 - val_loss: 1.8916 - val_accuracy: 0.2470\n",
      "Epoch 10/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.8974 - accuracy: 0.2220 - val_loss: 1.8830 - val_accuracy: 0.2510\n",
      "Epoch 11/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.8863 - accuracy: 0.2291 - val_loss: 1.8725 - val_accuracy: 0.2510\n",
      "Epoch 12/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.8764 - accuracy: 0.2395 - val_loss: 1.8612 - val_accuracy: 0.2670\n",
      "Epoch 13/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.8718 - accuracy: 0.2393 - val_loss: 1.8498 - val_accuracy: 0.2820\n",
      "Epoch 14/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.8602 - accuracy: 0.2513 - val_loss: 1.8370 - val_accuracy: 0.2970\n",
      "Epoch 15/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.8503 - accuracy: 0.2607 - val_loss: 1.8226 - val_accuracy: 0.3000\n",
      "Epoch 16/200\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.8382 - accuracy: 0.2657 - val_loss: 1.8077 - val_accuracy: 0.3130\n",
      "Epoch 17/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.8209 - accuracy: 0.2804 - val_loss: 1.7901 - val_accuracy: 0.3220\n",
      "Epoch 18/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.8004 - accuracy: 0.2888 - val_loss: 1.7718 - val_accuracy: 0.3450\n",
      "Epoch 19/200\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.7949 - accuracy: 0.2892 - val_loss: 1.7541 - val_accuracy: 0.3710\n",
      "Epoch 20/200\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 1.7759 - accuracy: 0.3060 - val_loss: 1.7328 - val_accuracy: 0.3740\n",
      "Epoch 21/200\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 1.7678 - accuracy: 0.3047 - val_loss: 1.7138 - val_accuracy: 0.3850\n",
      "Epoch 22/200\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.7477 - accuracy: 0.3220 - val_loss: 1.6922 - val_accuracy: 0.4060\n",
      "Epoch 23/200\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 1.7377 - accuracy: 0.3289 - val_loss: 1.6725 - val_accuracy: 0.4340\n",
      "Epoch 24/200\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.7069 - accuracy: 0.3468 - val_loss: 1.6506 - val_accuracy: 0.4520\n",
      "Epoch 25/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.7021 - accuracy: 0.3411 - val_loss: 1.6295 - val_accuracy: 0.4640\n",
      "Epoch 26/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.6836 - accuracy: 0.3549 - val_loss: 1.6069 - val_accuracy: 0.4820\n",
      "Epoch 27/200\n",
      "7500/7500 [==============================] - 0s 61us/step - loss: 1.6657 - accuracy: 0.3573 - val_loss: 1.5821 - val_accuracy: 0.4950\n",
      "Epoch 28/200\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.6464 - accuracy: 0.3716 - val_loss: 1.5606 - val_accuracy: 0.5130\n",
      "Epoch 29/200\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 1.6358 - accuracy: 0.3756 - val_loss: 1.5385 - val_accuracy: 0.5200\n",
      "Epoch 30/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.6062 - accuracy: 0.3864 - val_loss: 1.5155 - val_accuracy: 0.5330\n",
      "Epoch 31/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.5936 - accuracy: 0.3936 - val_loss: 1.4928 - val_accuracy: 0.5440\n",
      "Epoch 32/200\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.5840 - accuracy: 0.4000 - val_loss: 1.4721 - val_accuracy: 0.5550\n",
      "Epoch 33/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.5630 - accuracy: 0.4157 - val_loss: 1.4482 - val_accuracy: 0.5530\n",
      "Epoch 34/200\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.5327 - accuracy: 0.4216 - val_loss: 1.4257 - val_accuracy: 0.5640\n",
      "Epoch 35/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.5235 - accuracy: 0.4315 - val_loss: 1.4036 - val_accuracy: 0.5750\n",
      "Epoch 36/200\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 1.5122 - accuracy: 0.4305 - val_loss: 1.3847 - val_accuracy: 0.5830\n",
      "Epoch 37/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.4927 - accuracy: 0.4412 - val_loss: 1.3649 - val_accuracy: 0.5880\n",
      "Epoch 38/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.4836 - accuracy: 0.4369 - val_loss: 1.3439 - val_accuracy: 0.5930\n",
      "Epoch 39/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.4607 - accuracy: 0.4509 - val_loss: 1.3259 - val_accuracy: 0.6010\n",
      "Epoch 40/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.4495 - accuracy: 0.4624 - val_loss: 1.3081 - val_accuracy: 0.6080\n",
      "Epoch 41/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.4177 - accuracy: 0.4701 - val_loss: 1.2865 - val_accuracy: 0.6130\n",
      "Epoch 42/200\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 1.4245 - accuracy: 0.4659 - val_loss: 1.2713 - val_accuracy: 0.6130\n",
      "Epoch 43/200\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 1.4046 - accuracy: 0.4744 - val_loss: 1.2558 - val_accuracy: 0.6210\n",
      "Epoch 44/200\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.3906 - accuracy: 0.4816 - val_loss: 1.2380 - val_accuracy: 0.6280\n",
      "Epoch 45/200\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.3699 - accuracy: 0.4804 - val_loss: 1.2177 - val_accuracy: 0.6340\n",
      "Epoch 46/200\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 1.3529 - accuracy: 0.4900 - val_loss: 1.2062 - val_accuracy: 0.6370\n",
      "Epoch 47/200\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.3587 - accuracy: 0.4825 - val_loss: 1.1909 - val_accuracy: 0.6380\n",
      "Epoch 48/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.3451 - accuracy: 0.5045 - val_loss: 1.1757 - val_accuracy: 0.6480\n",
      "Epoch 49/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.3288 - accuracy: 0.5071 - val_loss: 1.1619 - val_accuracy: 0.6510\n",
      "Epoch 50/200\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.3216 - accuracy: 0.5015 - val_loss: 1.1493 - val_accuracy: 0.6550\n",
      "Epoch 51/200\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 1.3015 - accuracy: 0.5131 - val_loss: 1.1362 - val_accuracy: 0.6570\n",
      "Epoch 52/200\n",
      "7500/7500 [==============================] - 1s 68us/step - loss: 1.3006 - accuracy: 0.5112 - val_loss: 1.1255 - val_accuracy: 0.6580\n",
      "Epoch 53/200\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 1.2907 - accuracy: 0.5171 - val_loss: 1.1161 - val_accuracy: 0.6570\n",
      "Epoch 54/200\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.2709 - accuracy: 0.5303 - val_loss: 1.1024 - val_accuracy: 0.6590\n",
      "Epoch 55/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.2581 - accuracy: 0.5305 - val_loss: 1.0926 - val_accuracy: 0.6620\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.2546 - accuracy: 0.5240 - val_loss: 1.0822 - val_accuracy: 0.6630\n",
      "Epoch 57/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.2481 - accuracy: 0.5367 - val_loss: 1.0722 - val_accuracy: 0.6660\n",
      "Epoch 58/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.2356 - accuracy: 0.5373 - val_loss: 1.0604 - val_accuracy: 0.6650\n",
      "Epoch 59/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.2257 - accuracy: 0.5427 - val_loss: 1.0490 - val_accuracy: 0.6710\n",
      "Epoch 60/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.2241 - accuracy: 0.5417 - val_loss: 1.0412 - val_accuracy: 0.6690\n",
      "Epoch 61/200\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.2117 - accuracy: 0.5451 - val_loss: 1.0320 - val_accuracy: 0.6760\n",
      "Epoch 62/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.2043 - accuracy: 0.5552 - val_loss: 1.0253 - val_accuracy: 0.6770\n",
      "Epoch 63/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1779 - accuracy: 0.5557 - val_loss: 1.0148 - val_accuracy: 0.6770\n",
      "Epoch 64/200\n",
      "7500/7500 [==============================] - 0s 62us/step - loss: 1.1755 - accuracy: 0.5660 - val_loss: 1.0063 - val_accuracy: 0.6740\n",
      "Epoch 65/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1742 - accuracy: 0.5659 - val_loss: 0.9987 - val_accuracy: 0.6830\n",
      "Epoch 66/200\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 1.1781 - accuracy: 0.5597 - val_loss: 0.9941 - val_accuracy: 0.6840\n",
      "Epoch 67/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1650 - accuracy: 0.5609 - val_loss: 0.9865 - val_accuracy: 0.6870\n",
      "Epoch 68/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1540 - accuracy: 0.5649 - val_loss: 0.9763 - val_accuracy: 0.6830\n",
      "Epoch 69/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1442 - accuracy: 0.5751 - val_loss: 0.9686 - val_accuracy: 0.6800\n",
      "Epoch 70/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1441 - accuracy: 0.5719 - val_loss: 0.9627 - val_accuracy: 0.6860\n",
      "Epoch 71/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1264 - accuracy: 0.5840 - val_loss: 0.9557 - val_accuracy: 0.6820\n",
      "Epoch 72/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.1303 - accuracy: 0.5791 - val_loss: 0.9503 - val_accuracy: 0.6850\n",
      "Epoch 73/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1201 - accuracy: 0.5785 - val_loss: 0.9419 - val_accuracy: 0.6870\n",
      "Epoch 74/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1080 - accuracy: 0.5819 - val_loss: 0.9372 - val_accuracy: 0.6910\n",
      "Epoch 75/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1005 - accuracy: 0.5972 - val_loss: 0.9296 - val_accuracy: 0.6870\n",
      "Epoch 76/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.1033 - accuracy: 0.5851 - val_loss: 0.9262 - val_accuracy: 0.6900\n",
      "Epoch 77/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 1.0929 - accuracy: 0.5955 - val_loss: 0.9200 - val_accuracy: 0.6910\n",
      "Epoch 78/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.0879 - accuracy: 0.5925 - val_loss: 0.9157 - val_accuracy: 0.6890\n",
      "Epoch 79/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.0934 - accuracy: 0.5993 - val_loss: 0.9137 - val_accuracy: 0.6920\n",
      "Epoch 80/200\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 1.0694 - accuracy: 0.6059 - val_loss: 0.9067 - val_accuracy: 0.7000\n",
      "Epoch 81/200\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.0815 - accuracy: 0.5949 - val_loss: 0.9035 - val_accuracy: 0.6990\n",
      "Epoch 82/200\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 1.0677 - accuracy: 0.6041 - val_loss: 0.8988 - val_accuracy: 0.6990\n",
      "Epoch 83/200\n",
      "7500/7500 [==============================] - 0s 59us/step - loss: 1.0567 - accuracy: 0.6025 - val_loss: 0.8953 - val_accuracy: 0.6950\n",
      "Epoch 84/200\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 1.0622 - accuracy: 0.6033 - val_loss: 0.8898 - val_accuracy: 0.6970\n",
      "Epoch 85/200\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 1.0452 - accuracy: 0.6144 - val_loss: 0.8831 - val_accuracy: 0.6950\n",
      "Epoch 86/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.0507 - accuracy: 0.6100 - val_loss: 0.8803 - val_accuracy: 0.6970\n",
      "Epoch 87/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.0483 - accuracy: 0.6155 - val_loss: 0.8765 - val_accuracy: 0.6970\n",
      "Epoch 88/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.0482 - accuracy: 0.6073 - val_loss: 0.8726 - val_accuracy: 0.7000\n",
      "Epoch 89/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.0322 - accuracy: 0.6131 - val_loss: 0.8673 - val_accuracy: 0.6980\n",
      "Epoch 90/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 1.0236 - accuracy: 0.6140 - val_loss: 0.8642 - val_accuracy: 0.7040\n",
      "Epoch 91/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 1.0168 - accuracy: 0.6221 - val_loss: 0.8599 - val_accuracy: 0.7040\n",
      "Epoch 92/200\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 1.0317 - accuracy: 0.6195 - val_loss: 0.8578 - val_accuracy: 0.7040\n",
      "Epoch 93/200\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 1.0277 - accuracy: 0.6140 - val_loss: 0.8569 - val_accuracy: 0.7070\n",
      "Epoch 94/200\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 1.0163 - accuracy: 0.6293 - val_loss: 0.8523 - val_accuracy: 0.7060\n",
      "Epoch 95/200\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 1.0086 - accuracy: 0.6251 - val_loss: 0.8489 - val_accuracy: 0.7060\n",
      "Epoch 96/200\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 1.0048 - accuracy: 0.6263 - val_loss: 0.8458 - val_accuracy: 0.7100\n",
      "Epoch 97/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 1.0068 - accuracy: 0.6287 - val_loss: 0.8444 - val_accuracy: 0.7100\n",
      "Epoch 98/200\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.9853 - accuracy: 0.6277 - val_loss: 0.8402 - val_accuracy: 0.7100\n",
      "Epoch 99/200\n",
      "7500/7500 [==============================] - 1s 67us/step - loss: 0.9989 - accuracy: 0.6324 - val_loss: 0.8365 - val_accuracy: 0.7170\n",
      "Epoch 100/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9901 - accuracy: 0.6320 - val_loss: 0.8337 - val_accuracy: 0.7150\n",
      "Epoch 101/200\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.9832 - accuracy: 0.6380 - val_loss: 0.8298 - val_accuracy: 0.7140\n",
      "Epoch 102/200\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.9671 - accuracy: 0.6408 - val_loss: 0.8256 - val_accuracy: 0.7110\n",
      "Epoch 103/200\n",
      "7500/7500 [==============================] - 0s 54us/step - loss: 0.9700 - accuracy: 0.6429 - val_loss: 0.8226 - val_accuracy: 0.7150\n",
      "Epoch 104/200\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.9480 - accuracy: 0.6520 - val_loss: 0.8171 - val_accuracy: 0.7150\n",
      "Epoch 105/200\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.9576 - accuracy: 0.6412 - val_loss: 0.8151 - val_accuracy: 0.7180\n",
      "Epoch 106/200\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.9679 - accuracy: 0.6436 - val_loss: 0.8149 - val_accuracy: 0.7210\n",
      "Epoch 107/200\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.9648 - accuracy: 0.6468 - val_loss: 0.8113 - val_accuracy: 0.7230\n",
      "Epoch 108/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9459 - accuracy: 0.6540 - val_loss: 0.8100 - val_accuracy: 0.7210\n",
      "Epoch 109/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.9505 - accuracy: 0.6541 - val_loss: 0.8072 - val_accuracy: 0.7250\n",
      "Epoch 110/200\n",
      "7500/7500 [==============================] - 0s 60us/step - loss: 0.9437 - accuracy: 0.6480 - val_loss: 0.8034 - val_accuracy: 0.7160\n",
      "Epoch 111/200\n",
      "7500/7500 [==============================] - 0s 66us/step - loss: 0.9476 - accuracy: 0.6517 - val_loss: 0.8014 - val_accuracy: 0.7210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9368 - accuracy: 0.6549 - val_loss: 0.7984 - val_accuracy: 0.7190\n",
      "Epoch 113/200\n",
      "7500/7500 [==============================] - 0s 57us/step - loss: 0.9446 - accuracy: 0.6564 - val_loss: 0.7977 - val_accuracy: 0.7270\n",
      "Epoch 114/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9231 - accuracy: 0.6561 - val_loss: 0.7952 - val_accuracy: 0.7240\n",
      "Epoch 115/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9242 - accuracy: 0.6636 - val_loss: 0.7915 - val_accuracy: 0.7290\n",
      "Epoch 116/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9237 - accuracy: 0.6513 - val_loss: 0.7905 - val_accuracy: 0.7260\n",
      "Epoch 117/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9189 - accuracy: 0.6619 - val_loss: 0.7884 - val_accuracy: 0.7290\n",
      "Epoch 118/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9104 - accuracy: 0.6609 - val_loss: 0.7865 - val_accuracy: 0.7330\n",
      "Epoch 119/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9121 - accuracy: 0.6635 - val_loss: 0.7840 - val_accuracy: 0.7350\n",
      "Epoch 120/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9144 - accuracy: 0.6567 - val_loss: 0.7838 - val_accuracy: 0.7280\n",
      "Epoch 121/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.9170 - accuracy: 0.6591 - val_loss: 0.7822 - val_accuracy: 0.7320\n",
      "Epoch 122/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.9074 - accuracy: 0.6637 - val_loss: 0.7813 - val_accuracy: 0.7310\n",
      "Epoch 123/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8990 - accuracy: 0.6687 - val_loss: 0.7789 - val_accuracy: 0.7290\n",
      "Epoch 124/200\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.8933 - accuracy: 0.6672 - val_loss: 0.7753 - val_accuracy: 0.7280\n",
      "Epoch 125/200\n",
      "7500/7500 [==============================] - 0s 53us/step - loss: 0.8902 - accuracy: 0.6708 - val_loss: 0.7724 - val_accuracy: 0.7280\n",
      "Epoch 126/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8982 - accuracy: 0.6665 - val_loss: 0.7715 - val_accuracy: 0.7320\n",
      "Epoch 127/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8870 - accuracy: 0.6761 - val_loss: 0.7702 - val_accuracy: 0.7290\n",
      "Epoch 128/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8920 - accuracy: 0.6689 - val_loss: 0.7686 - val_accuracy: 0.7350\n",
      "Epoch 129/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8885 - accuracy: 0.6743 - val_loss: 0.7643 - val_accuracy: 0.7330\n",
      "Epoch 130/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8847 - accuracy: 0.6703 - val_loss: 0.7647 - val_accuracy: 0.7310\n",
      "Epoch 131/200\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.8843 - accuracy: 0.6805 - val_loss: 0.7633 - val_accuracy: 0.7320\n",
      "Epoch 132/200\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.8658 - accuracy: 0.6755 - val_loss: 0.7615 - val_accuracy: 0.7310\n",
      "Epoch 133/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8862 - accuracy: 0.6759 - val_loss: 0.7609 - val_accuracy: 0.7320\n",
      "Epoch 134/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8722 - accuracy: 0.6832 - val_loss: 0.7587 - val_accuracy: 0.7350\n",
      "Epoch 135/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8702 - accuracy: 0.6777 - val_loss: 0.7566 - val_accuracy: 0.7350\n",
      "Epoch 136/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8420 - accuracy: 0.6899 - val_loss: 0.7532 - val_accuracy: 0.7390\n",
      "Epoch 137/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.8545 - accuracy: 0.6855 - val_loss: 0.7529 - val_accuracy: 0.7290\n",
      "Epoch 138/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8567 - accuracy: 0.6872 - val_loss: 0.7533 - val_accuracy: 0.7370\n",
      "Epoch 139/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8582 - accuracy: 0.6803 - val_loss: 0.7504 - val_accuracy: 0.7380\n",
      "Epoch 140/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8553 - accuracy: 0.6836 - val_loss: 0.7486 - val_accuracy: 0.7380\n",
      "Epoch 141/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8450 - accuracy: 0.6925 - val_loss: 0.7482 - val_accuracy: 0.7360\n",
      "Epoch 142/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8522 - accuracy: 0.6931 - val_loss: 0.7463 - val_accuracy: 0.7390\n",
      "Epoch 143/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8413 - accuracy: 0.6903 - val_loss: 0.7445 - val_accuracy: 0.7320\n",
      "Epoch 144/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8542 - accuracy: 0.6895 - val_loss: 0.7430 - val_accuracy: 0.7380\n",
      "Epoch 145/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8347 - accuracy: 0.6957 - val_loss: 0.7418 - val_accuracy: 0.7400\n",
      "Epoch 146/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8432 - accuracy: 0.6929 - val_loss: 0.7420 - val_accuracy: 0.7370\n",
      "Epoch 147/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8302 - accuracy: 0.6928 - val_loss: 0.7401 - val_accuracy: 0.7390\n",
      "Epoch 148/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8327 - accuracy: 0.6897 - val_loss: 0.7392 - val_accuracy: 0.7370\n",
      "Epoch 149/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8319 - accuracy: 0.6925 - val_loss: 0.7381 - val_accuracy: 0.7340\n",
      "Epoch 150/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8404 - accuracy: 0.6936 - val_loss: 0.7361 - val_accuracy: 0.7320\n",
      "Epoch 151/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8173 - accuracy: 0.7000 - val_loss: 0.7351 - val_accuracy: 0.7330\n",
      "Epoch 152/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8214 - accuracy: 0.7009 - val_loss: 0.7350 - val_accuracy: 0.7360\n",
      "Epoch 153/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8307 - accuracy: 0.6909 - val_loss: 0.7327 - val_accuracy: 0.7380\n",
      "Epoch 154/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8107 - accuracy: 0.7027 - val_loss: 0.7300 - val_accuracy: 0.7430\n",
      "Epoch 155/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8169 - accuracy: 0.7001 - val_loss: 0.7302 - val_accuracy: 0.7430\n",
      "Epoch 156/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8362 - accuracy: 0.6865 - val_loss: 0.7294 - val_accuracy: 0.7460\n",
      "Epoch 157/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8236 - accuracy: 0.6967 - val_loss: 0.7289 - val_accuracy: 0.7450\n",
      "Epoch 158/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8034 - accuracy: 0.6997 - val_loss: 0.7279 - val_accuracy: 0.7490\n",
      "Epoch 159/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8094 - accuracy: 0.6984 - val_loss: 0.7265 - val_accuracy: 0.7450\n",
      "Epoch 160/200\n",
      "7500/7500 [==============================] - 0s 56us/step - loss: 0.8104 - accuracy: 0.7005 - val_loss: 0.7254 - val_accuracy: 0.7410\n",
      "Epoch 161/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8113 - accuracy: 0.6944 - val_loss: 0.7245 - val_accuracy: 0.7390\n",
      "Epoch 162/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.7947 - accuracy: 0.7023 - val_loss: 0.7231 - val_accuracy: 0.7450\n",
      "Epoch 163/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8110 - accuracy: 0.6957 - val_loss: 0.7228 - val_accuracy: 0.7440\n",
      "Epoch 164/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.8056 - accuracy: 0.7033 - val_loss: 0.7216 - val_accuracy: 0.7470\n",
      "Epoch 165/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.8088 - accuracy: 0.7015 - val_loss: 0.7214 - val_accuracy: 0.7430\n",
      "Epoch 166/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.7958 - accuracy: 0.7035 - val_loss: 0.7216 - val_accuracy: 0.7430\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8014 - accuracy: 0.7040 - val_loss: 0.7208 - val_accuracy: 0.7450\n",
      "Epoch 168/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7905 - accuracy: 0.7153 - val_loss: 0.7178 - val_accuracy: 0.7420\n",
      "Epoch 169/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.8050 - accuracy: 0.6972 - val_loss: 0.7175 - val_accuracy: 0.7430\n",
      "Epoch 170/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7921 - accuracy: 0.7111 - val_loss: 0.7168 - val_accuracy: 0.7410\n",
      "Epoch 171/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.7981 - accuracy: 0.7055 - val_loss: 0.7161 - val_accuracy: 0.7450\n",
      "Epoch 172/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.7830 - accuracy: 0.7137 - val_loss: 0.7144 - val_accuracy: 0.7420\n",
      "Epoch 173/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7741 - accuracy: 0.7057 - val_loss: 0.7135 - val_accuracy: 0.7470\n",
      "Epoch 174/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.7924 - accuracy: 0.7068 - val_loss: 0.7152 - val_accuracy: 0.7410\n",
      "Epoch 175/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7957 - accuracy: 0.7093 - val_loss: 0.7137 - val_accuracy: 0.7390\n",
      "Epoch 176/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7841 - accuracy: 0.7125 - val_loss: 0.7128 - val_accuracy: 0.7490\n",
      "Epoch 177/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7881 - accuracy: 0.7008 - val_loss: 0.7130 - val_accuracy: 0.7440\n",
      "Epoch 178/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7748 - accuracy: 0.7132 - val_loss: 0.7117 - val_accuracy: 0.7500\n",
      "Epoch 179/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7593 - accuracy: 0.7223 - val_loss: 0.7086 - val_accuracy: 0.7520\n",
      "Epoch 180/200\n",
      "7500/7500 [==============================] - 0s 48us/step - loss: 0.7642 - accuracy: 0.7221 - val_loss: 0.7087 - val_accuracy: 0.7440\n",
      "Epoch 181/200\n",
      "7500/7500 [==============================] - 0s 52us/step - loss: 0.7798 - accuracy: 0.7184 - val_loss: 0.7090 - val_accuracy: 0.7500\n",
      "Epoch 182/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.7707 - accuracy: 0.7200 - val_loss: 0.7082 - val_accuracy: 0.7520\n",
      "Epoch 183/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7751 - accuracy: 0.7123 - val_loss: 0.7084 - val_accuracy: 0.7490\n",
      "Epoch 184/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7695 - accuracy: 0.7149 - val_loss: 0.7084 - val_accuracy: 0.7510\n",
      "Epoch 185/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7621 - accuracy: 0.7215 - val_loss: 0.7072 - val_accuracy: 0.7480\n",
      "Epoch 186/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7592 - accuracy: 0.7209 - val_loss: 0.7060 - val_accuracy: 0.7530\n",
      "Epoch 187/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7550 - accuracy: 0.7225 - val_loss: 0.7057 - val_accuracy: 0.7460\n",
      "Epoch 188/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7683 - accuracy: 0.7209 - val_loss: 0.7054 - val_accuracy: 0.7490\n",
      "Epoch 189/200\n",
      "7500/7500 [==============================] - 0s 51us/step - loss: 0.7688 - accuracy: 0.7192 - val_loss: 0.7048 - val_accuracy: 0.7510\n",
      "Epoch 190/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7474 - accuracy: 0.7237 - val_loss: 0.7034 - val_accuracy: 0.7470\n",
      "Epoch 191/200\n",
      "7500/7500 [==============================] - 0s 55us/step - loss: 0.7682 - accuracy: 0.7176 - val_loss: 0.7028 - val_accuracy: 0.7480\n",
      "Epoch 192/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.7477 - accuracy: 0.7267 - val_loss: 0.7027 - val_accuracy: 0.7530\n",
      "Epoch 193/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7423 - accuracy: 0.7244 - val_loss: 0.7006 - val_accuracy: 0.7460\n",
      "Epoch 194/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.7572 - accuracy: 0.7205 - val_loss: 0.7005 - val_accuracy: 0.7500\n",
      "Epoch 195/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7429 - accuracy: 0.7259 - val_loss: 0.6995 - val_accuracy: 0.7550\n",
      "Epoch 196/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7448 - accuracy: 0.7243 - val_loss: 0.6994 - val_accuracy: 0.7540\n",
      "Epoch 197/200\n",
      "7500/7500 [==============================] - 0s 50us/step - loss: 0.7518 - accuracy: 0.7184 - val_loss: 0.6991 - val_accuracy: 0.7530\n",
      "Epoch 198/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7727 - accuracy: 0.7187 - val_loss: 0.6984 - val_accuracy: 0.7520\n",
      "Epoch 199/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7379 - accuracy: 0.7280 - val_loss: 0.6976 - val_accuracy: 0.7550\n",
      "Epoch 200/200\n",
      "7500/7500 [==============================] - 0s 49us/step - loss: 0.7461 - accuracy: 0.7292 - val_loss: 0.6967 - val_accuracy: 0.7550\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "model.add(layers.Dense(50, activation='relu')) #2 hidden layers\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "dropout_model = model.fit(X_train_tok,\n",
    "                    y_train_lb,\n",
    "                    epochs=200,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 0s 49us/step\n",
      "Training Loss: 0.453 Training Accuracy: 0.849\n",
      "1500/1500 [==============================] - 0s 48us/step\n",
      "Testing Loss: 0.602 Testing Accuracy: 0.783\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_tok, y_test_cat)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again! The variance did become higher again compared to L1-regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture, one of the solutions to high variance was just getting more data. You actually *have* more data, but took a subset of 10,000 units before. Let's now quadruple your data set, and see what happens. Note that you are really just lucky here, and getting more data isn't always possible, but this is a useful exercise in order to understand the power of big data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Bank_complaints.csv')\n",
    "df = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df[\"Consumer complaint narrative\"]\n",
    "y = df[\"Product\"]\n",
    "\n",
    "# train test split\n",
    "X_train_lrg, X_test_lrg, y_train_lrg, y_test_lrg = train_test_split(X, y, random_state=42)\n",
    "\n",
    "#Validation set\n",
    "X_train_final_lrg, X_val_lrg, y_train_final_lrg, y_val_lrg = train_test_split(X_train_lrg, y_train_lrg, random_state=123)\n",
    "\n",
    "\n",
    "#one-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_lrg)\n",
    "\n",
    "X_train_tok_lrg = tokenizer.texts_to_matrix(X_train_final_lrg, mode='binary')\n",
    "X_val_lrg = tokenizer.texts_to_matrix(X_val_lrg, mode='binary')\n",
    "X_test_lrg = tokenizer.texts_to_matrix(X_test_lrg, mode='binary')\n",
    "\n",
    "#one-hot encoding of products\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(y_train_final_lrg)\n",
    "\n",
    "y_train_lb_lrg = to_categorical(lb.transform(y_train_final_lrg))[:, :, 1]\n",
    "y_val_lrg = to_categorical(lb.transform(y_val_lrg))[:, :, 1]\n",
    "y_test_lrg = to_categorical(lb.transform(y_test_lrg))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 7500 samples\n",
      "Epoch 1/120\n",
      "22500/22500 [==============================] - 1s 59us/step - loss: 1.9245 - accuracy: 0.1804 - val_loss: 1.8862 - val_accuracy: 0.2251\n",
      "Epoch 2/120\n",
      "22500/22500 [==============================] - 1s 48us/step - loss: 1.8469 - accuracy: 0.2684 - val_loss: 1.8032 - val_accuracy: 0.3213\n",
      "Epoch 3/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 1.7487 - accuracy: 0.3635 - val_loss: 1.6941 - val_accuracy: 0.4035\n",
      "Epoch 4/120\n",
      "22500/22500 [==============================] - 1s 42us/step - loss: 1.6298 - accuracy: 0.4431 - val_loss: 1.5701 - val_accuracy: 0.4804\n",
      "Epoch 5/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 1.5009 - accuracy: 0.5158 - val_loss: 1.4405 - val_accuracy: 0.5445\n",
      "Epoch 6/120\n",
      "22500/22500 [==============================] - 1s 57us/step - loss: 1.3687 - accuracy: 0.5756 - val_loss: 1.3111 - val_accuracy: 0.5935\n",
      "Epoch 7/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 1.2414 - accuracy: 0.6196 - val_loss: 1.1900 - val_accuracy: 0.6329\n",
      "Epoch 8/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 1.1266 - accuracy: 0.6544 - val_loss: 1.0865 - val_accuracy: 0.6548\n",
      "Epoch 9/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 1.0294 - accuracy: 0.6801 - val_loss: 1.0008 - val_accuracy: 0.6751\n",
      "Epoch 10/120\n",
      "22500/22500 [==============================] - 1s 41us/step - loss: 0.9499 - accuracy: 0.7010 - val_loss: 0.9322 - val_accuracy: 0.6931\n",
      "Epoch 11/120\n",
      "22500/22500 [==============================] - 1s 41us/step - loss: 0.8860 - accuracy: 0.7148 - val_loss: 0.8784 - val_accuracy: 0.7068\n",
      "Epoch 12/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.8349 - accuracy: 0.7268 - val_loss: 0.8373 - val_accuracy: 0.7171\n",
      "Epoch 13/120\n",
      "22500/22500 [==============================] - 1s 44us/step - loss: 0.7936 - accuracy: 0.7384 - val_loss: 0.8012 - val_accuracy: 0.7204\n",
      "Epoch 14/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 0.7594 - accuracy: 0.7451 - val_loss: 0.7743 - val_accuracy: 0.7268\n",
      "Epoch 15/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.7311 - accuracy: 0.7536 - val_loss: 0.7513 - val_accuracy: 0.7335\n",
      "Epoch 16/120\n",
      "22500/22500 [==============================] - 1s 53us/step - loss: 0.7072 - accuracy: 0.7583 - val_loss: 0.7327 - val_accuracy: 0.7373\n",
      "Epoch 17/120\n",
      "22500/22500 [==============================] - 1s 47us/step - loss: 0.6865 - accuracy: 0.7644 - val_loss: 0.7164 - val_accuracy: 0.7432\n",
      "Epoch 18/120\n",
      "22500/22500 [==============================] - 1s 52us/step - loss: 0.6687 - accuracy: 0.7696 - val_loss: 0.7020 - val_accuracy: 0.7468\n",
      "Epoch 19/120\n",
      "22500/22500 [==============================] - 1s 41us/step - loss: 0.6525 - accuracy: 0.7728 - val_loss: 0.6905 - val_accuracy: 0.7503\n",
      "Epoch 20/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.6386 - accuracy: 0.7780 - val_loss: 0.6804 - val_accuracy: 0.7516\n",
      "Epoch 21/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.6257 - accuracy: 0.7829 - val_loss: 0.6721 - val_accuracy: 0.7516\n",
      "Epoch 22/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 0.6138 - accuracy: 0.7860 - val_loss: 0.6634 - val_accuracy: 0.7564\n",
      "Epoch 23/120\n",
      "22500/22500 [==============================] - 1s 40us/step - loss: 0.6029 - accuracy: 0.7898 - val_loss: 0.6579 - val_accuracy: 0.7568\n",
      "Epoch 24/120\n",
      "22500/22500 [==============================] - 1s 48us/step - loss: 0.5929 - accuracy: 0.7924 - val_loss: 0.6495 - val_accuracy: 0.7589\n",
      "Epoch 25/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.5838 - accuracy: 0.7960 - val_loss: 0.6440 - val_accuracy: 0.7621\n",
      "Epoch 26/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.5751 - accuracy: 0.7980 - val_loss: 0.6380 - val_accuracy: 0.7631\n",
      "Epoch 27/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.5665 - accuracy: 0.8011 - val_loss: 0.6345 - val_accuracy: 0.7643\n",
      "Epoch 28/120\n",
      "22500/22500 [==============================] - 1s 44us/step - loss: 0.5589 - accuracy: 0.8028 - val_loss: 0.6290 - val_accuracy: 0.7676\n",
      "Epoch 29/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 0.5517 - accuracy: 0.8050 - val_loss: 0.6255 - val_accuracy: 0.7675\n",
      "Epoch 30/120\n",
      "22500/22500 [==============================] - 1s 47us/step - loss: 0.5451 - accuracy: 0.8070 - val_loss: 0.6214 - val_accuracy: 0.7692\n",
      "Epoch 31/120\n",
      "22500/22500 [==============================] - 1s 42us/step - loss: 0.5380 - accuracy: 0.8100 - val_loss: 0.6172 - val_accuracy: 0.7700\n",
      "Epoch 32/120\n",
      "22500/22500 [==============================] - ETA: 0s - loss: 0.5325 - accuracy: 0.81 - 1s 39us/step - loss: 0.5315 - accuracy: 0.8108 - val_loss: 0.6150 - val_accuracy: 0.7731\n",
      "Epoch 33/120\n",
      "22500/22500 [==============================] - 1s 56us/step - loss: 0.5255 - accuracy: 0.8140 - val_loss: 0.6130 - val_accuracy: 0.7728\n",
      "Epoch 34/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.5195 - accuracy: 0.8160 - val_loss: 0.6114 - val_accuracy: 0.7747\n",
      "Epoch 35/120\n",
      "22500/22500 [==============================] - 1s 42us/step - loss: 0.5143 - accuracy: 0.8174 - val_loss: 0.6067 - val_accuracy: 0.7780\n",
      "Epoch 36/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.5085 - accuracy: 0.8207 - val_loss: 0.6036 - val_accuracy: 0.7787\n",
      "Epoch 37/120\n",
      "22500/22500 [==============================] - 1s 52us/step - loss: 0.5033 - accuracy: 0.8208 - val_loss: 0.6023 - val_accuracy: 0.7795\n",
      "Epoch 38/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.4983 - accuracy: 0.8241 - val_loss: 0.6011 - val_accuracy: 0.7801\n",
      "Epoch 39/120\n",
      "22500/22500 [==============================] - 1s 44us/step - loss: 0.4935 - accuracy: 0.8248 - val_loss: 0.5990 - val_accuracy: 0.7808\n",
      "Epoch 40/120\n",
      "22500/22500 [==============================] - 1s 53us/step - loss: 0.4888 - accuracy: 0.8278 - val_loss: 0.5961 - val_accuracy: 0.7852\n",
      "Epoch 41/120\n",
      "22500/22500 [==============================] - 1s 47us/step - loss: 0.4842 - accuracy: 0.8289 - val_loss: 0.5953 - val_accuracy: 0.7837\n",
      "Epoch 42/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.4796 - accuracy: 0.8311 - val_loss: 0.5928 - val_accuracy: 0.7863\n",
      "Epoch 43/120\n",
      "22500/22500 [==============================] - 1s 44us/step - loss: 0.4755 - accuracy: 0.8330 - val_loss: 0.5931 - val_accuracy: 0.7821\n",
      "Epoch 44/120\n",
      "22500/22500 [==============================] - 1s 47us/step - loss: 0.4707 - accuracy: 0.8343 - val_loss: 0.5926 - val_accuracy: 0.7837\n",
      "Epoch 45/120\n",
      "22500/22500 [==============================] - 1s 46us/step - loss: 0.4668 - accuracy: 0.8352 - val_loss: 0.5893 - val_accuracy: 0.7868\n",
      "Epoch 46/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.4629 - accuracy: 0.8382 - val_loss: 0.5881 - val_accuracy: 0.7864\n",
      "Epoch 47/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.4585 - accuracy: 0.8379 - val_loss: 0.5872 - val_accuracy: 0.7885\n",
      "Epoch 48/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.4550 - accuracy: 0.8413 - val_loss: 0.5881 - val_accuracy: 0.7864\n",
      "Epoch 49/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.4512 - accuracy: 0.8417 - val_loss: 0.5864 - val_accuracy: 0.7893\n",
      "Epoch 50/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 0.4476 - accuracy: 0.8434 - val_loss: 0.5844 - val_accuracy: 0.7869\n",
      "Epoch 51/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.4439 - accuracy: 0.8436 - val_loss: 0.5840 - val_accuracy: 0.7897\n",
      "Epoch 52/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.4405 - accuracy: 0.8451 - val_loss: 0.5825 - val_accuracy: 0.7895\n",
      "Epoch 53/120\n",
      "22500/22500 [==============================] - 1s 52us/step - loss: 0.4369 - accuracy: 0.8463 - val_loss: 0.5821 - val_accuracy: 0.7909\n",
      "Epoch 54/120\n",
      "22500/22500 [==============================] - 1s 53us/step - loss: 0.4335 - accuracy: 0.8478 - val_loss: 0.5822 - val_accuracy: 0.7911\n",
      "Epoch 55/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s 48us/step - loss: 0.4298 - accuracy: 0.8489 - val_loss: 0.5814 - val_accuracy: 0.7919\n",
      "Epoch 56/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.4270 - accuracy: 0.8503 - val_loss: 0.5807 - val_accuracy: 0.7931\n",
      "Epoch 57/120\n",
      "22500/22500 [==============================] - 1s 41us/step - loss: 0.4236 - accuracy: 0.8527 - val_loss: 0.5811 - val_accuracy: 0.7932\n",
      "Epoch 58/120\n",
      "22500/22500 [==============================] - 1s 41us/step - loss: 0.4208 - accuracy: 0.8532 - val_loss: 0.5810 - val_accuracy: 0.7903\n",
      "Epoch 59/120\n",
      "22500/22500 [==============================] - 1s 39us/step - loss: 0.4176 - accuracy: 0.8547 - val_loss: 0.5820 - val_accuracy: 0.7919\n",
      "Epoch 60/120\n",
      "22500/22500 [==============================] - 1s 47us/step - loss: 0.4146 - accuracy: 0.8562 - val_loss: 0.5798 - val_accuracy: 0.7951\n",
      "Epoch 61/120\n",
      "22500/22500 [==============================] - 1s 47us/step - loss: 0.4114 - accuracy: 0.8577 - val_loss: 0.5798 - val_accuracy: 0.7933\n",
      "Epoch 62/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.4088 - accuracy: 0.8584 - val_loss: 0.5794 - val_accuracy: 0.7943\n",
      "Epoch 63/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.4057 - accuracy: 0.8598 - val_loss: 0.5800 - val_accuracy: 0.7951\n",
      "Epoch 64/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.4028 - accuracy: 0.8608 - val_loss: 0.5795 - val_accuracy: 0.7921\n",
      "Epoch 65/120\n",
      "22500/22500 [==============================] - 1s 42us/step - loss: 0.4000 - accuracy: 0.8616 - val_loss: 0.5812 - val_accuracy: 0.7920\n",
      "Epoch 66/120\n",
      "22500/22500 [==============================] - 1s 39us/step - loss: 0.3972 - accuracy: 0.8627 - val_loss: 0.5799 - val_accuracy: 0.7945\n",
      "Epoch 67/120\n",
      "22500/22500 [==============================] - 1s 40us/step - loss: 0.3947 - accuracy: 0.8636 - val_loss: 0.5797 - val_accuracy: 0.7948\n",
      "Epoch 68/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.3919 - accuracy: 0.8648 - val_loss: 0.5808 - val_accuracy: 0.7945\n",
      "Epoch 69/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.3892 - accuracy: 0.8648 - val_loss: 0.5825 - val_accuracy: 0.7923\n",
      "Epoch 70/120\n",
      "22500/22500 [==============================] - 1s 46us/step - loss: 0.3867 - accuracy: 0.8664 - val_loss: 0.5817 - val_accuracy: 0.7937\n",
      "Epoch 71/120\n",
      "22500/22500 [==============================] - 1s 46us/step - loss: 0.3841 - accuracy: 0.8676 - val_loss: 0.5802 - val_accuracy: 0.7941\n",
      "Epoch 72/120\n",
      "22500/22500 [==============================] - 1s 54us/step - loss: 0.3819 - accuracy: 0.8686 - val_loss: 0.5810 - val_accuracy: 0.7941\n",
      "Epoch 73/120\n",
      "22500/22500 [==============================] - 1s 46us/step - loss: 0.3790 - accuracy: 0.8694 - val_loss: 0.5811 - val_accuracy: 0.7941\n",
      "Epoch 74/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.3766 - accuracy: 0.8704 - val_loss: 0.5802 - val_accuracy: 0.7937\n",
      "Epoch 75/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.3741 - accuracy: 0.8714 - val_loss: 0.5807 - val_accuracy: 0.7935\n",
      "Epoch 76/120\n",
      "22500/22500 [==============================] - 1s 41us/step - loss: 0.3721 - accuracy: 0.8719 - val_loss: 0.5817 - val_accuracy: 0.7943\n",
      "Epoch 77/120\n",
      "22500/22500 [==============================] - 1s 40us/step - loss: 0.3693 - accuracy: 0.8730 - val_loss: 0.5818 - val_accuracy: 0.7947\n",
      "Epoch 78/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.3672 - accuracy: 0.8744 - val_loss: 0.5825 - val_accuracy: 0.7936\n",
      "Epoch 79/120\n",
      "22500/22500 [==============================] - 1s 58us/step - loss: 0.3649 - accuracy: 0.8758 - val_loss: 0.5826 - val_accuracy: 0.7959\n",
      "Epoch 80/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.3627 - accuracy: 0.8756 - val_loss: 0.5826 - val_accuracy: 0.7955\n",
      "Epoch 81/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.3605 - accuracy: 0.8761 - val_loss: 0.5838 - val_accuracy: 0.7963\n",
      "Epoch 82/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.3584 - accuracy: 0.8778 - val_loss: 0.5839 - val_accuracy: 0.7952\n",
      "Epoch 83/120\n",
      "22500/22500 [==============================] - 1s 48us/step - loss: 0.3557 - accuracy: 0.8787 - val_loss: 0.5853 - val_accuracy: 0.7940\n",
      "Epoch 84/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.3538 - accuracy: 0.8803 - val_loss: 0.5853 - val_accuracy: 0.7939\n",
      "Epoch 85/120\n",
      "22500/22500 [==============================] - 1s 47us/step - loss: 0.3516 - accuracy: 0.8796 - val_loss: 0.5854 - val_accuracy: 0.7964\n",
      "Epoch 86/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.3493 - accuracy: 0.8811 - val_loss: 0.5859 - val_accuracy: 0.7961\n",
      "Epoch 87/120\n",
      "22500/22500 [==============================] - 1s 52us/step - loss: 0.3471 - accuracy: 0.8815 - val_loss: 0.5875 - val_accuracy: 0.7960\n",
      "Epoch 88/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.3454 - accuracy: 0.8824 - val_loss: 0.5877 - val_accuracy: 0.7960\n",
      "Epoch 89/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.3436 - accuracy: 0.8835 - val_loss: 0.5883 - val_accuracy: 0.7948\n",
      "Epoch 90/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.3411 - accuracy: 0.8836 - val_loss: 0.5913 - val_accuracy: 0.7953\n",
      "Epoch 91/120\n",
      "22500/22500 [==============================] - 1s 47us/step - loss: 0.3394 - accuracy: 0.8859 - val_loss: 0.5892 - val_accuracy: 0.7968\n",
      "Epoch 92/120\n",
      "22500/22500 [==============================] - 1s 48us/step - loss: 0.3374 - accuracy: 0.8867 - val_loss: 0.5903 - val_accuracy: 0.7957\n",
      "Epoch 93/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.3355 - accuracy: 0.8864 - val_loss: 0.5904 - val_accuracy: 0.7956\n",
      "Epoch 94/120\n",
      "22500/22500 [==============================] - 1s 38us/step - loss: 0.3334 - accuracy: 0.8876 - val_loss: 0.5932 - val_accuracy: 0.7952\n",
      "Epoch 95/120\n",
      "22500/22500 [==============================] - 1s 41us/step - loss: 0.3317 - accuracy: 0.8872 - val_loss: 0.5942 - val_accuracy: 0.7936\n",
      "Epoch 96/120\n",
      "22500/22500 [==============================] - 1s 52us/step - loss: 0.3296 - accuracy: 0.8889 - val_loss: 0.5944 - val_accuracy: 0.7949\n",
      "Epoch 97/120\n",
      "22500/22500 [==============================] - 1s 47us/step - loss: 0.3281 - accuracy: 0.8889 - val_loss: 0.5944 - val_accuracy: 0.7956\n",
      "Epoch 98/120\n",
      "22500/22500 [==============================] - 1s 46us/step - loss: 0.3257 - accuracy: 0.8906 - val_loss: 0.5977 - val_accuracy: 0.7943\n",
      "Epoch 99/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 0.3240 - accuracy: 0.8909 - val_loss: 0.5957 - val_accuracy: 0.7941\n",
      "Epoch 100/120\n",
      "22500/22500 [==============================] - 1s 42us/step - loss: 0.3226 - accuracy: 0.8915 - val_loss: 0.6012 - val_accuracy: 0.7959\n",
      "Epoch 101/120\n",
      "22500/22500 [==============================] - 1s 41us/step - loss: 0.3205 - accuracy: 0.8930 - val_loss: 0.5969 - val_accuracy: 0.7953\n",
      "Epoch 102/120\n",
      "22500/22500 [==============================] - 1s 52us/step - loss: 0.3188 - accuracy: 0.8928 - val_loss: 0.5982 - val_accuracy: 0.7932\n",
      "Epoch 103/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.3168 - accuracy: 0.8945 - val_loss: 0.5989 - val_accuracy: 0.7952\n",
      "Epoch 104/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 0.3153 - accuracy: 0.8941 - val_loss: 0.6040 - val_accuracy: 0.7969\n",
      "Epoch 105/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.3130 - accuracy: 0.8955 - val_loss: 0.6008 - val_accuracy: 0.7952\n",
      "Epoch 106/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.3116 - accuracy: 0.8963 - val_loss: 0.6023 - val_accuracy: 0.7928\n",
      "Epoch 107/120\n",
      "22500/22500 [==============================] - 1s 55us/step - loss: 0.3099 - accuracy: 0.8961 - val_loss: 0.6032 - val_accuracy: 0.7940\n",
      "Epoch 108/120\n",
      "22500/22500 [==============================] - 1s 42us/step - loss: 0.3083 - accuracy: 0.8976 - val_loss: 0.6043 - val_accuracy: 0.7969\n",
      "Epoch 109/120\n",
      "22500/22500 [==============================] - 1s 42us/step - loss: 0.3065 - accuracy: 0.8975 - val_loss: 0.6041 - val_accuracy: 0.7968\n",
      "Epoch 110/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.3053 - accuracy: 0.8978 - val_loss: 0.6056 - val_accuracy: 0.7952\n",
      "Epoch 111/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.3032 - accuracy: 0.8998 - val_loss: 0.6064 - val_accuracy: 0.7947\n",
      "Epoch 112/120\n",
      "22500/22500 [==============================] - 1s 40us/step - loss: 0.3018 - accuracy: 0.8999 - val_loss: 0.6072 - val_accuracy: 0.7948\n",
      "Epoch 113/120\n",
      "22500/22500 [==============================] - 1s 51us/step - loss: 0.2998 - accuracy: 0.8998 - val_loss: 0.6103 - val_accuracy: 0.7928\n",
      "Epoch 114/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.2982 - accuracy: 0.9011 - val_loss: 0.6114 - val_accuracy: 0.7945\n",
      "Epoch 115/120\n",
      "22500/22500 [==============================] - 1s 50us/step - loss: 0.2965 - accuracy: 0.9018 - val_loss: 0.6139 - val_accuracy: 0.7935\n",
      "Epoch 116/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 0.2950 - accuracy: 0.9018 - val_loss: 0.6161 - val_accuracy: 0.7932\n",
      "Epoch 117/120\n",
      "22500/22500 [==============================] - 1s 42us/step - loss: 0.2935 - accuracy: 0.9031 - val_loss: 0.6131 - val_accuracy: 0.7952\n",
      "Epoch 118/120\n",
      "22500/22500 [==============================] - 1s 49us/step - loss: 0.2921 - accuracy: 0.9036 - val_loss: 0.6148 - val_accuracy: 0.7937\n",
      "Epoch 119/120\n",
      "22500/22500 [==============================] - 1s 45us/step - loss: 0.2903 - accuracy: 0.9049 - val_loss: 0.6170 - val_accuracy: 0.7936\n",
      "Epoch 120/120\n",
      "22500/22500 [==============================] - 1s 43us/step - loss: 0.2887 - accuracy: 0.9041 - val_loss: 0.6174 - val_accuracy: 0.7939\n"
     ]
    }
   ],
   "source": [
    "# ⏰ This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(50, activation='relu', input_shape=(2000,))) #2 hidden layers\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "moredata_model = model.fit(X_train_tok_lrg,\n",
    "                    y_train_lb_lrg,\n",
    "                    epochs=120,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(X_val_lrg, y_val_lrg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 1s 45us/step\n",
      "Training Loss: 0.284 Training Accuracy: 0.908\n",
      "10000/10000 [==============================] - 0s 46us/step\n",
      "Testing Loss: 0.612 Testing Accuracy: 0.789\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train_tok_lrg, y_train_lb_lrg)\n",
    "print(f'Training Loss: {results_train[0]:.3} Training Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "results_test = model.evaluate(X_test_lrg, y_test_lrg)\n",
    "print(f'Testing Loss: {results_test[0]:.3} Testing Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs, you were able to get a fairly similar validation accuracy of 89.67 (compared to 88.45 in obtained in the first model in this lab). Your test set accuracy went up from 75.8 to 79.2% though, without any other regularization technique. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "\n",
    "In this lesson, you not only built an initial deep-learning model, you then used a validation set to tune your model using various types of regularization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
